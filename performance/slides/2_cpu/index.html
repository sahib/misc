<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml"><head><title>Performance: CPU</title><meta charset="UTF-8"></meta><meta name="generator" content="Hovercraft! 1.0 http://regebro.github.com/hovercraft"></meta><link rel="stylesheet" href="css/hovercraft.css" media="all"></link><link rel="stylesheet" href="css/highlight.css" media="all"></link><link rel="stylesheet" href="hovercraft.css" media="screen,projection"></link><script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        showProcessingMessages: false,
        messageStyle: "none",
        TeX : { extensions : ['color.js'] }
      });
    </script></head><body class="impress-not-supported"><div id="impress-help"></div><div id="impress" data-transition-duration="1500"><div class="step step-level-1" step="0" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="0" data-y="0" data-z="0"><h1 id="agenda">Agenda</h1><p>TODO: Agenda</p></div><div class="step step-level-1 chapter-class" step="1" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="1600" data-y="0" data-z="0"><h1 id="cpu">CPU</h1><p>Quiz:</p><ul><li>If two programs A and B execute the same number of instructions will they have roughly the same runtime?</li><li>If two CPUs have the same frequency, can we make assumptions based on their speed?</li></ul><div class="notes"><p>Answer no.</p><p>Every instruction can take a different amount of cpu cycles.
Every instruction can do a lot of different work (SIMD vs normal)</p></div></div><div class="step step-level-1" step="2" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="3200" data-y="0" data-z="0"><h1 id="compilers">Compilers</h1><img src="images/llvm.png" width="100%"></img><div class="notes"><p>Steps to compile something:</p><ul><li>Lexer/Tokenizer (break code in tokens)</li><li>Parser (build AST from code)</li><li>High Level IR (build generic language from it)</li><li>Low level IR (optimize and make it suitable for machines)</li><li>Convert to actual target machine code</li></ul></div></div><div class="step step-level-1" step="3" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="4800" data-y="0" data-z="0"><h1 id="fun-fact-supercompilers">Fun fact: Supercompilers</h1><img src="images/supercompiler.png"></img><div class="notes"><blockquote><ul><li>Compilers do not usually produce the best code and rely heavily on pattern matching, heuristics
and just being smart. They can miss room for optimizations although this is rather rare in practice.
(except Go, which is just a developing compiler)</li><li>Super compilers brute force compilation (sometimes with benchmarks) until they found the best performing
piece of code.</li><li>Not used in practice, since freaking slow but helpful for developing new compiler optimizations.</li></ul></blockquote><p>STOKE: <a href="https://github.com/StanfordPL/stoke">https://github.com/StanfordPL/stoke</a></p></div></div><div class="step step-level-1" step="4" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="6400" data-y="0" data-z="0"><h1 id="how-is-code-executed">How is code executed?</h1><ul><li>Assembly: 1:1 human readable interpretation of machine code.</li><li>Machine code: machine readable instructions (each instruction has an id)</li><li>Assembler: Program that converts assembly to machine code.</li></ul><div class="notes"><ul><li>This slides could be also a talk about "Why interpreted languages suck"<blockquote><p>Most optimizations will not work with python.
As a language it's really disconnected from the HW - every single statement will cause 100s or 1000s of assembly instructions.
Also there are no almost no guarantees how big e.g. arrays or other data structures will be and how they are layout in memory.
You have to rely on your interpreter (and I count Java's JIT as one!) to be fast on modern hardware - most are not and that's why
there's so much C libraries in python, making the whole packaging system a bloody mess.</p></blockquote></li></ul></div></div><div class="step step-level-1" step="5" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="8000" data-y="0" data-z="0"><h1 id="other-terminology">Other terminology</h1><ul><li>Instruction Set Architecture (x86, arm)</li><li>RISC / CISC</li><li>Microarchitecture / Microcode (<tt>Pentium</tt>, <tt>Coffee Lake</tt>...)</li><li>Instruction Set Extensions / SIMD (MMX, AES, SSE...)</li></ul><div class="notes"><p>Example of a CISC instruction set: x86
Today, most complex operations get translated to RISC code though by the CPU.
CISC turned out to be slower, surprisingly.</p><p>RISC: ARM. Usually cheaper to build and also faster.</p><p>Microarchitecture: Implementation of a certain ISA.</p><p>ISE are not directly available in Go, only if the compiler decides to.</p></div></div><div class="step step-level-1" step="6" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="9600" data-y="0" data-z="0"><h1 id="how-is-machine-code-stored-elf">How is machine code stored? ELF!</h1><p>ELF (Executable and linkable format)</p><pre class="highlight code bash">$ readelf --sections /usr/bin/ls
<span class="o">[</span>...<span class="o">]</span>
<span class="o">[</span><span class="m">12</span><span class="o">]</span> .text             PROGBITS         <span class="m">0000000000008020</span>  <span class="m">00008020</span>
<span class="o">[</span>...<span class="o">]</span>
<span class="o">[</span><span class="m">22</span><span class="o">]</span> .data             PROGBITS         <span class="m">0000000000059000</span>  <span class="m">00058000</span>
$ objdump --disassemble /usr/bin/ls</pre><div class="notes"><p>Beside storing the actual instructions ELF solves:</p><ul><li>Storing debugging info</li><li>Making it possible to link with existing other libraries.</li><li>Includes a text (code) and data section (pre-initialized variables)</li><li>Different OS use different formats, but ELF is probably the most relevant for you
and also the most widely known. Windows has a different one.</li></ul></div></div><div class="step step-level-1" step="7" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="11200" data-y="0" data-z="0"><h1 id="go-assembler-1">Go Assembler #1</h1><pre class="highlight code go"><span class="ln"> 1 </span><span class="w"> </span><span class="kn">package</span><span class="w"> </span><span class="nx">main</span><span class="w">
</span><span class="ln"> 2 </span><span class="w">
</span><span class="ln"> 3 </span><span class="w"> </span><span class="c1">//go:noinline</span><span class="w">
</span><span class="ln"> 4 </span><span class="w"> </span><span class="kd">func</span><span class="w"> </span><span class="nx">add</span><span class="p">(</span><span class="nx">a</span><span class="p">,</span><span class="w"> </span><span class="nx">b</span><span class="w"> </span><span class="kt">int</span><span class="p">)</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="ln"> 5 </span><span class="w">     </span><span class="k">return</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">b</span><span class="w">
</span><span class="ln"> 6 </span><span class="w"> </span><span class="p">}</span><span class="w">
</span><span class="ln"> 7 </span><span class="w">
</span><span class="ln"> 8 </span><span class="w"> </span><span class="kd">func</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="ln"> 9 </span><span class="w">     </span><span class="nx">add</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="w">
</span><span class="ln">10 </span><span class="w"> </span><span class="p">}</span></pre></div><div class="step step-level-1" step="8" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="12800" data-y="0" data-z="0"><h1 id="go-assembler-2">Go Assembler #2</h1><p>Go assembly = assembler for a fantasy CPU</p><pre class="highlight code bash">main.add STEXT nosplit <span class="nv">size</span><span class="o">=</span><span class="m">4</span> <span class="nv">args</span><span class="o">=</span>0x10 <span class="nv">locals</span><span class="o">=</span>0x0 <span class="nv">funcid</span><span class="o">=</span>0x0 <span class="nv">align</span><span class="o">=</span>0x0
      <span class="o">(</span>test.go:4<span class="o">)</span>     TEXT    main.add<span class="o">(</span>SB<span class="o">)</span>, NOSPLIT<span class="p">|</span>ABIInternal, <span class="nv">$0</span>-16
      <span class="o">(</span>test.go:4<span class="o">)</span>     FUNCDATA        <span class="nv">$0</span>, gclocals&#xB7;g2BeySu+wFnoycgXfElmcg<span class="o">==(</span>SB<span class="o">)</span>
      <span class="o">(</span>test.go:4<span class="o">)</span>     FUNCDATA        <span class="nv">$1</span>, gclocals&#xB7;g2BeySu+wFnoycgXfElmcg<span class="o">==(</span>SB<span class="o">)</span>
      <span class="o">(</span>test.go:4<span class="o">)</span>     FUNCDATA        <span class="nv">$5</span>, main.add.arginfo1<span class="o">(</span>SB<span class="o">)</span>
      <span class="o">(</span>test.go:4<span class="o">)</span>     FUNCDATA        <span class="nv">$6</span>, main.add.argliveinfo<span class="o">(</span>SB<span class="o">)</span>
      <span class="o">(</span>test.go:4<span class="o">)</span>     PCDATA  <span class="nv">$3</span>, <span class="nv">$1</span>
      <span class="o">(</span>test.go:5<span class="o">)</span>     ADDQ    BX, AX
      <span class="o">(</span>test.go:5<span class="o">)</span>     RET
<span class="o">(</span>...<span class="o">)</span></pre><div class="notes"><p>Important: Explain registers!</p><p>Can we just say: To make things faster you have to reduce the number of instructions?</p><p>Sadly no. Modern CPUs are MUCH complexer than machines that sequentially execute instructions.
They take all kind of shortcuts to execute things faster - most of the time.
See also: Megaherz myth (-&gt; higher clock = more cycles per time)</p><p>Effects that may play a role</p><ul><li>Not every instruction takes the same amount of cycles (MOV 1 cycle,</li><li>Pipelining</li><li>Superscalar Execution</li><li>Branch prediction / Cache prefetching</li><li>Out-of-order execution</li><li>Cache misses (fetching from main memory mean</li></ul><p>List of typical cycles per instructions ("latency"): <a href="https://www.agner.org/optimize/instruction_tables.pdf">https://www.agner.org/optimize/instruction_tables.pdf</a></p></div></div><div class="step step-level-1" step="9" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="14400" data-y="0" data-z="0"><h1 id="detour-calling-conventions">Detour: Calling conventions</h1><pre class="highlight code asm"><span class="nl">FuncAddGo:</span><span class="w">
   </span><span class="nf">MOVQ</span><span class="w"> </span><span class="mi">0x8</span><span class="p">(</span><span class="no">SP</span><span class="p">),</span><span class="w"> </span><span class="no">AX</span><span class="w">  </span><span class="c1">; get arg x
</span><span class="w">   </span><span class="nf">MOVQ</span><span class="w"> </span><span class="mi">0x10</span><span class="p">(</span><span class="no">SP</span><span class="p">),</span><span class="w"> </span><span class="no">CX</span><span class="w"> </span><span class="c1">; get arg y
</span><span class="w">   </span><span class="nf">ADDQ</span><span class="w"> </span><span class="no">CX</span><span class="p">,</span><span class="w"> </span><span class="no">AX</span><span class="w">       </span><span class="c1">; %ax &lt;- x + y
</span><span class="w">   </span><span class="nf">MOVQ</span><span class="w"> </span><span class="no">AX</span><span class="p">,</span><span class="w"> </span><span class="mi">0x20</span><span class="p">(</span><span class="no">SP</span><span class="p">)</span><span class="w"> </span><span class="c1">; return x+y-z
</span><span class="w">   </span><span class="nf">RET</span></pre><pre class="highlight code asm"><span class="nl">FuncAddC:</span><span class="w">
    </span><span class="nf">LEAL</span><span class="w">  </span><span class="p">(</span><span class="nv">%rdi</span><span class="p">,</span><span class="nv">%rsi</span><span class="p">),</span><span class="w"> </span><span class="nv">%eax</span><span class="w">
    </span><span class="nf">ADDL</span><span class="w">  </span><span class="nv">%edx</span><span class="p">,</span><span class="w"> </span><span class="nv">%eax</span><span class="w">
    </span><span class="nf">RETQ</span></pre><div class="notes"><p>Go and C have different calling conventions.
C passes params and return values over registers
Go uses memory addresses (on the stack)</p><p>This makes it impossible to call a C function directly from Go.
Some languages like Zig share the same calling convetions and make
it therefore possible to directly call C code. For go we need a weird
abstraction layer called cgo.</p></div></div><div class="step step-level-1" step="10" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="16000" data-y="0" data-z="0"><h1 id="inlining-functions">Inlining functions</h1><p>Inlining functions can speed up things at the cost of increased ELF size.</p><p>Advantage: Parameters do not need to get copied, but CPU can re-use whatever
is in the registers alreadys. Also return values do not need to be copied.</p><p>Only done for small functions and only in hot paths.</p></div><div class="step step-level-1" step="11" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="17600" data-y="0" data-z="0"><h1 id="pipelining">Pipelining</h1><p><a href="https://de.wikipedia.org/wiki/Pipeline_(Prozessor">https://de.wikipedia.org/wiki/Pipeline_(Prozessor</a>)</p><p>LOAD: Load the instruction from memory, increment instruction counter.
DECODE: Data for the command is loaded.
EXEC: Instruction is executed.
WRITEBACK: Result is written back to a register.</p><ul><li>Every instruction needs to do this</li><li>Modern CPUs can work on many instructions at the same time</li><li>They can be also re-ordered by the CPU!</li><li>This can lead to issues when an instruction depends on results of another instructions! (branches!)</li><li>It can even happen that we do unncessary work! See SPECTRE and MELTDOWN security issues!</li></ul></div><div class="step step-level-1" step="12" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="19200" data-y="0" data-z="0"><h1 id="branch-prediction">Branch prediction</h1><p>... you can give hints to your CPU!</p><pre class="highlight code c"><span class="k">if</span><span class="p">(</span><span class="n">likely</span><span class="p">(</span><span class="n">a</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="c1">// ...
</span><span class="p">}</span><span class="w">

</span><span class="k">if</span><span class="p">(</span><span class="n">unlikely</span><span class="p">(</span><span class="n">err</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="c1">// ...
</span><span class="p">}</span></pre><p>No likely() in Go, compiler tries to insert those hints automayically.
Not much of an important optimization nowadays though as CPUs get a lot better:</p><p><a href="https://de.wikipedia.org/wiki/Sprungvorhersage">https://de.wikipedia.org/wiki/Sprungvorhersage</a></p><p>(but can be relevant for very hot paths on cheap ARM cpus)</p></div><div class="step step-level-1" step="13" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="20800" data-y="0" data-z="0"><h1 id="branch-prediction-in-real-life">Branch prediction in real life</h1><pre class="highlight code go"><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="p">&lt;</span><span class="w"> </span><span class="nx">N</span><span class="p">;</span><span class="w"> </span><span class="nx">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">unsorted</span><span class="p">[</span><span class="nx">i</span><span class="p">]</span><span class="w"> </span><span class="p">&lt;</span><span class="w"> </span><span class="nx">X</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nx">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nx">unsorted</span><span class="p">[</span><span class="nx">i</span><span class="p">];</span><span class="w">
    </span><span class="p">}</span><span class="w">
</span><span class="p">}</span></pre><pre class="highlight code go"><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="p">&lt;</span><span class="w"> </span><span class="nx">N</span><span class="p">;</span><span class="w"> </span><span class="nx">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">sorted</span><span class="p">[</span><span class="nx">i</span><span class="p">]</span><span class="w"> </span><span class="p">&lt;</span><span class="w"> </span><span class="nx">X</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nx">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nx">sorted</span><span class="p">[</span><span class="nx">i</span><span class="p">];</span><span class="w">
    </span><span class="p">}</span><span class="w">
</span><span class="p">}</span></pre><div class="notes"><p>Effect is unnotice-able if optimizations are enabled.
Why? Compilers can make the inner branch a branchless statement.</p></div></div><div class="step step-level-1" step="14" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="22400" data-y="0" data-z="0"><h1 id="go-1-20-profile-guided-optimization">Go 1.20: Profile Guided Optimization</h1><p>Idea:</p><ul><li>Let program run in analysis mode.</li><li>Capture data about what branches were hit how often.</li><li>Use this data on the next compile to decide which branch is likely!</li></ul><img src="images/pgo.png"></img><div class="notes"><p>Also decides on where to inline functions.</p><p><a href="https://tip.golang.org/doc/pgo">https://tip.golang.org/doc/pgo</a></p><p>Old news for languages like C.</p></div></div><div class="step step-level-1" step="15" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="24000" data-y="0" data-z="0"><h1 id="branchless-programming">Branchless programming</h1><pre class="highlight code c"><span class="kt">int32_t</span><span class="w"> </span><span class="nf">max</span><span class="p">(</span><span class="kt">int32_t</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">int32_t</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="k">if</span><span class="p">(</span><span class="n">a</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="k">return</span><span class="w"> </span><span class="n">a</span><span class="p">;</span><span class="w">
    </span><span class="p">}</span><span class="w">
    </span><span class="k">return</span><span class="w"> </span><span class="n">b</span><span class="p">;</span><span class="w">
</span><span class="p">}</span></pre><pre class="highlight code c"><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">a</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">a</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">;</span></pre><pre class="highlight code c"><span class="k">return</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="p">((</span><span class="n">a</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="p">((</span><span class="n">a</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">31</span><span class="p">)</span></pre><div class="notes"><p>Probably not relevant in most cases, as compiler are usually smart, but CAN
be a life saver in really hot loops.</p></div></div><div class="step step-level-1" step="16" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="25600" data-y="0" data-z="0"><h1 id="loop-unrolling">Loop unrolling</h1><ul><li>A for loop is just a repeated branch condition.</li><li>Compilers unroll simple loops.</li><li>If they don't hand unrolling can be useful (very seldom!)</li></ul><p>TODO: Example</p></div><div class="step step-level-1" step="17" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="27200" data-y="0" data-z="0"><h1 id="reduce-number-of-instructions">Reduce number of instructions</h1><p>memcpy example</p><p>TODO: Instrinsic</p></div><div class="step step-level-1" step="18" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="28800" data-y="0" data-z="0"><h1 id="i-want-to-mov-mov-it">I want to MOV, MOV it</h1><pre class="highlight code">MOV &lt;dst&gt; &lt;src&gt;</pre><pre class="highlight code">MOV &lt;reg&gt; &lt;reg&gt;
MOV &lt;mem&gt; &lt;reg&gt;
MOV &lt;reg&gt; &lt;mem&gt;</pre><p>-&gt; Access to main memory is 125ns, L1 cache is ~1ns</p><p>Fun fact: MOV alone is Turing complete: <a href="https://github.com/xoreaxeaxeax/movfuscator">https://github.com/xoreaxeaxeax/movfuscator</a></p></div><div class="step step-level-1" step="19" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="30400" data-y="0" data-z="0"><h1 id="the-von-neumann-bottleneck">The von Neumann Bottleneck</h1><p>von Neumann Architektur:</p><ul><li>Computer Architecture where there is common memory accessible by all cores</li><li>Memory contains Data as well as code instructions</li><li>All data/code goes over a common bus</li><li>Pretty much all computer nowadays are build this way</li></ul><p>Bottleneck: Memory acess is much slower than CPUs can process the data.</p></div><div class="step step-level-1" step="20" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="32000" data-y="0" data-z="0"><h1 id="l1-l2-l3">L1, L2, L3</h1><p>Just add caches!</p><img src="images/whatcouldgowrong.jpeg"></img><p>TODO: Add picture of cache architecture.</p></div><div class="step step-level-1" step="21" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="33600" data-y="0" data-z="0"><h1 id="cache-lines">Cache lines</h1><p>typicall 64 byte
Read an written in one go!</p></div><div class="step step-level-1" step="22" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="35200" data-y="0" data-z="0"><h1 id="caches-misses">Caches misses</h1><p>Unsure if you have cache misses? Use the perf stat -p &lt;PID&gt; command!</p><p><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance</a>
<a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/overview-of-performance-monitoring-options_monitoring-and-managing-system-status-and-performance">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/overview-of-performance-monitoring-options_monitoring-and-managing-system-status-and-performance</a></p><p>counter example 1-3</p></div><div class="step step-level-1" step="23" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="36800" data-y="0" data-z="0"><h1 id="struct-size-matters">Struct size matters</h1><pre class="highlight code go"><span class="c1">// How big is this struct?</span><span class="w">
</span><span class="kd">type</span><span class="w"> </span><span class="nx">XXX</span><span class="w"> </span><span class="kd">struct</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nx">A</span><span class="w"> </span><span class="kt">int64</span><span class="w">
    </span><span class="nx">B</span><span class="w"> </span><span class="kt">uint32</span><span class="w">
    </span><span class="nx">C</span><span class="w"> </span><span class="kt">byte</span><span class="w">
    </span><span class="nx">D</span><span class="w"> </span><span class="kt">bool</span><span class="w">
    </span><span class="nx">E</span><span class="w"> </span><span class="kt">string</span><span class="w">
    </span><span class="nx">F</span><span class="w"> </span><span class="p">[]</span><span class="kt">byte</span><span class="w">
    </span><span class="nx">G</span><span class="w"> </span><span class="kd">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="kt">int64</span><span class="w">
    </span><span class="nx">H</span><span class="w"> </span><span class="kd">interface</span><span class="p">{}</span><span class="w">
    </span><span class="nx">I</span><span class="w"> </span><span class="kt">int</span><span class="w">
</span><span class="p">}</span></pre></div><div class="step step-level-1" step="24" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="38400" data-y="0" data-z="0"><h1 id="padding-can-happen">Padding can happen</h1><pre class="highlight code go"><span class="nx">x</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">XXX</span><span class="p">{}</span><span class="w">  </span><span class="c1">// measured with Go 1.20!</span><span class="w">
</span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="s">"A"</span><span class="p">,</span><span class="w"> </span><span class="nx">unsafe</span><span class="p">.</span><span class="nx">Sizeof</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">A</span><span class="p">))</span><span class="w">  </span><span class="c1">// 8</span><span class="w">
</span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="s">"B"</span><span class="p">,</span><span class="w"> </span><span class="nx">unsafe</span><span class="p">.</span><span class="nx">Sizeof</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">B</span><span class="p">))</span><span class="w">  </span><span class="c1">// 4</span><span class="w">
</span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="s">"C"</span><span class="p">,</span><span class="w"> </span><span class="nx">unsafe</span><span class="p">.</span><span class="nx">Sizeof</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">C</span><span class="p">))</span><span class="w">  </span><span class="c1">// 1</span><span class="w">
</span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="s">"D"</span><span class="p">,</span><span class="w"> </span><span class="nx">unsafe</span><span class="p">.</span><span class="nx">Sizeof</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">D</span><span class="p">))</span><span class="w">  </span><span class="c1">// 1 (&lt;-- +2 padding)</span><span class="w">
</span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="s">"E"</span><span class="p">,</span><span class="w"> </span><span class="nx">unsafe</span><span class="p">.</span><span class="nx">Sizeof</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">E</span><span class="p">))</span><span class="w">  </span><span class="c1">// 16</span><span class="w">
</span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="s">"F"</span><span class="p">,</span><span class="w"> </span><span class="nx">unsafe</span><span class="p">.</span><span class="nx">Sizeof</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">F</span><span class="p">))</span><span class="w">  </span><span class="c1">// 24</span><span class="w">
</span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="s">"G"</span><span class="p">,</span><span class="w"> </span><span class="nx">unsafe</span><span class="p">.</span><span class="nx">Sizeof</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">G</span><span class="p">))</span><span class="w">  </span><span class="c1">// 8</span><span class="w">
</span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="s">"H"</span><span class="p">,</span><span class="w"> </span><span class="nx">unsafe</span><span class="p">.</span><span class="nx">Sizeof</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">H</span><span class="p">))</span><span class="w">  </span><span class="c1">// 16</span><span class="w">
</span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="s">"I"</span><span class="p">,</span><span class="w"> </span><span class="nx">unsafe</span><span class="p">.</span><span class="nx">Sizeof</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">I</span><span class="p">))</span><span class="w">  </span><span class="c1">// 8</span><span class="w">
</span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="s">"x"</span><span class="p">,</span><span class="w"> </span><span class="nx">unsafe</span><span class="p">.</span><span class="nx">Sizeof</span><span class="p">(</span><span class="nx">x</span><span class="p">))</span><span class="w">    </span><span class="c1">// 88 (not 86!)</span></pre><div class="notes"><p>If a struct is bigger than a cache line, then accessing .A and .I would
cause the CPU to always require to get a new cache line!</p></div></div><div class="step step-level-1" step="25" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="40000" data-y="0" data-z="0"><h1 id="binary-size-matters">Binary size matters</h1><ul><li>More debug symbols, functions and instructions make the binary bigger.</li><li>A process needs <em>at least</em> as much memory as the binary size (caveat: only the first one)</li><li>The bigger the binary, the longer the startup size. Important for shortlived processes (scripts!)</li><li>CPUs have caches for code instructions. If your program is so fat that that the caches get evicted,
you might have created a performance issue. (ex: jumping between two functions in your binary, located across)</li></ul><div class="notes"><p>Binaries can be compressed with UPX, but that does make start up time faster - contrary to that.</p><p>Also, in the embedded world the binary size is way more important, but 30M binaries seem excessive
even on servers. Go is doing a bad job here while Rust produces tiny outputs.</p></div></div><div class="step step-level-1" step="26" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="41600" data-y="0" data-z="0"><h1 id="detour-perf-command">Detour: perf command</h1><p>System wide profiling</p><pre class="highlight code bash">perf stat -a &lt;command&gt;   <span class="c1"># Like `time` but much better.
</span>perf stat -a -p &lt;PID&gt;    <span class="c1"># Attach to existin process.
</span>perf mem                 <span class="c1"># Detailed report about memory access / misses
</span>perf c2c                 <span class="c1"># Can find false sharing (see next chapter)</span></pre></div><div class="step step-level-1" step="27" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="43200" data-y="0" data-z="0"><h1 id="detour-pprof">Detour: <tt>pprof</tt></h1><p>Visualize where the program spends time:</p><ul><li>Call graph is annotated times.</li><li>Alternatively available as flamegraph.</li></ul><pre class="highlight code bash"><span class="c1"># pprof server under port 3000:
</span>$ go tool pprof localhost:3000/debug/pprof/profile</pre><div class="notes"><p>Look at images/dashboard_pprof.svg here.</p><p>Pprof is also available for Python, but not as well integrated:
<a href="https://github.com/timpalpant/pypprof">https://github.com/timpalpant/pypprof</a></p></div></div><div class="step step-level-1" step="28" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="44800" data-y="0" data-z="0"><h1 id="detour-flame-graphs">Detour: Flame graphs</h1><pre class="highlight code go"><span class="c1">// Alternative for shortlived programs.</span><span class="w">
</span><span class="c1">// Paste this in main():</span><span class="w">
</span><span class="nx">f</span><span class="p">,</span><span class="w"> </span><span class="nx">_</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">os</span><span class="p">.</span><span class="nx">Create</span><span class="p">(</span><span class="s">"cpu.pprof"</span><span class="p">)</span><span class="w">
</span><span class="nx">pprof</span><span class="p">.</span><span class="nx">StartCPUProfile</span><span class="p">(</span><span class="nx">f</span><span class="p">)</span><span class="w">
</span><span class="k">defer</span><span class="w"> </span><span class="nx">pprof</span><span class="p">.</span><span class="nx">StopCPUProfile</span><span class="p">()</span><span class="w">

</span><span class="c1">// ... do your work here ...</span></pre><div class="notes"><p>See images/brig_flamegraph.png
See images/brig_flamegraph.html</p><p>Perfect to see what time is spend in in what symbol.
Available for:</p><ul><li>CPU</li><li>Memory Allocations (although I like pprof more here)</li><li>Off-CPU (i.e. I/O)</li></ul></div></div><div class="step step-level-1" step="29" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="46400" data-y="0" data-z="0"><h1 id="cache-coherency">Cache coherency</h1><p>In multithreaded programs, a cache gets evicted</p></div><div class="step step-level-1" step="30" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="48000" data-y="0" data-z="0"><h1 id="false-sharing">False sharing</h1><p>Counter4 example.</p><p>Multiple threads use the same memory</p><p>Can be fixed by introducing padding!</p><ul><li>False sharing / True sharing (i.e. when to pad your data structures
<a href="https://alic.dev/blog/false-sharing.html">https://alic.dev/blog/false-sharing.html</a> )</li></ul></div><div class="step step-level-1" step="31" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="49600" data-y="0" data-z="0"><h1 id="true-sharing">True sharing</h1><p>This is when the idea of introducing caches between CPU and memory works out.
Good news: Can be controlled by:</p><ul><li>Limiting struct sizes to 64 bytes</li><li>Grouping often accessed data together.
(arrays of data, not array of structs of data)</li></ul><p>-&gt; employee example</p></div><div class="step step-level-1" step="32" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="51200" data-y="0" data-z="0"><h1 id="data-oriented-programming">Data oriented programming</h1><p>The science of designing programs in a CPU friendly way.</p><div class="notes"><p>DOP is often mentioned as contrast to OOP, but both concepts can complement each other.</p><p>Object oriented program is designing the program in a way that is friendly to humans.</p><p>It does by encapsulating data and methods together. By coincidence, this is not exactly
helpful to the machine your program runs on. Why?</p><ul><li>global state (i.e. impure functions) make branch/cache predictions way harder.</li><li>hurts cache locality.</li></ul></div></div><div class="step step-level-1" step="33" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="52800" data-y="0" data-z="0"><h1 id="matrix-traversal">Matrix Traversal</h1><ul><li>Why is column traversal so much slower?</li></ul><p>Good picture source: <a href="https://medium.com/mirum-budapest/introduction-to-data-oriented-programming-85b51b99572d">https://medium.com/mirum-budapest/introduction-to-data-oriented-programming-85b51b99572d</a></p></div><div class="step step-level-1" step="34" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="54400" data-y="0" data-z="0"><h1 id="employees">Employees</h1><ul><li>Why is the variant with two arrays faster?</li><li>What happens if we make the name array longer/shorter?</li></ul><p>Array-of-Structures vs Structures-of-Arrays</p><p><a href="https://www.dataorienteddesign.com/dodmain/">https://www.dataorienteddesign.com/dodmain/</a></p></div><div class="step step-level-1" step="35" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="56000" data-y="0" data-z="0"><h1 id="memcpy"><tt>memcpy</tt></h1><ul><li>Why is the single-byte memcpy so much slower?</li><li>What evil trick is the system memcpy doing?</li><li>Can we do even faster?</li></ul><div class="notes"><p>-&gt; Problem: von-Neumann-Bottleneck.
-&gt; CPU can work on data faster than typical RAM can deliver it.
-&gt; Workaround: Caches in the CPU, Prefetching.
-&gt; Actual solution: Data oriented design.
-&gt; Sequential access, tight packing of data, SIMD (and if you're crazy: DMA)
-&gt; Still best way to speed up copies: don't copy.</p></div><div class="notes"><p>Object oriented design tends to fuck this up and many Games (at their core)
do not use OOP. You can use both at the same time though!</p></div></div><div class="step step-level-1" step="36" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="57600" data-y="0" data-z="0"><h1 id="process-scheduler">Process scheduler</h1><p>We're not alone on a system. Every process get assigned a share of time that it may execute.</p><ul><li>After execution: Store state in RAM.</li><li>Before execution: Load state from RAM.</li></ul><img src="images/process_states.jpg"></img><img src="images/process_states.webp"></img><p>-&gt; Expensive. Switching too often is expensive.</p><div class="notes"><ul><li>scheduler types (O(n), O(1), CFS, BFS)</li><li>scheduler is determined at compile time.</li><li>there are some knobs to tune the scheduler, but not that interesting.</li><li>Show process states with ps a.</li></ul></div></div><div class="step step-level-1" step="37" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="59200" data-y="0" data-z="0"><h1 id="process-load">Process load</h1><ul><li>Load param counts the number of processes in running or waiting state.</li><li>"0" describes an idle system.</li><li>If the system has a higher load number than cores it is overloaded.</li><li>load is averaged over 5, 10, 15 by default.</li><li>use load5 for graphs, load15 for quick judgmenet.</li></ul></div><div class="step step-level-1" step="38" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="60800" data-y="0" data-z="0"><h1 id="process-niceness">Process niceness</h1><p>Niceness is the "weight" for a certain process during scheduling:</p><ul><li>Ranges from -20 to +19.</li><li>-20 gives the process more time to execute.</li><li>0 is the default.</li><li>+19 gives the process way less to execute.</li></ul><p>Can be set via nice (new commands), renice (running programs)
Exact behaviour depends on scheduler (scheduling frequency vs time slice size)</p></div><div class="step step-level-1" step="39" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="62400" data-y="0" data-z="0"><h1 id="rough-rules-to-take-away">Rough Rules to take away</h1><ol><li>Only use so much memory as you really need.</li><li>Writes modify the cache. Directly use your data or declare it later.</li><li>Keep your structs small. (&lt;64 byte)</li><li>Avoid nesting of data, if possible.</li><li>For small structures (&lt;64 byte) prefer copying over pointers.</li><li>Avoid jumpin around in your memory a lot.</li><li>Avoid virtual methods and inheritance.</li></ol><p>TODO: Revisit those rules.</p><div class="notes"><p>Go even warns about too structures (if they are used as values):</p><p>gocritic hugeParam: cfg is heavy (240 bytes); consider passing it by pointer</p></div></div></div><script type="text/javascript" src="js/impress.js"></script><script type="text/javascript" src="js/gotoSlide.js"></script><script type="text/javascript" src="js/hovercraft.js"></script></body></html>