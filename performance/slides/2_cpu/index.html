<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml"><head><title>Performance: CPU</title><meta charset="UTF-8"></meta><meta name="generator" content="Hovercraft! 1.0 http://regebro.github.io/hovercraft"></meta><link rel="stylesheet" href="css/hovercraft.css" media="all"></link><link rel="stylesheet" href="css/highlight.css" media="all"></link><link rel="stylesheet" href="hovercraft.css" media="screen,projection"></link><script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        showProcessingMessages: false,
        messageStyle: "none",
        TeX : { extensions : ['color.js'] }
      });
    </script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script></head><body class="impress-not-supported"><div id="impress-help"></div><div id="impress" data-transition-duration="950"><div class="step step-level-1" step="0" data-x="2500" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-y="0" data-z="0"><p class="chapter">CPU</p><p>The secrets of the computer &#x1F9E0;</p></div><div class="step step-level-1" step="1" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="5000" data-y="0" data-z="0"><h1 id="agenda">Agenda</h1><ul><li>How to get from source to machine code?</li><li>How does the CPU execute machine code?</li><li>What performance effects does this have?</li><li>Profiling &amp; Benchmarking thoughts &amp; tips</li></ul><img src="images/cpu.jpg" width="50%"></img></div><div class="step step-level-1" step="2" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="7500" data-y="0" data-z="0"><h1 id="quiz">Quiz</h1><ol><li>If two CPUs have the same frequency, can we make assumptions on their speed?</li><li>If two programs <em>A</em> and <em>B</em> execute the same number of machine instructions will they have roughly the same runtime?</li></ol><div class="notes"><p>Those are the questions we will be looking into in detail today.
Here's the TL;DR:</p><ol><li>Answer no.
Every instruction can take a different amount of cpu cycles.
Every instruction can do a lot of different work (SIMD vs normal)</li><li>Also no.
Speed of a CPU largely relies on many many factors (#core, cache size, ...)
The frequency also did not increase much over the years since CPUs get
manufactured much smaller, causing heat issues with higher freqs.</li></ol></div></div><div class="step step-level-1" step="3" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="10000" data-y="0" data-z="0"><h1 id="compilers">Compilers</h1><img src="diagrams/2_compilers.svg" width="140%"></img><div class="notes"><p>Steps to compile something:</p><ul><li>Lexer/Tokenizer (break code in tokens)</li><li>Parser (build AST from code)</li><li>High Level IR (build generic language from it)</li><li>Low level IR (optimize and make it suitable for machines)</li><li>Convert to actual target machine code</li></ul></div></div><div class="step step-level-1" step="4" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="12500" data-y="0" data-z="0"><h1 id="fun-fact-supercompilers">Fun fact: Supercompilers</h1><img src="images/supercompiler.png"></img><div class="notes"><ul><li>Compilers do not usually produce the best code and rely heavily on pattern matching, heuristics
and just being smart. They can miss room for optimizations although this is rather rare in practice.
(except Go, which is just a developing compiler)</li><li>Super compilers brute force compilation (sometimes with benchmarks) until they found the best performing
piece of code.</li><li>Not used in practice, since freaking slow but helpful for developing new compiler optimizations.</li></ul><p>As you will see in the rest of the workshop,
70% of optimization is to help the compiler
make the right decisions.</p><p>STOKE: <a href="https://github.com/StanfordPL/stoke">https://github.com/StanfordPL/stoke</a></p></div></div><div class="step step-level-1" step="5" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="15000" data-y="0" data-z="0"><h1 id="how-is-code-executed">How is code executed?</h1><img src="diagrams/2_assembler.svg" width="120%"></img><div class="notes"><ul><li>Assembly: 1:1 human readable interpretation of machine code.</li><li>Machine code: machine readable instructions (each instruction has an id)</li><li>Assembler: Program that converts assembly to machine code.</li></ul></div></div><div class="step step-level-1" step="6" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="17500" data-y="0" data-z="0"><h1 id="other-terminology">Other terminology</h1><ul><li><strong>ISA:</strong> Instruction Set Architecture (<tt>x86</tt>, <tt>arm</tt>, ...)</li><li><strong>CISC</strong> Complex Instruction Set Computer (<tt>x86</tt>)</li><li><strong>RISC:</strong> Reduced Instruction Set Computer (<tt>arm</tt>)</li><li><strong>SIMD:</strong> Single Instruction, Multiple Data</li><li><strong>ISE:</strong> Instruction Set Extensions (<tt>AVX</tt>, <tt>AES</tt>, <tt>SSE</tt>...)</li><li>Micro{architecture,code} (<tt>Pentium3</tt>, <tt>Alder Lake</tt>, <tt>Zen</tt>...)</li></ul><div class="notes"><p>Example of a CISC instruction set: x86
Today, most complex operations get translated to RISC code though by the CPU.
CISC turned out to be slower, surprisingly.</p><p>RISC: ARM. Usually cheaper to build and also faster.</p><p>Microarchitecture: Implementation of a certain ISA.</p><p>ISE (Instruction Set Extensions) are not directly available in Go, only if the compiler decides to use them.</p></div></div><div class="step step-level-1" step="7" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="20000" data-y="0" data-z="0"><h1 id="how-is-machine-code-stored">How is machine code stored?</h1><p>As ELF (Executable and Linkable Format)</p><pre class="highlight code bash">$<span class="w"> </span>readelf<span class="w"> </span>--sections<span class="w"> </span>/usr/bin/ls<span class="w">
</span><span class="o">[</span>...<span class="o">]</span><span class="w">
</span><span class="o">[</span><span class="m">12</span><span class="o">]</span><span class="w"> </span>.text<span class="w">             </span>PROGBITS<span class="w">
</span><span class="o">[</span>...<span class="o">]</span><span class="w">
</span><span class="o">[</span><span class="m">22</span><span class="o">]</span><span class="w"> </span>.data<span class="w">             </span>PROGBITS<span class="w">
</span>$<span class="w"> </span>objdump<span class="w"> </span>--disassemble<span class="w"> </span>/usr/bin/ls</pre><div class="notes"><p>Beside storing the actual instructions ELF solves:</p><ul><li>Storing debugging info</li><li>Making it possible to link with existing other libraries.</li><li>Includes a text (code) and data section (pre-initialized variables)</li><li>Different OS use different formats, but ELF is probably the most relevant for you
and also the most widely known. Windows has a different one.</li></ul></div></div><div class="step step-level-1" step="8" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="22500" data-y="0" data-z="0"><h1 id="go-assembler-1">Go Assembler #1</h1><pre class="highlight code go"><span class="ln"> 1 </span><span class="w"> </span><span class="kn">package</span><span class="w"> </span><span class="nx">main</span><span class="w">
</span><span class="ln"> 2 </span><span class="w">
</span><span class="ln"> 3 </span><span class="w"> </span><span class="c1">//go:noinline</span><span class="w">
</span><span class="ln"> 4 </span><span class="w"> </span><span class="kd">func</span><span class="w"> </span><span class="nx">add</span><span class="p">(</span><span class="nx">a</span><span class="p">,</span><span class="w"> </span><span class="nx">b</span><span class="w"> </span><span class="kt">int</span><span class="p">)</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="ln"> 5 </span><span class="w">     </span><span class="k">return</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">b</span><span class="w">
</span><span class="ln"> 6 </span><span class="w"> </span><span class="p">}</span><span class="w">
</span><span class="ln"> 7 </span><span class="w">
</span><span class="ln"> 8 </span><span class="w"> </span><span class="kd">func</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="ln"> 9 </span><span class="w">     </span><span class="nx">add</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="w">
</span><span class="ln">10 </span><span class="w"> </span><span class="p">}</span></pre><div class="notes"><p>The official Go compiler is not based on LLVM or GCC.
However, it also uses a IR which it calls "Go assembler".
It's basically an assembler like dialect for a fantasy CPU.
After it was optimized, it gets translated to actual target machine code.</p></div></div><div class="step step-level-1" step="9" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="25000" data-y="0" data-z="0"><h1 id="go-assembler-2">Go Assembler #2</h1><pre class="highlight code bash">$<span class="w"> </span>go<span class="w"> </span>build<span class="w"> </span>-gcflags<span class="o">=</span><span class="s2">"-S"</span><span class="w"> </span>add.go<span class="w">
</span><span class="o">[</span>...<span class="o">]</span><span class="w">
</span>main.add<span class="w"> </span>STEXT<span class="w"> </span>nosplit<span class="w"> </span><span class="nv">size</span><span class="o">=</span><span class="m">4</span><span class="w"> </span><span class="o">[</span>...<span class="o">]</span><span class="w">
  </span><span class="o">(</span>test.go:4<span class="o">)</span><span class="w"> </span>TEXT<span class="w">   </span>main.add<span class="o">(</span>SB<span class="o">)</span>,<span class="w"> </span><span class="o">[</span>...<span class="o">]</span><span class="w">
  </span><span class="o">(</span>test.go:4<span class="o">)</span><span class="w"> </span>PCDATA<span class="w"> </span><span class="nv">$3</span>,<span class="w"> </span><span class="nv">$1</span><span class="w">
  </span><span class="o">(</span>test.go:5<span class="o">)</span><span class="w"> </span>ADDQ<span class="w">   </span>BX,<span class="w"> </span>AX<span class="w">
  </span><span class="o">(</span>test.go:5<span class="o">)</span><span class="w"> </span>RET<span class="w">
</span><span class="o">[</span>...<span class="o">]</span><span class="w">
</span>main.main<span class="w"> </span>STEXT<span class="w"> </span><span class="nv">size</span><span class="o">=</span><span class="m">121</span><span class="w"> </span><span class="o">[</span>...<span class="o">]</span><span class="w">
</span><span class="o">[</span>...<span class="o">]</span><span class="w">
  </span><span class="o">(</span>test.go:9<span class="o">)</span><span class="w"> </span>MOVL<span class="w"> </span><span class="nv">$2</span>,<span class="w"> </span>AX<span class="w">
  </span><span class="o">(</span>test.go:9<span class="o">)</span><span class="w"> </span>MOVL<span class="w"> </span><span class="nv">$3</span>,<span class="w"> </span>BX<span class="w">
  </span><span class="o">(</span>test.go:9<span class="o">)</span><span class="w"> </span>CALL<span class="w"> </span>main.add<span class="o">(</span>SB<span class="o">)</span><span class="w">
  </span><span class="c1"># result is in AX</span></pre><p><a href="https://go.dev/doc/asm">https://go.dev/doc/asm</a></p><div class="notes"><p>Important: There are many assembler dialects for many ISA. This is a IR.
Also Important: Explain registers!</p><p>Can we just say: To make things faster you have to reduce the number of instructions?</p><p>Sadly no. Modern CPUs are MUCH complexer than machines that sequentially execute instructions.
They take all kind of shortcuts to execute things faster - most of the time.
See also: Megaherz myth (-&gt; higher clock = more cycles per time)</p><p>Effects that may play a role</p><ul><li>Not every instruction takes the same amount of cycles (MOV 1 cycle,</li><li>Pipelining</li><li>Superscalar Execution</li><li>Branch prediction / Cache prefetching</li><li>Out-of-order execution</li><li>Cache misses (fetching from main memory)</li></ul><p>List of typical cycles per instructions ("latency"): <a href="https://www.agner.org/optimize/instruction_tables.pdf">https://www.agner.org/optimize/instruction_tables.pdf</a></p></div></div><div class="step step-level-1" step="10" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="27500" data-y="0" data-z="0"><h1 id="von-neumann-architecture">Von-Neumann Architecture</h1><img src="images/vn_cpu.png" width="100%"></img><div class="notes"><p>Von Neumann Computer: Memory contains data and code.
CPU adresses memory as whole and can address I/O device the same way
over a bus system.</p><p>Greatly simplified.</p><ul><li>Clocked with a certain frequency.</li><li>A cycle is the basic work synchronization.</li><li>Registers for internal usage. (CPUs have more than x86 says)</li><li>Peripherals look to the CPU like memory.</li></ul><p>Intel 8086 kinda worked this way.</p></div></div><div class="step step-level-1" step="11" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="30000" data-y="0" data-z="0"><h1 id="single-instruction-pipeline">Single instruction pipeline</h1><img src="images/pipeline.png" width="70%"></img><ol><li><strong>Load:</strong> Instruction gets loaded (<tt>0x012345</tt>)</li><li><strong>Decode:</strong> Check type/args of instruction.</li><li><strong>Memory:</strong> Load data from memory (if necessary)</li><li><strong>Execute:</strong> Calculate (e.g. add 2+3 in the ALU)</li><li><strong>Write back:</strong> Save result in some register.</li></ol><div class="notes"><p>This would need 5 cycles per instruction.
You kinda assumed, that one cycle is one instruction, did you?</p></div></div><div class="step step-level-1" step="12" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="32500" data-y="0" data-z="0"><h1 id="pipelining-ooo-superscalar-wtf">Pipelining, OoO, Superscalar, wtf?</h1><ul><li><strong>Pipelining:</strong> The 5 steps get done in parallel.</li><li><strong>Out-of-Order:</strong>  Instructions get re-ordered.</li><li><strong>Superscalar:</strong> Several instructions per cycle (~5x)</li></ul><p><em>Ergo:</em></p><ul><li>1 Cycle &#x2260; 1 instruction.</li><li>CPU might do unnecessary work!</li><li>Reducing instructions alone does not get us far.</li></ul><div class="notes"><ul><li>Every instruction needs to do all 5 steps</li><li>Modern CPUs can work on many instructions at the same time</li><li>They can be also re-ordered by the CPU! (think of a queue that gets reordered)</li><li>This can lead to issues when an instruction depends on results of another instructions! (branches!)</li><li>It can even happen that we do unncessary work!
This made the SPECTRE and MELTDOWN security issues possible that made cloud computing 20% slower over night.</li><li>CPUs can also execute more than one instruction per cycle (e.g. one MOV, ADD, CMP, as they all use different parts of the CPU)
(Superscalar CPUs)</li><li>This is the reason why focussing on reducing the number of instructions alone is not
too helpful when optimizing.</li></ul><p><a href="https://de.wikipedia.org/wiki/Pipeline_(Prozessor">https://de.wikipedia.org/wiki/Pipeline_(Prozessor</a>)</p></div></div><div class="step step-level-1" step="13" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="35000" data-y="0" data-z="0"><h1 id="disclaimer-cpu-effects">Disclaimer: CPU effects</h1><ul><li>Modern CPUs are insanely complex (like humans).</li><li>Compilers are insanely smart (unlike humans).</li><li>This tandem is probably smarter than you and me.
The following slides are mostly for educational purpose.
Trust the compiler in 95% of the time.</li><li>Still helpful to know what happens in the 5%.</li></ul></div><div class="step step-level-1" step="14" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="37500" data-y="0" data-z="0"><h1 id="branch-prediction">Branch prediction</h1><pre class="highlight code c"><span class="c1">// NOTE: works only in C/C++
</span><span class="k">if</span><span class="p">(</span><span class="n">likely</span><span class="p">(</span><span class="n">a</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="c1">// ...
</span><span class="p">}</span><span class="w">

</span><span class="c1">// Branch mis-prediction are very costly!
// ~20 - ~35 cycles can be lost per miss.
</span><span class="k">if</span><span class="p">(</span><span class="n">unlikely</span><span class="p">(</span><span class="n">err</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="c1">// ...
</span><span class="p">}</span></pre><div class="notes"><p>Modern cpus guess what branch is taken due to pipelining. The accuracy is done to 96%,
they even use neural networks for that.</p><p>No likely() in Go, compiler tries to insert those hints automayically.
Not much of an important optimization nowadays though as CPUs get a lot better:</p><p><a href="https://de.wikipedia.org/wiki/Sprungvorhersage">https://de.wikipedia.org/wiki/Sprungvorhersage</a></p><p>(but can be relevant for very hot paths on cheap ARM cpus)</p><p>Penalty Source: <a href="https://users.elis.ugent.be/~leeckhou/papers/ispass06-eyerman.pdf">https://users.elis.ugent.be/~leeckhou/papers/ispass06-eyerman.pdf</a></p></div></div><div class="step step-level-1" step="15" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="40000" data-y="0" data-z="0"><h1 id="can-we-observe-it">Can we observe it?</h1><pre class="highlight code go"><span class="c1">// Which loop runs faster?</span><span class="w">
</span><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="p">&lt;</span><span class="w"> </span><span class="nx">N</span><span class="p">;</span><span class="w"> </span><span class="nx">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">unsorted</span><span class="p">[</span><span class="nx">i</span><span class="p">]</span><span class="w"> </span><span class="p">&lt;</span><span class="w"> </span><span class="nx">X</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nx">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nx">unsorted</span><span class="p">[</span><span class="nx">i</span><span class="p">];</span><span class="w">
    </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="p">&lt;</span><span class="w"> </span><span class="nx">N</span><span class="p">;</span><span class="w"> </span><span class="nx">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">sorted</span><span class="p">[</span><span class="nx">i</span><span class="p">]</span><span class="w"> </span><span class="p">&lt;</span><span class="w"> </span><span class="nx">X</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nx">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nx">sorted</span><span class="p">[</span><span class="nx">i</span><span class="p">];</span><span class="w">
    </span><span class="p">}</span><span class="w">
</span><span class="p">}</span></pre><p class="example">Example: code/branchpredict</p><div class="notes"><p>Effect is unnotice-able if optimizations are enabled.
Why? Compilers can make the inner branch a branchless statement.</p></div></div><div class="step step-level-1" step="16" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="42500" data-y="0" data-z="0"><h1 id="profile-guided-optimization">Profile Guided Optimization</h1><img src="images/pgo.png" width="80%"></img><div class="notes"><p>Idea:</p><ul><li>Let program run in analysis mode.</li><li>Capture data about what branches were hit how often.</li><li>Use this data on the next compile to decide which branch is likely!</li></ul><p>Feature is available as part of Go 1.20
and since around 20 years as part of GCC/clang</p><p>Also decides on where to inline functions.</p><p><a href="https://tip.golang.org/doc/pgo">https://tip.golang.org/doc/pgo</a></p><p>Old news for languages like C.</p></div></div><div class="step step-level-1" step="17" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="45000" data-y="0" data-z="0"><h1 id="branchless-programming">Branchless programming</h1><pre class="highlight code c"><span class="c1">// Don't optimize this at home, kids.
// Your compiler does this for you.
</span><span class="kt">uint32_t</span><span class="w"> </span><span class="nf">max</span><span class="p">(</span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="k">if</span><span class="p">(</span><span class="n">a</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="k">return</span><span class="w"> </span><span class="n">a</span><span class="p">;</span><span class="w">
    </span><span class="p">}</span><span class="w">
    </span><span class="k">return</span><span class="w"> </span><span class="n">b</span><span class="p">;</span><span class="w">
</span><span class="p">}</span></pre><pre class="highlight code c"><span class="c1">// variant 1; not possible in Go:
</span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">a</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="o">!</span><span class="p">(</span><span class="n">a</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">;</span><span class="w">

</span><span class="c1">// variant 2; possible in Go:
</span><span class="k">return</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="p">(</span><span class="n">a</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">b</span><span class="p">)</span></pre><div class="notes"><p>Not relevant, as the compiler will optimize this for you in most cases
by using branchless code.</p><p>It can be however a life safer in hot loops if the compiler does not know.
Always check the assembly output if unsure.</p><p><a href="https://gcc.godbolt.org/#%7B%22version%22%3A3%2C%22filterAsm%22%3A%7B%22labels%22%3Atrue%2C%22directives%22%3Atrue%2C%22commentOnly%22%3Atrue%2C%22intel%22%3Atrue%2C%22colouriseAsm%22%3Atrue%7D%2C%22compilers%22%3A%5B%7B%22source%22%3A%22%23include%20%3Calgorithm%3E%5Cnint%20max%28int%20x%2C%20int%20y%29%20%7B%5Cn%20%20return%20std%3A%3Amax%28x%2Cy%29%3B%5Cn%7D%5Cn%22%2C%22compiler%22%3A%22%2Fusr%2Fbin%2Fg%2B%2B-4.7%22%2C%22options%22%3A%22-O2%20-m32%20-march%3Dnative%22%7D%5D%7D">https://gcc.godbolt.org/#%7B%22version%22%3A3%2C%22filterAsm%22%3A%7B%22labels%22%3Atrue%2C%22directives%22%3Atrue%2C%22commentOnly%22%3Atrue%2C%22intel%22%3Atrue%2C%22colouriseAsm%22%3Atrue%7D%2C%22compilers%22%3A%5B%7B%22source%22%3A%22%23include%20%3Calgorithm%3E%5Cnint%20max%28int%20x%2C%20int%20y%29%20%7B%5Cn%20%20return%20std%3A%3Amax%28x%2Cy%29%3B%5Cn%7D%5Cn%22%2C%22compiler%22%3A%22%2Fusr%2Fbin%2Fg%2B%2B-4.7%22%2C%22options%22%3A%22-O2%20-m32%20-march%3Dnative%22%7D%5D%7D</a></p></div></div><div class="step step-level-1" step="18" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="47500" data-y="0" data-z="0"><h1 id="loop-unrolling-and-ilp">Loop unrolling and ILP</h1><p><em>ILP</em> = Instruction Level Parallelism</p><pre class="highlight code go"><span class="c1">// a loop is just a repeated if condition:</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="nx">idx</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="nx">idx</span><span class="w"> </span><span class="p">&lt;</span><span class="w"> </span><span class="mi">3</span><span class="p">;</span><span class="w"> </span><span class="nx">idx</span><span class="o">++</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nx">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nx">sin</span><span class="p">(</span><span class="nx">idx</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="c1">// same, but no "idx &lt; 3" needed:</span><span class="w">
</span><span class="c1">// (can be computed in parallel!)</span><span class="w">
</span><span class="nx">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nx">sin</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w">
</span><span class="nx">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nx">sin</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w">
</span><span class="nx">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nx">sin</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span></pre><div class="notes"><ul><li>A for loop is just a repeated branch condition.</li><li>Compilers unroll simple loops.</li><li>If they don't hand unrolling can be useful (very seldom!)</li></ul><p>Example with interdependent code will not work as good:</p><pre class="highlight code go"><span class="nx">v</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="mi">1234</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="nx">v</span><span class="w"> </span><span class="p">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nx">digit</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">v</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">10</span><span class="w">
    </span><span class="nx">v</span><span class="w"> </span><span class="o">/=</span><span class="w"> </span><span class="mi">10</span><span class="w">
</span><span class="p">}</span></pre></div></div><div class="step step-level-1" step="19" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="50000" data-y="0" data-z="0"><h1 id="just-use-less-instructions">Just use less instructions?</h1><pre class="highlight code c"><span class="c1">// How to reduce the number of instructions?
</span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="nf">memcpy_basic</span><span class="p">(</span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">dst</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="k">for</span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="n">dst</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">src</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w">
    </span><span class="p">}</span><span class="w">
    </span><span class="k">return</span><span class="w"> </span><span class="n">dst</span><span class="p">;</span><span class="w">
</span><span class="p">}</span></pre><p class="example">Example: code/memcpy</p><div class="notes"><p>-&gt; Problem: von-Neumann-Bottleneck.
-&gt; CPU can work on data faster than typical RAM can deliver it.
-&gt; Workaround: Caches in the CPU, Prefetching.
-&gt; Actual solution: Data oriented design.
-&gt; Sequential access, tight packing of data, SIMD (and if you're crazy: DMA)
-&gt; Still best way to speed up copies: don't copy.</p><p>Object oriented design tends to fuck this up and many Games (at their core)
do not use OOP. You can use both at the same time though!</p></div></div><div class="step step-level-1" step="20" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="52500" data-y="0" data-z="0"><h1 id="simd">SIMD</h1><img src="images/simd.png" width="100%"></img><p><a href="https://github.com/mmcloughlin/avo">https://github.com/mmcloughlin/avo</a></p><div class="notes"><p>SISD = Single Instruction / Single Data
SIMD = Single Instruction / Multiple Data</p><p>Can be really worth the effort, since compilers can't figure out
all cases where SIMD can be used.</p><p>Example use cases:</p><ul><li>Image computation (i.e. changing brightness of several pixels at once)</li><li>Math operations like vector / matrix multiplications.</li><li>Audio/DSP processing.</li></ul><p>Disadvantage: Code gets ugly, hard to maintain and has additional obstacles
to solve like memory alignment. Also freaking complicated, which is why
we won't go into detail. Read up more here if you really want to:</p><p><a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data">https://en.wikipedia.org/wiki/Single_instruction,_multiple_data</a></p></div></div><div class="step step-level-1" step="21" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="55000" data-y="0" data-z="0"><h1 id="optimization-inlining">Optimization: Inlining</h1><img src="diagrams/2_inlining.svg" width="130%"></img><div class="notes"><p>Inlining functions can speed up things at the cost of increased ELF size.</p><p>Advantage: Parameters do not need to get copied, but CPU can re-use whatever
is in the registers alreadys. Also return values do not need to be copied.</p><p>Only done for small functions and only in hot paths.</p></div></div><div class="step step-level-1" step="22" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="57500" data-y="0" data-z="0"><h1 id="i-like-to-mov-mov-it">I like to MOV, MOV it</h1><pre class="highlight code asm"><span class="c1"># General syntax:
# MOV &lt;dst&gt;,&lt;src&gt;
</span><span class="w">
</span><span class="c1"># Possible:
</span><span class="nf">MOV</span><span class="w"> </span><span class="no">reg1</span><span class="p">,</span><span class="w"> </span><span class="mi">1234</span><span class="w">
</span><span class="nf">MOV</span><span class="w"> </span><span class="no">reg1</span><span class="p">,</span><span class="w"> </span><span class="no">reg2</span><span class="w">
</span><span class="nf">MOV</span><span class="w"> </span><span class="no">reg1</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="mi">1234</span><span class="p">]</span><span class="w">
</span><span class="nf">MOV</span><span class="w"> </span><span class="p">[</span><span class="mi">1234</span><span class="p">],</span><span class="w"> </span><span class="no">reg1</span><span class="w">
</span><span class="nf">MOV</span><span class="w"> </span><span class="p">[</span><span class="no">reg2</span><span class="p">],</span><span class="w"> </span><span class="no">reg1</span><span class="w">

</span><span class="c1"># Not possible:
</span><span class="nf">MOV</span><span class="w"> </span><span class="p">[</span><span class="mi">1234</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">4321</span><span class="p">]</span></pre><div class="notes"><p>How does access to main memory work? By using the MOV instruction.
And MOV from main memory is very costly:
Access to main memory is 125ns, L1 cache is ~1ns</p><p>Fun fact: MOV alone is Turing complete: <a href="https://github.com/xoreaxeaxeax/movfuscator">https://github.com/xoreaxeaxeax/movfuscator</a></p><p>TODO: Move this slide a bit before cache lines?</p></div></div><div class="step step-level-1" step="23" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="60000" data-y="0" data-z="0"><h1 id="von-neumann-bottleneck">von Neumann Bottleneck</h1><img src="diagrams/2_bottleneck.svg" width="100%"></img><div class="notes"><p>von Neumann Architektur:</p><ul><li>Computer Architecture where there is common memory accessible by all cores</li><li>Memory contains Data as well as code instructions</li><li>All data/code goes over a common bus</li><li>Pretty much all computer nowadays are build this way</li></ul><p>Bottleneck: Memory acess is much slower than CPUs can process the data.</p></div></div><div class="step step-level-1" step="24" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="62500" data-y="0" data-z="0"><h1 id="just-add-some-caches">Just add some caches!</h1><img src="images/whatcouldgowrong.jpeg"></img><div class="notes"><p>Good example of our industry really.</p><p>Instead of fixing an issue we wrap layers aorund it
until we just don't see the problem. But we never fix it.</p></div></div><div class="step step-level-1" step="25" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="65000" data-y="0" data-z="0"><h1 id="l1-l2-l3">L1, L2, L3</h1><img src="images/l1l2l3.png" width="70%"></img></div><div class="step step-level-1" step="26" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="67500" data-y="0" data-z="0"><h1 id="cache-lines-64b">Cache lines (64B)</h1><img src="diagrams/2_cache_line.svg" width="100%"></img><div class="notes"><p>Minimal line size is 64 byte!
It can only be written and evicted as one.
No partial reads or writes possible.
(Reason: adress space would be too big otherwise)</p><p>Some platforms have different cache lines and future CPUs might change too.
So instead on relying on the magic 64 you should use some const or cpu.CacheLinePad.</p></div></div><div class="step step-level-1" step="27" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="70000" data-y="0" data-z="0"><h1 id="caches-misses">Caches misses</h1><p class="example">Example: code/counter (1-3)</p><pre class="highlight code bash"><span class="c1"># Use this to check your cache miss count:
</span>$<span class="w"> </span>perf<span class="w"> </span>stat<span class="w"> </span>-p<span class="w"> </span>&lt;PID&gt;</pre><div class="notes"><p><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance</a>
<a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/overview-of-performance-monitoring-options_monitoring-and-managing-system-status-and-performance">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/overview-of-performance-monitoring-options_monitoring-and-managing-system-status-and-performance</a></p></div></div><div class="step step-level-1" step="28" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="72500" data-y="0" data-z="0"><h1 id="struct-size-matters">(Struct) size matters!</h1><pre class="highlight code go"><span class="c1">// Quiz: How big is this struct?</span><span class="w">
</span><span class="kd">type</span><span class="w"> </span><span class="nx">XXX</span><span class="w"> </span><span class="kd">struct</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nx">A</span><span class="w"> </span><span class="kt">int64</span><span class="w">
    </span><span class="nx">B</span><span class="w"> </span><span class="kt">uint32</span><span class="w">
    </span><span class="nx">C</span><span class="w"> </span><span class="kt">byte</span><span class="w">
    </span><span class="nx">D</span><span class="w"> </span><span class="kt">bool</span><span class="w">
    </span><span class="nx">E</span><span class="w"> </span><span class="kt">string</span><span class="w">
    </span><span class="nx">F</span><span class="w"> </span><span class="p">[]</span><span class="kt">byte</span><span class="w">
    </span><span class="nx">G</span><span class="w"> </span><span class="kd">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="kt">int64</span><span class="w">
    </span><span class="nx">H</span><span class="w"> </span><span class="kd">interface</span><span class="p">{}</span><span class="w">
    </span><span class="nx">I</span><span class="w"> </span><span class="kt">int</span><span class="w">
</span><span class="p">}</span></pre></div><div class="step step-level-1" step="29" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="75000" data-y="0" data-z="0"><h1 id="what-s-padding">What's padding?</h1><pre class="highlight code go"><span class="nx">x</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">XXX</span><span class="p">{}</span><span class="w">         </span><span class="c1">// measured with Go 1.20!</span><span class="w">
</span><span class="nx">s</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">unsafe</span><span class="p">.</span><span class="nx">Sizeof</span><span class="w"> </span><span class="c1">//</span><span class="w">
</span><span class="nb">println</span><span class="p">(</span><span class="nx">s</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">A</span><span class="p">))</span><span class="w">    </span><span class="c1">// 8 int64</span><span class="w">
</span><span class="nb">println</span><span class="p">(</span><span class="nx">s</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">B</span><span class="p">))</span><span class="w">    </span><span class="c1">// 4 uint32</span><span class="w">
</span><span class="nb">println</span><span class="p">(</span><span class="nx">s</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">C</span><span class="p">))</span><span class="w">    </span><span class="c1">// 1 byte</span><span class="w">
</span><span class="nb">println</span><span class="p">(</span><span class="nx">s</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">D</span><span class="p">))</span><span class="w">    </span><span class="c1">// 1 bool</span><span class="w">
                   </span><span class="c1">// +2 padding</span><span class="w">
</span><span class="nb">println</span><span class="p">(</span><span class="nx">s</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">E</span><span class="p">))</span><span class="w">    </span><span class="c1">// 16 string (ptr+len)</span><span class="w">
</span><span class="nb">println</span><span class="p">(</span><span class="nx">s</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">F</span><span class="p">))</span><span class="w">    </span><span class="c1">// 24 slice (ptr+len+cap)</span><span class="w">
</span><span class="nb">println</span><span class="p">(</span><span class="nx">s</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">G</span><span class="p">))</span><span class="w">    </span><span class="c1">// 8 map (ptr)</span><span class="w">
</span><span class="nb">println</span><span class="p">(</span><span class="nx">s</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">H</span><span class="p">))</span><span class="w">    </span><span class="c1">// 16 iface (ptr+typ)</span><span class="w">
</span><span class="nb">println</span><span class="p">(</span><span class="nx">s</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">I</span><span class="p">))</span><span class="w">    </span><span class="c1">// 8 int</span><span class="w">
                   </span><span class="c1">// Sum: 86</span><span class="w">
</span><span class="nb">println</span><span class="p">(</span><span class="nx">s</span><span class="p">(</span><span class="nx">x</span><span class="p">))</span><span class="w">      </span><span class="c1">// 88 (not 86!)</span></pre><div class="notes"><p>If a struct is bigger than a cache line, then accessing .A and .I
would cause the CPU to always require to get a new cache line!</p><p>Keep your structures under 64 bytes at max. Even less is better,
aim to stay under 32 byte.</p><p>Some more background info regarding why the value needs to be padded
can be found here (i.e. instructions require proper alignment):</p><p><a href="https://go101.org/article/memory-layout.html">https://go101.org/article/memory-layout.html</a></p></div></div><div class="step step-level-1" step="30" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="77500" data-y="0" data-z="0"><pre class="highlight code go"><span class="kd">var</span><span class="w"> </span><span class="nx">data</span><span class="w"> </span><span class="p">[</span><span class="mi">100</span><span class="p">]</span><span class="nx">XXX</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="nx">_</span><span class="p">,</span><span class="w"> </span><span class="nx">elem</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="k">range</span><span class="w"> </span><span class="nx">data</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="c1">// 100 cache misses (at least)!</span><span class="w">
    </span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="nx">elem</span><span class="p">.</span><span class="nx">A</span><span class="p">,</span><span class="w"> </span><span class="nx">elem</span><span class="p">.</span><span class="nx">I</span><span class="p">)</span><span class="w">
</span><span class="p">}</span></pre><pre class="highlight code bash"><span class="c1"># How big is a cache line?
</span>$<span class="w"> </span>lscpu<span class="w"> </span>--caches</pre><div class="notes"><p>Good article with a slightly different (and more realworld) example:</p><p><a href="https://www.ardanlabs.com/blog/2023/07/getting-friendly-with-cpu-caches.html">https://www.ardanlabs.com/blog/2023/07/getting-friendly-with-cpu-caches.html</a></p></div></div><div class="step step-level-1" step="31" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="80000" data-y="0" data-z="0"><h1 id="binary-size-matters">(Binary) size matters!</h1><ul><li>More debug symbols, functions, lookup tables and instructions make the binary bigger.</li><li>A process needs <em>at least</em> as much memory as the binary size (<em>Caveat:</em> only the first one)</li><li>The bigger the binary, the longer the startup time. Important for shortlived processes/bootup (scripts!)</li><li>CPUs have separate caches for code instructions. If your program is so fat that that the caches get evicted while jumping
between two functions, then you pay with performance.</li></ul><p class="small">&#xBB;<em>Yo binary is so fat, you see it on Google Earth!</em> &#x1F30D;&#xAB;</p><div class="notes"><p>Binaries can be compressed with UPX, but that does make start up time faster - contrary to that.</p><p>Also, in the embedded world the binary size is way more important, but 30M binaries seem excessive
even on servers. Go is doing a bad job here while Rust produces tiny outputs.</p></div></div><div class="step step-level-1" step="32" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="82500" data-y="0" data-z="0"><h1 id="binary-sizes-per-language">Binary sizes per language</h1><p>(for a &#xBB;<em>Hello world!</em>&#xAB;)</p><img src="images/binary_sizes.png" width="100%"></img><div class="notes"><p>Source: <a href="https://drewdevault.com/2020/01/04/Slow.html">https://drewdevault.com/2020/01/04/Slow.html</a></p></div></div><div class="step step-level-1" step="33" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="85000" data-y="0" data-z="0"><h1 id="detour-perf-command">Detour: perf command</h1><pre class="highlight code bash"><span class="c1"># Like `time` but much better.
</span>$<span class="w"> </span>perf<span class="w"> </span>stat<span class="w"> </span>-a<span class="w"> </span>&lt;command&gt;<span class="w">
</span>$<span class="w"> </span>perf<span class="w"> </span>stat<span class="w"> </span>-a<span class="w"> </span>-p<span class="w"> </span>&lt;PID&gt;<span class="w">

</span><span class="c1"># See where the system spends time now:
</span>$<span class="w"> </span>perf<span class="w"> </span>top<span class="w">

</span><span class="c1"># Detailed report about memory access / misses
</span>$<span class="w"> </span>perf<span class="w"> </span>mem<span class="w"> </span>record<span class="w"> </span>-a<span class="w"> </span>./counter<span class="w"> </span>atomic<span class="w">
</span>$<span class="w"> </span>perf<span class="w"> </span>mem<span class="w"> </span>-t<span class="w"> </span>load<span class="w"> </span>report<span class="w"> </span>--sort<span class="o">=</span>mem<span class="w">

</span><span class="c1"># Can find false sharing (see next chapter)
</span>$<span class="w"> </span>perf<span class="w"> </span>c2c</pre></div><div class="step step-level-1" step="34" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="87500" data-y="0" data-z="0"><h1 id="detour-pprof">Detour: <tt>pprof</tt></h1><img src="images/dashboard_pprof_preview.png" width="100%"></img><pre class="highlight code bash"><span class="c1"># simple:
</span>$<span class="w"> </span>go<span class="w"> </span><span class="nb">test</span><span class="w"> </span>-v<span class="w"> </span>-cpuprofile<span class="o">=</span>cpu.pprof<span class="w"> </span>-memprofile<span class="o">=</span>mem.pprof<span class="w">
</span>$<span class="w"> </span>go<span class="w"> </span>tool<span class="w"> </span>pprof<span class="w"> </span>./cpu.pprof</pre><pre class="highlight code go"><span class="c1">// permanently:</span><span class="w">
</span><span class="kn">import</span><span class="w"> </span><span class="nx">_</span><span class="w"> </span><span class="s">"net/http/pprof"</span><span class="w">
</span><span class="k">go</span><span class="w"> </span><span class="nx">http</span><span class="p">.</span><span class="nx">ListenAndServe</span><span class="p">(</span><span class="s">"localhost:3000"</span><span class="p">,</span><span class="w"> </span><span class="kc">nil</span><span class="p">)</span></pre><pre class="highlight code bash">$<span class="w"> </span>go<span class="w"> </span>tool<span class="w"> </span>pprof<span class="w"> </span>localhost:3000/debug/pprof/profile<span class="w">
</span>$<span class="w"> </span>go<span class="w"> </span>tool<span class="w"> </span>pprof<span class="w"> </span>localhost:3000/debug/pprof/heap</pre><p><a href="https://raw.githubusercontent.com/sahib/misc/master/performance/images/telemetry_pprof.svg">Profile of firmware's telemetry service</a></p><div class="notes"><p>Look at images/dashboard_pprof.svg here.</p><p>Pprof is also available for Python, but not as well integrated:
<a href="https://github.com/timpalpant/pypprof">https://github.com/timpalpant/pypprof</a></p></div></div><div class="step step-level-1" step="35" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="90000" data-y="0" data-z="0"><h1 id="detour-flame-graphs">Detour: Flame graphs</h1><img src="images/brig_flamegraph.png" width="80%"></img><pre class="highlight code go"><span class="nx">f</span><span class="p">,</span><span class="w"> </span><span class="nx">_</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">os</span><span class="p">.</span><span class="nx">Create</span><span class="p">(</span><span class="s">"/tmp/cpu.pprof"</span><span class="p">)</span><span class="w">
</span><span class="nx">pprof</span><span class="p">.</span><span class="nx">StartCPUProfile</span><span class="p">(</span><span class="nx">f</span><span class="p">)</span><span class="w">
</span><span class="k">defer</span><span class="w"> </span><span class="nx">pprof</span><span class="p">.</span><span class="nx">StopCPUProfile</span><span class="p">()</span></pre><pre class="highlight code bash">$<span class="w"> </span>go<span class="w"> </span>tool<span class="w"> </span>pprof<span class="w"> </span>-http<span class="o">=</span><span class="s2">":8000"</span><span class="w"> </span>&lt;binary&gt;<span class="w"> </span>/tmp/cpu.prof</pre><div class="notes"><p>Alternative for short lived programs:
make pprof record a profile.</p><p>See images/brig_flamegraph.png
See images/brig_flamegraph.html</p><p>Perfect to see what time is spend in in what symbol.
Available for:</p><ul><li>CPU</li><li>Memory Allocations (although I like pprof more here)</li><li>Off-CPU (i.e. I/O)</li></ul></div></div><div class="step step-level-1" step="36" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="92500" data-y="0" data-z="0"><h1 id="false-sharing">False sharing</h1><ul><li><strong>Problem:</strong> Unrelated data in the same cache line gets modified and thus cache line gets evicted.</li><li><strong>Solution:</strong> Add some padding!</li></ul><p class="example">Example code/counter (4)</p><div class="notes"><p>If a program modifies data, the responding cache line needs
to be evicted (unless the modification resulted from the currently
running program). This is called "cache eviction" in short.</p><p>If it happens because the data in the cache line was actually
changed, then all is good. Data needs to be fetched again from memory
which costs a bit of time.</p><p>But what if two data points just happen to be in the same cache line?
Imagine two int64 counters that get incremented by two separate threads.
They do not talk to each other and should be influenced by each other.
However, each increment evicts the cache line and causes a slowdown.
We can use padding to force each counter into a separate cache line.</p></div></div><div class="step step-level-1" step="37" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="95000" data-y="0" data-z="0"><h1 id="true-sharing">True sharing</h1><ul><li><strong>Situation:</strong> Closely related data lands in the same cache line.</li><li><strong>Effect:</strong> Less jumping, less memory loads, higher throughput.</li><li><strong>Trick:</strong> Structs &lt; 64 byte and being cache friendly.</li></ul><p class="example">Example: code/striding</p><div class="notes"><p>This is when the idea of introducing caches between CPU and memory works out.
Good news: Can be controlled by:</p><ul><li>Limiting struct sizes to 64 bytes</li><li>Grouping often accessed data together.
(arrays of data, not array of structs of data)</li></ul><p>A bad example of this are linked lists. The next node is usually somewhere else
in memory and the size of a single node is below 64 bytes. This results in cache lines
that are mostly loaded for no reason. One solution would be to design cache-friendly linked
list by packing more data into the node itself.</p></div></div><div class="step step-level-1" step="38" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="97500" data-y="0" data-z="0"><h1 id="typical-access-patterns">Typical Access patterns</h1><img src="images/access_patterns.png" width="100%"></img><div class="line-block"><br></br></div><div class="notes"><p><em>Learning:</em> Group data in a CPU friendly way. Prefer <em>Struct of Arrays</em> over
<em>Array of Structs</em> if you require a performance boost.</p></div></div><div class="step step-level-1" step="39" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="100000" data-y="0" data-z="0"><h1 id="aos-vs-soa">AoS vs SoA</h1><pre class="highlight code go"><span class="kd">var</span><span class="w"> </span><span class="nx">AoS</span><span class="w"> </span><span class="p">[]</span><span class="kd">struct</span><span class="p">{</span><span class="w"> </span><span class="c1">// ArrayOfStructures</span><span class="w">
    </span><span class="nx">A</span><span class="w"> </span><span class="kt">int</span><span class="w">
    </span><span class="nx">B</span><span class="w"> </span><span class="kt">int</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="kd">var</span><span class="w"> </span><span class="nx">SoA</span><span class="w"> </span><span class="kd">struct</span><span class="p">{</span><span class="w">   </span><span class="c1">// StructureOfArrays</span><span class="w">
    </span><span class="nx">A</span><span class="w"> </span><span class="p">[]</span><span class="kt">int</span><span class="w">
    </span><span class="nx">B</span><span class="w"> </span><span class="p">[]</span><span class="kt">int</span><span class="w">
</span><span class="p">}</span></pre><img src="images/struct_of_slices.png" width="90%"></img></div><div class="step step-level-1" step="40" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="102500" data-y="0" data-z="0"><h1 id="dataoriented-programming">Dataoriented programming</h1><p>The science of designing programs in a CPU friendly way.</p><img src="images/dop_book.png" width="50%"></img><div class="notes"><p>DOP is often mentioned as contrast to OOP, but both concepts can complement each other.</p><p>Object oriented program is designing the program in a way that is friendly to humans.</p><p>It does by encapsulating data and methods together. By coincidence, this is not exactly
helpful to the machine your program runs on. Why?</p><ul><li>global state (i.e. impure functions) make branch/cache predictions way harder.</li><li>hurts cache locality.</li></ul></div></div><div class="step step-level-1" step="41" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="105000" data-y="0" data-z="0"><h1 id="quiz-matrix-traversal">Quiz: Matrix Traversal</h1><pre class="highlight code c"><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">malloc</span><span class="p">(</span><span class="n">N_ROWS</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">N_COLS</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span></pre><img src="images/matrix_traversal.png" width="100%"></img><p class="example">Example: code/matrix</p><div class="notes"><p>What is faster? Traversing <tt>m</tt>...</p><ol><li>...row by row?</li><li>...column by column?</li></ol><p>Good picture source: <a href="https://medium.com/mirum-budapest/introduction-to-data-oriented-programming-85b51b99572d">https://medium.com/mirum-budapest/introduction-to-data-oriented-programming-85b51b99572d</a></p></div></div><div class="step step-level-1" step="42" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="107500" data-y="0" data-z="0"><h1 id="recursion-vs-iteration">Recursion vs Iteration</h1><ul><li>Recursion is elegant but can be expensive.</li><li>Make the recursive call the last thing in your function.</li><li>(&#xBB;Tailcall optimization&#xAB;)</li></ul><pre class="highlight code">BenchmarkSum/normal    286.7 ns/op
BenchmarkSum/tailcall  242.1 ns/op
BenchmarkSum/iterative  71.1 ns/op</pre><p class="example">Example: code/tailcall</p><div class="notes"><p>Recursive algorithms like quicksort or merge sort are relatively elegant
when writing as recursive function. Sadly, this results in some performance impact.</p><p>Why? Because function call have a certain overhead, as we will see in the next chapter.
This function overhead can be reduced if we place the recursive function call at the end
of the function. This allows a smart compiler to save some instructions. An even smarter
compiler (clang or gcc) might even able to convert the recursion function into its
iterative equivalent.</p><p>This is called "Tail call optimization": <a href="https://de.wikipedia.org/wiki/Endrekursion">https://de.wikipedia.org/wiki/Endrekursion</a></p></div></div><div class="step step-level-1" step="43" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="110000" data-y="0" data-z="0"><h1 id="virtual-funcs-interfaces">Virtual funcs &amp; Interfaces</h1><img src="images/interface.svg" width="60%"></img><p class="example">Example: code/cost_of_interface</p><div class="notes"><p>Interface calls have between 2x to 10x as much overhead as direct calls in Go.</p><p>Interfaces also have a space cost. A variable of type interface is basically
a pointer with 16 byte (Space!). It consists of two actual pointers: type
(pointing to a struct describing the type for reflection) and a pointer to
the actual data the interface points to. This is one indirection more, one
more cycle for the GC.</p><p>Also, interfaces are opaque to the compiler. It cannot reason about what
they could do, so they can not use inlining or do proper escape analysis and
instead allocate on the heap always.</p><p>More info: <a href="https://syslog.ravelin.com/go-interfaces-but-at-what-cost-961e0f58a07b">https://syslog.ravelin.com/go-interfaces-but-at-what-cost-961e0f58a07b</a></p><p>Now you could say: Ah, I don't use Go, all good. Well, pretty much all
languages that support OOP are affected by this kind of behaviour. Virtual
methods in C++ or Java have their price too: They need to lookup a vtable,
which adds some more instructions but most importantly hinders the compiler
to optimize further.</p><p>Since especially Java uses Getters and Setters a lot - which are just one-line
functions in most cases - they pay quite a penalty regarding performance.</p><p>Python is especially wild, since they just might do tons of dictionary lookups
if you use classes with a lot of inheritance.</p></div></div><div class="step step-level-1" step="44" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="112500" data-y="0" data-z="0"><h1 id="boundcheck-elimination">Boundcheck Elimination</h1><p>Help the compiler!</p><p class="example">Example: code/boundscheck</p><div class="notes"><p>In a memory-safe language all access to slices are checked
(and if out-of-bound, an language panic/exception is produced)</p><p>This is a very small price to pay for the safety, but it costs
a few instructions.</p><p>More infos can be found here:
<a href="https://go101.org/article/bounds-check-elimination.html">https://go101.org/article/bounds-check-elimination.html</a></p></div></div><div class="step step-level-1" step="45" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="115000" data-y="0" data-z="0"><h1 id="process-scheduler">Process scheduler</h1><p><strong>Context switch:</strong></p><ul><li><em>Before execution:</em> Load register state from RAM.</li><li><em>After execution:</em> Store register state in RAM.</li></ul><img src="images/process_states.webp" width="50%"></img><div class="notes"><p>We're not alone on a system. Every process get assigned a share of time that it may execute.</p><p>-&gt; Expensive. Switching too often is expensive.</p><ul><li>scheduler types (O(n), O(1), CFS, BFS)</li><li>scheduler is determined at compile time.</li><li>there are some knobs to tune the scheduler, but not that interesting.</li><li>Show process states with ps a.</li></ul></div></div><div class="step step-level-1" step="46" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="117500" data-y="0" data-z="0"><h1 id="process-load">Process load</h1><p><strong>Load:</strong> Count of processes currently in running or waiting state.</p><p><span class="math ">\(load_{now} = \begin{cases}N_{count} = 0\:\:\:\:\:\:\:\:\:\iff\textrm{Idle}\\N_{count} &lt; N_{cores}\iff\textrm{Normal}\\N_{count}\ge N_{cores}\iff\textrm{Overload}\end{cases}\)</span></p><div class="notes"><p>The load metric makes most sense if averaged over some time.</p><p>Those are the load5/load10/load15 params.
Use load5 for graphs, load15 for quick judgmenet.</p><p>You can use the "uptime" command to check the load.</p></div></div><div class="step step-level-1" step="47" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="120000" data-y="0" data-z="0"><h1 id="process-niceness">Process niceness</h1><p><em>Niceness</em> is the scheduling priority.</p><ul><li>Ranges from <span class="math ">\(-20\)</span> to <span class="math ">\(+19\)</span>; <span class="math ">\(0\)</span> is default.</li><li><span class="math ">\(-20\)</span> gives the process more time to execute.</li><li><span class="math ">\(+19\)</span> gives the process way less to execute.</li></ul><pre class="highlight code bash"><span class="c1"># for new processes: sleep with high prio
</span>$<span class="w"> </span>nice<span class="w"> </span>-n<span class="w"> </span>-20<span class="w"> </span>sleep<span class="w"> </span>5s<span class="w">

</span><span class="c1"># for running processes: change to unimportant
</span>$<span class="w"> </span>renice<span class="w"> </span>-n<span class="w"> </span>+19<span class="w"> </span><span class="k">$(</span>pgrep<span class="w"> </span>docker<span class="k">)</span></pre><div class="notes"><p>Disclaimer: Exact behaviour depends on scheduler (scheduling frequency vs
time slice size)</p></div></div><div class="step step-level-1" step="48" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="122500" data-y="0" data-z="0"><h1 id="rough-rules-to-take-away">Rough Rules to take away</h1><ol><li>Watch out for cache misses.</li><li>Keep your structs small (&lt; 64B).</li><li>Check if you need padding (false sharing).</li><li>Place often accessed data close (true sharing).</li><li>Design your access patterns cache friendly.</li><li>Avoid virtual methods and inheritance.</li><li>Do not overuse pointers over values.</li><li>Trust your compiler, but check what it did.</li><li>Use SIMD if you have to; or leave it to others.</li></ol><div class="notes"><p>Go even warns about too structures (if they are used as values):
gocritic hugeParam: cfg is heavy (240 bytes); consider passing it by pointer</p><p>A good and very quick summary is also in this article
(although you need background info to understand the tips):</p><p><a href="https://medium.com/scum-gazeta/golang-simple-optimization-notes-70bc64673980">https://medium.com/scum-gazeta/golang-simple-optimization-notes-70bc64673980</a></p></div></div><div class="step step-level-1" step="49" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="125000" data-y="0" data-z="0"><h1 id="fynn">Fynn!</h1><div class="line-block"><br></br></div><p class="big-text">&#x1F3C1;</p><div class="line-block"><br></br></div><p class="next-link"><strong>Next:</strong> <a href="../3_memory/index.html">Memory</a>: Bookkeeping is hard &#x1F4DD;</p></div></div><div id="slide-number" class="slide-number">
         1
      </div><script type="text/javascript" src="js/impress.js"></script><script type="text/javascript" src="js/gotoSlide.js"></script><script type="text/javascript" src="js/hovercraft.js"></script><script type="text/javascript" src="hovercraft.js"></script><script type="text/javascript">
      document.getElementById("impress").addEventListener("impress:stepenter", update_slide_number, false);
    </script></body></html>