<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml"><head><title>Performance: I/O</title><meta charset="UTF-8"></meta><meta name="generator" content="Hovercraft! 1.0 http://regebro.github.io/hovercraft"></meta><link rel="stylesheet" href="css/hovercraft.css" media="all"></link><link rel="stylesheet" href="css/highlight.css" media="all"></link><link rel="stylesheet" href="hovercraft.css" media="screen,projection"></link><script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        showProcessingMessages: false,
        messageStyle: "none",
        TeX : { extensions : ['color.js'] }
      });
    </script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script></head><body class="impress-not-supported"><div id="impress-help"></div><div id="impress" data-transition-duration="1500"><div class="step step-level-1" step="0" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="0" data-y="0" data-z="0"><p class="chapter">I/O &amp; Syscalls</p><p>Speaking with the kernel &#x1F427;</p></div><div class="step step-level-1" step="1" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="1600" data-y="0" data-z="0"><h1 id="agenda">Agenda</h1><ul><li>How to store bits?</li><li>How does the kernel talk to the storage?</li><li>How can we do I/O over syscalls?</li><li>Profiling and benchmarking.</li><li>Some performance tips.</li></ul><img src="images/waterpipe.png" width="50%"></img></div><div class="step step-level-1" step="2" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="3200" data-y="0" data-z="0"><h1 id="typical-terms">Typical terms</h1><ul><li><em>Latency:</em> Time until the first drop of water arrives.</li><li><em>Throughput:</em> Current volume of water per time.</li><li><em>Bandwidth:</em> Maximum throughput.</li></ul><div class="line-block"><br></br><br></br></div><table cellpadding="0" cellspacing="0" class="colwidths-given"><thead><tr><th><p>Examples:</p></th><th><p><em>Low latency</em></p></th><th><p><em>High latency</em></p></th></tr></thead><tbody><tr><td><p><em>Low throughput</em></p></td><td><p><strong>SDCards</strong></p></td><td><p><strong>SSHFS</strong></p></td></tr><tr><td><p><em>High throughput</em></p></td><td><p><strong>SSD</strong></p></td><td><p><strong>HDD</strong></p></td></tr></tbody></table><div class="notes"><p>Fun fact: An extreme example of high latency with high throughput is IPoAC
(IP over Avian Carrier), i.e. sticking an USB stick on a homing pidgeon.
This was even standardized (jokingly):
<a href="https://en.wikipedia.org/wiki/IP_over_Avian_Carriers">https://en.wikipedia.org/wiki/IP_over_Avian_Carriers</a></p></div></div><div class="step step-level-1" step="3" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="4800" data-y="0" data-z="0"><h1 id="hardware-hdds">Hardware: HDDs</h1><img src="images/hdd.jpg" width="70%"></img><div class="line-block"><br></br></div><ul><li>Rotational, stacked disks with reading head.</li><li>Reading head needs to seek to the right position.</li><li>Elevator algorithm for ordering seeks.</li><li>Performance loss at high or low temperature.</li><li>Does not work if moved - bad for laptops.</li><li>Dying, but battled tested &amp; still widely used.</li></ul><div class="notes"><p>Big advantage: You could debug issues with too many seeks by audio!</p></div></div><div class="step step-level-1" step="4" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="6400" data-y="0" data-z="0"><h1 id="hardware-sdds">Hardware: SDDs</h1><img src="images/ssd.jpg" width="70%"></img><div class="line-block"><br></br></div><ul><li>NAND Flash technology (like USB sticks)</li><li>No expensive seek necessary.</li><li>Limited number of write cycles.</li><li>Becoming cheaper and better every year.</li></ul><div class="notes"><p>Write software for SSDs. There were some crazy tricks like FIEMAP to make
applications re-order their reads in the order of how they are placed on disk.
(Huge speedup on HDD, small speedup on SSD), but those will become pointless
more and more.</p></div></div><div class="step step-level-1" step="5" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="8000" data-y="0" data-z="0"><h1 id="ssd-write-amplification">SSD Write amplification</h1><img src="images/ssd_write_amplification.png" width="100%"></img><div class="notes"><p>Source: <a href="http://databasearchitects.blogspot.com/2021/06/what-every-programmer-should-know-about.html?m=1">http://databasearchitects.blogspot.com/2021/06/what-every-programmer-should-know-about.html?m=1</a></p><p>SSDs are divided into blocks (seveal MB), which are divided into pages (often 4K).
Pages cannot be erased, only blocks can be. Updates of a pages are written to new blocks.
If space runs out, old blocks with many stale pages are erased and can be re-used.
The number of physical writes is therefore higher than the number of logical writes.
The more space is used, the higher the write amplication factor though.</p><p>What we can do about it: Buy bigger SSDs than you need. Also avoid rewriting pages if possible.
Secret: SSD have some spare space to keep working they don't tell you about.</p><p>Also enable TRIM support if your OS did not yet, but nowadways always enabled.
This makes it possible for the OS to tell the SSD additional blocks that are not needed anymore.</p></div></div><div class="step step-level-1" step="6" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="9600" data-y="0" data-z="0"><h1 id="virtual-file-system">Virtual File System</h1><img src="images/vfs.webp" width="100%"></img><div class="notes"><p>Below device drivers: hardware controllers - beyond this talk.
They can also re-order writes and are mostly concerned with durability,
i.e. a SSD controller will try to distribute the blocks he used to make sure
they have a similar amount of write cycles.</p></div></div><div class="step step-level-1" step="7" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="11200" data-y="0" data-z="0"><h1 id="how-do-syscalls-work-1">How do syscalls work? (#1)</h1><pre class="highlight code c"><span class="c1">// Example: writing to a file
// as documented in glibc:
// ssize_t write(
//     int fd,           // file descriptor
//     const void buf[], // data
//     size_t count      // size of data
// );
</span><span class="n">write</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="s">"Hello world!</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="w"> </span><span class="mi">12</span><span class="p">);</span></pre></div><div class="step step-level-1" step="8" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="12800" data-y="0" data-z="0"><h1 id="how-do-syscalls-work-2">How do syscalls work? (#2)</h1><p>Compiled:</p><pre class="highlight code asm"><span class="c1">; use the `write` system call (1)
</span><span class="nf">movl</span><span class="w"> </span><span class="no">rax</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="w">
</span><span class="c1">; write to stdout (1) - 1st arg
</span><span class="nf">movl</span><span class="w"> </span><span class="no">rbx</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="w">
</span><span class="c1">; use string "Hello World" - 2nd arg
; (0x1234 is the addr of the "Hello World!\0")
</span><span class="nf">movl</span><span class="w"> </span><span class="no">rcx</span><span class="p">,</span><span class="w"> </span><span class="mi">0x1234</span><span class="w">
</span><span class="c1">; write 12 characters - 3rd arg
</span><span class="nf">movl</span><span class="w"> </span><span class="no">rdx</span><span class="p">,</span><span class="w"> </span><span class="mi">12</span><span class="w">
</span><span class="c1">; make system call via special instruction
</span><span class="nf">syscall</span><span class="w">
</span><span class="c1">; The return code is now in the RAX register.</span></pre><div class="notes"><p>All available syscalls and their ids are here: <a href="https://filippo.io/linux-syscall-table/">https://filippo.io/linux-syscall-table/</a></p><p>Only method of userspace to talk to kernel. How to call is ISA specific.</p><p>The syscall instruction performs a context switch: This means the current
state of the process (i.e. the state of all registers in the CPU) is saved
away, so it can be restored later. Once done, the kernel sets the register
to its needs, does whatever is required to serve the system call. When
finished, the process state is restored and execution continues.</p><p>Context switches also happen when you're not calling any syscalls.
Simply when the scheduler decide this process is done with execution.</p></div></div><div class="step step-level-1" step="9" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="14400" data-y="0" data-z="0"><h1 id="typical-syscalls">Typical syscalls</h1><ul><li>IO: <tt>read</tt>, <tt>write</tt>, <tt>close</tt></li><li>Files: <tt>stat</tt>, <tt>chmod</tt>, <tt>mkdir</tt></li><li>Memory: <tt>sbrk</tt>, <tt>mmap</tt></li><li>Processes: <tt>fork</tt>, <tt>kill</tt>, <tt>wait</tt></li><li>Network: <tt>listen</tt>, <tt>connect</tt>, <tt>epoll</tt></li><li>Mysterious: <tt>ioctl</tt>, <tt>chroot</tt>, <tt>mount</tt></li></ul><div class="notes"><p>Luckily for us, glibc and Go provide us nice names and interfaces to make those system calls.
They usually provide thin wrappers that also do some basic error checking. Watch out: <tt>fread</tt>
is doing buffering in userspace!</p><p>Can anyone think of another syscall not in the list above? exit! chdir ...
(There are about 300 of them)</p></div></div><div class="step step-level-1" step="10" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="16000" data-y="0" data-z="0"><h1 id="typical-read-i-o">Typical read I/O</h1><pre class="highlight code c"><span class="kt">char</span><span class="w"> </span><span class="n">buf</span><span class="p">[</span><span class="mi">1024</span><span class="p">];</span><span class="w">
</span><span class="kt">int</span><span class="w"> </span><span class="n">fd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">open</span><span class="p">(</span><span class="s">"/some/path"</span><span class="p">,</span><span class="w"> </span><span class="n">O_CREAT</span><span class="o">|</span><span class="n">O_RDONLY</span><span class="o">|</span><span class="n">O_TRUNC</span><span class="p">);</span><span class="w">
</span><span class="kt">size_t</span><span class="w"> </span><span class="n">bytes_read</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w">
</span><span class="k">while</span><span class="p">((</span><span class="n">bytes_read</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">read</span><span class="p">(</span><span class="n">fd</span><span class="p">,</span><span class="w"> </span><span class="n">buf</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">buf</span><span class="p">)))</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="cm">/* do something with buf[:bytes_read] */</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="n">close</span><span class="p">(</span><span class="n">fd</span><span class="p">);</span></pre><div class="notes"><p>Looks fairly straightforward and most of you might have written something like that already.
Maybe even for sockets or other streams. BUT here's the thing: every read needs one syscall
and all bytes from the file are copied to a userspace-supplied buffer. This model is flexible,
but costs performance. With mmap() and io_uring we will see options that can, sometimes,
work with zero copies.</p><p>Sidenote: Always be nice and close your file descriptors.
That has two reasons:</p><ul><li>You are only allowed a certain maximum of file descriptors per process.
(check with  ulimit -a for soft limits and ulimit -aH for hard limits)</li><li>If you write something to a file close will also flush file contents
that are not written to disk yet.</li></ul></div></div><div class="step step-level-1" step="11" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="17600" data-y="0" data-z="0"><h1 id="typical-write-i-o">Typical write I/O</h1><pre class="highlight code c"><span class="kt">char</span><span class="w"> </span><span class="n">buf</span><span class="p">[</span><span class="mi">1024</span><span class="p">];</span><span class="w">
</span><span class="kt">size_t</span><span class="w"> </span><span class="n">bytes_in_buf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w">
</span><span class="kt">int</span><span class="w"> </span><span class="n">fd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">open</span><span class="p">(</span><span class="s">"/some/path"</span><span class="p">,</span><span class="w"> </span><span class="n">O_CREAT</span><span class="o">|</span><span class="n">O_WRONLY</span><span class="o">|</span><span class="n">O_TRUNC</span><span class="p">);</span><span class="w">
</span><span class="k">do</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="cm">/* fill buf somehow with data you'd like to write,
     * set bytes_in_buf accordingly.
     */</span><span class="w">
</span><span class="p">}</span><span class="w"> </span><span class="k">while</span><span class="p">(</span><span class="n">write</span><span class="p">(</span><span class="n">fd</span><span class="p">,</span><span class="w"> </span><span class="n">buf</span><span class="p">,</span><span class="w"> </span><span class="n">bytes_in_buf</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w">
</span><span class="n">fsync</span><span class="p">(</span><span class="n">fd</span><span class="p">);</span><span class="w">
</span><span class="n">close</span><span class="p">(</span><span class="n">fd</span><span class="p">);</span></pre><div class="notes"><p>Q1: Does this mean that the data is available to read() when write() returned?
Q2: Is the data saved on disk after write() returns?</p><dl><dt>A1: Mostly. There might be exotic edge cases with non-POSIX filesystems,</dt><dd><p>but you should mostly be able to assume this.</p></dd><dt>A2: No. You should call fsync() to ensure that and even than, it is</dt><dd><p>sadly not guaranteed depending on the storage driver and hardware.
(Kernel has to rely on the hardware to acknowledge received data)</p></dd></dl><p>---</p><p>There is a bug here though:</p><p>write() returns the number of written bytes. It might be less than bytes_in_buf
and this is not counted as an error. The write call might have simply been
interrupted and we expect that it is called another time with the remaining data.
This only happens if your program uses POSIX signals that were not registed with
the SA_RESTART flag (see man 7 signal). Since it's default, it's mostly not an
issue in C.</p><p>Go hides this edgecase for you in normal likes fd.Write() or io.ReadAll().
However, the Go runtime uses plenty of signals and if you use the syscalls
package for some reason, then you might be hit by this kind of bug.
This does not affect only write() but also read() and many other syscalls.</p><p>Also please note: There is some error handling missing here.</p></div></div><div class="step step-level-1" step="12" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="19200" data-y="0" data-z="0"><h1 id="what-about-fread">What about <tt>fread()</tt>?</h1><p>Confusingly, this is double buffered.</p><p><strong>Usecases:</strong></p><ul><li>You need to read byte by byte.</li><li>You need to unread some bytes frequently.</li><li>You need to read easily line by line.</li></ul><p>Otherwise: Do not use.</p><div class="notes"><p>Userspace buffered functions. No real advantage, but limiting and confusing API.
Has some extra features like printf-style formatting.</p><p>In Go the normal read/write is using the syscall directly,
bufio is roughly equivalent to f{read,write} etc.
fsync() is a syscall, not part of that even though it starts with "f"</p></div></div><div class="step step-level-1" step="13" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="20800" data-y="0" data-z="0"><h1 id="syscalls-are-expensive">Syscalls are expensive</h1><pre class="highlight code bash">$<span class="w"> </span>dd<span class="w"> </span><span class="k">if</span><span class="o">=</span>/dev/urandom<span class="w"> </span><span class="nv">of</span><span class="o">=</span>./x<span class="w"> </span><span class="nv">bs</span><span class="o">=</span>1M<span class="w"> </span><span class="nv">count</span><span class="o">=</span><span class="m">1024</span><span class="w">
</span>$<span class="w"> </span>dd<span class="w"> </span><span class="k">if</span><span class="o">=</span>x<span class="w"> </span><span class="nv">of</span><span class="o">=</span>/dev/null<span class="w"> </span><span class="nv">bs</span><span class="o">=</span>1b<span class="w">
</span><span class="m">4</span>,07281<span class="w"> </span>s,<span class="w"> </span><span class="m">264</span><span class="w"> </span>MB/s<span class="w">
</span>$<span class="w"> </span>dd<span class="w"> </span><span class="k">if</span><span class="o">=</span>x<span class="w"> </span><span class="nv">of</span><span class="o">=</span>/dev/null<span class="w"> </span><span class="nv">bs</span><span class="o">=</span>32b<span class="w">
</span><span class="m">0</span>,255229<span class="w"> </span>s,<span class="w"> </span><span class="m">4</span>,2<span class="w"> </span>GB/s<span class="w">
</span>$<span class="w"> </span>dd<span class="w"> </span><span class="k">if</span><span class="o">=</span>x<span class="w"> </span><span class="nv">of</span><span class="o">=</span>/dev/null<span class="w"> </span><span class="nv">bs</span><span class="o">=</span>1024b<span class="w">
</span><span class="m">0</span>,136717<span class="w"> </span>s,<span class="w"> </span><span class="m">7</span>,9<span class="w"> </span>GB/s<span class="w">
</span>$<span class="w"> </span>dd<span class="w"> </span><span class="k">if</span><span class="o">=</span>x<span class="w"> </span><span class="nv">of</span><span class="o">=</span>/dev/null<span class="w"> </span><span class="nv">bs</span><span class="o">=</span>32M<span class="w">
</span><span class="m">0</span>,206027<span class="w"> </span>s,<span class="w"> </span><span class="m">5</span>,2<span class="w"> </span>GB/s</pre><p>Good buffer sizes: <span class="math ">\(1k - 32k\)</span></p><div class="notes"><p>Each syscall needs to store away the state of all registers in the CPU
and restore it after it finished. This is called "context switch".</p><p>Many syscalls vs a few big ones.</p><p>Try to reduce the number of syscalls,
but too big buffers hurt too.</p></div></div><div class="step step-level-1" step="14" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="22400" data-y="0" data-z="0"><h1 id="making-syscalls-visible">Making syscalls visible</h1><pre class="highlight code bash"><span class="c1"># (Unimportant output skipped)
</span>$<span class="w"> </span>strace<span class="w"> </span>ls<span class="w"> </span>-l<span class="w"> </span>/tmp<span class="w">
</span>openat<span class="o">(</span>AT_FDCWD,<span class="w"> </span><span class="s2">"/tmp"</span>,<span class="w"> </span>...<span class="o">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">4</span><span class="w">
</span>getdents64<span class="o">(</span><span class="m">4</span>,<span class="w"> </span>/*<span class="w"> </span><span class="m">47</span><span class="w"> </span>entries<span class="w"> </span>*/,<span class="w"> </span><span class="m">32768</span><span class="o">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2256</span><span class="w">
</span>...<span class="w">
</span>statx<span class="o">(</span>AT_FDCWD,<span class="w"> </span><span class="s2">"/tmp/file"</span>,<span class="w"> </span>...<span class="o">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="w">
</span>getxattr<span class="o">(</span><span class="s2">"/tmp/file"</span>,<span class="w"> </span>...<span class="o">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>-1<span class="w"> </span>ENODATA<span class="w">
</span>...<span class="w">
</span>write<span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="s2">"r-- 8 sahib /tmp/file"</span>,<span class="w"> </span>...<span class="o">)</span></pre><div class="notes"><p>Insanely useful tool to debug hanging tools
or tools that crash without a proper error message.
Usually the last syscall they do gives a hint.</p><p>Important options:</p><p>-c: count syscalls and stats at the end.
-f: follow also subprocesses.</p></div></div><div class="step step-level-1" step="15" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="24000" data-y="0" data-z="0"><h1 id="page-cache">Page cache</h1><img src="images/page-cache.png" width="100%"></img><div class="notes"><ul><li>All I/O access is cached using the page cache (dir + inode)</li><li>Free pages are used to store recently accessed file contents.</li><li>Performance impact can be huge.</li><li>Writes are asynchronous, i.e. synced later</li></ul><p>Good overview and more details here:
<a href="https://biriukov.dev/docs/page-cache/2-essential-page-cache-theory/">https://biriukov.dev/docs/page-cache/2-essential-page-cache-theory/</a></p></div></div><div class="step step-level-1" step="16" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="25600" data-y="0" data-z="0"><h1 id="caveat-writes-are-buffered">Caveat: Writes are buffered!</h1><pre class="highlight code bash"><span class="c1"># wait for ALL buffers to be flushed:
</span>$<span class="w"> </span>sync<span class="w">
</span><span class="c1"># pending data is now safely stored.</span></pre><pre class="highlight code c"><span class="c1">// wait for specific file to be flushed:
</span><span class="k">if</span><span class="p">(</span><span class="n">fsync</span><span class="p">(</span><span class="n">fd</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
     </span><span class="c1">// error handling
</span><span class="p">}</span><span class="w">
</span><span class="c1">// pending data is now safely stored.</span></pre><div class="notes"><p>That's why we have the sync command before the drop_cache command.</p></div></div><div class="step step-level-1" step="17" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="27200" data-y="0" data-z="0"><h1 id="clearing-the-cache">Clearing the cache</h1><p>For I/O benchmarks <em>always</em> clear caches:</p><pre class="highlight code bash"><span class="c1"># 1: Clear page cache only.
# 2: Clear inodes/direntries cache.
# 3: Clear both.
</span>sync<span class="p">;</span><span class="w"> </span><span class="nb">echo</span><span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>/proc/sys/vm/drop_caches</pre><div class="line-block"><br></br></div><p class="example">Example: code/io_cache</p></div><div class="step step-level-1" step="18" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="28800" data-y="0" data-z="0"><h1 id="alternative-to-fsync">Alternative to <tt>fsync()</tt></h1><pre class="highlight code bash"><span class="c1"># Move is atomic!
</span>$<span class="w"> </span>cp<span class="w"> </span>/src/bigfile<span class="w"> </span>/dst/bigfile.tmp<span class="w">
</span>$<span class="w"> </span>mv<span class="w"> </span>/dst/bigfile.tmp<span class="w"> </span>/dst/bigfile</pre><div class="notes"><p>This only works obviously if you're not constantly updating the file,
i.e. for files that are written just once.</p></div></div><div class="step step-level-1" step="19" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="30400" data-y="0" data-z="0"><h1 id="detour-filesystems">Detour: Filesystems</h1><p>They layout file data on disk:</p><ul><li><em>ext2/3/4</em>: good, stable &amp; fast choice.</li><li><em>fat8/16/32</em>: simple, but legacy, do not use.</li><li><em>NTFS</em>: slow and only for compatibility.</li><li><em>XFS</em>: good with big files.</li><li><em>btrfs</em>: feature-rich, can do CoW &amp; snapshots.</li><li><em>ZFS</em>: highly scalable and very complex.</li><li><em>sshfs</em>: remote access over FUSE</li></ul><div class="notes"><p>Actual implementation of read/write/etc. for a single
filesystem like FAT, ext4, btrfs. There are different ways
to layout and maintain data on disk, depending on your use case.</p><p>Syscalls all work the same, but some filesystems have
better performance regarding writes/reads/syncs or
are more targeted at large files or many files.</p><p>Most differences are admin related (i.e. integrity, backups,
snapshots etc.)</p></div></div><div class="step step-level-1" step="20" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="32000" data-y="0" data-z="0"><h1 id="detour-fragmentation">Detour: Fragmentation</h1><img src="images/windows_fragmentation.jpg" width="100%"></img><div class="notes"><p>What OS do you think of when you hear "defragmentation"? Right, Windows.
Why? Because NTFS used to suffer from it quite heavily.
FAT suffered even more from this.</p><p>Fragmentation means that the content of a file is not stored as one
continuous block, but in several blocks that might be scattered all over
the place, possibly even out-of-order (Block B before Block A). With
rotational disk this was in issue since the reading head had to jump all
over the place to read a single file. This caused noticeable pauses.</p><p>Thing is: Linux filesystems rarely require defragmentation and if
you are in need of defragmentation you are probably using an exotic enough
setup that you know why.</p><p>Most Linux filesystems have strategies to actively, defragment files (i.e.
bringing the parts of the file closer together) during writes to that file.
In practice, it does not matter anymore today.</p></div></div><div class="step step-level-1" step="21" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="33600" data-y="0" data-z="0"><h1 id="detour-tweaking">Detour: Tweaking</h1><ul><li>Do not fill up your filesystem.</li><li>Do not stack layers (<tt>overlayfs</tt>, <tt>luks</tt>, <tt>mdadm</tt>)</li><li>Do not enable <tt>atime</tt> (Access time, <tt>noatime</tt>)</li><li>Disable journaling if you like to live risky.</li></ul><div class="notes"><p>Performance is not linear. The fuller the FS is the,
more it will be busy with background processes cleaning
things up.</p><p>Stacking filesystems (like with using encryption) can slow things
down. Often this without alternatives though. Only with RAID you
have the option to choose hardware RAID.</p><p>Journaling filesystems like ext4 use something like a WAL. They write the
metadata and/or data to a log before integrating it into the actual
data structure (which is more complex and takes longer to commit).
Data is written twice therefore with the advantage of being able to
recover it on crash or power loss. Disabling it speeds things up
at the risk of data loss (which might be okay on some servers).</p></div></div><div class="step step-level-1" step="22" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="35200" data-y="0" data-z="0"><h1 id="detour-fuse">Detour: FUSE</h1><img src="images/fuse.png" width="100%"></img></div><div class="step step-level-1" step="23" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="36800" data-y="0" data-z="0"><h1 id="mmap-1"><tt>mmap()</tt> #1</h1><pre class="highlight code c"><span class="c1">// Handle files like arrays:
</span><span class="kt">int</span><span class="w"> </span><span class="n">fd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">open</span><span class="p">(</span><span class="s">"/var/tmp/file1.db"</span><span class="p">)</span><span class="w">
</span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">map</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mmap</span><span class="p">(</span><span class="w">
    </span><span class="nb">NULL</span><span class="p">,</span><span class="w">                 </span><span class="c1">// addr
</span><span class="w">    </span><span class="mi">1024</span><span class="w">                  </span><span class="c1">// map size
</span><span class="w">    </span><span class="n">PROT_READ</span><span class="o">|</span><span class="n">PROT_WRITE</span><span class="p">,</span><span class="w"> </span><span class="c1">// acess flags
</span><span class="w">    </span><span class="n">MAP_SHARED</span><span class="w">            </span><span class="c1">// private or shared
</span><span class="w">    </span><span class="n">fd</span><span class="p">,</span><span class="w">                   </span><span class="c1">// file descriptor
</span><span class="w">    </span><span class="mi">0</span><span class="w">                     </span><span class="c1">// offset
</span><span class="p">);</span><span class="w">

</span><span class="c1">// copy string to file with offset
</span><span class="n">strcpy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">map</span><span class="p">[</span><span class="mi">20</span><span class="p">],</span><span class="w"> </span><span class="s">"Hello World!"</span><span class="p">);</span></pre></div><div class="step step-level-1" step="24" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="38400" data-y="0" data-z="0"><h1 id="mmap-2"><tt>mmap()</tt> #2</h1><img src="images/mmap.png" width="80%"></img><div class="notes"><p>Maybe one of the most mysterious and powerful features we have on Linux.</p><p>Typical open/read/write/close APIs see files as streams. They are awkward to
use if you need to jump around a lot in the file itself (like some datbases do).</p><p>With mmap() we can handle files as arrays and let the kernel manage
reading/writing the required data from us magically on access. See m[17] above,
it does not require reading the respective part of the file explicitly.</p><p>Good mmap use cases:</p><ul><li>Reading large files (+ telling the OS how to read)</li><li>Jumping back and forth in big files.</li><li>Sharing the file data with several processes in a very efficient way.</li><li>Zero copy during reading! No buffering needed.</li><li>Ease-of-use. No buffers, no file handles, just arrays.</li></ul><p>Image source:</p><p><a href="https://biriukov.dev/docs/page-cache/5-more-about-mmap-file-access/">https://biriukov.dev/docs/page-cache/5-more-about-mmap-file-access/</a></p></div></div><div class="step step-level-1" step="25" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="40000" data-y="0" data-z="0"><h1 id="mmap-controversy"><tt>mmap()</tt> controversy</h1><img src="images/mmap_for_db.png" width="42%"></img><div class="line-block"><br></br></div><ul><li>Some databases use <tt>mmap()</tt> (<em>Influx, sqlite3, ...</em>)</li><li>Some people <a href="https://db.cs.cmu.edu/mmap-cidr2022">advise vehemently against it</a>. &#x1F4A9;</li><li>For good reasons, but it's complicated.</li><li>Main argument: Not enough control &amp; safety.</li><li>For some usecases <tt>mmap()</tt> is fine for databases.</li></ul></div><div class="step step-level-1" step="26" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="41600" data-y="0" data-z="0"><h1 id="to-sync-or-to-async">To sync or to async? &#x1F914;</h1><img src="images/sync_async.jpg" width="100%"></img><div class="notes"><p><a href="https://unixism.net/loti/async_intro.html">https://unixism.net/loti/async_intro.html</a></p></div></div><div class="step step-level-1" step="27" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="43200" data-y="0" data-z="0"><h1 id="io-uring"><tt>io_uring</tt></h1><img src="images/iouring.png" width="100%"></img></div><div class="step step-level-1" step="28" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="44800" data-y="0" data-z="0"><h1 id="o-direct"><tt>O_DIRECT</tt></h1><pre class="highlight code c"><span class="c1">// Skip the page cache; see `man 2 open`
</span><span class="kt">int</span><span class="w"> </span><span class="n">fd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">open</span><span class="p">(</span><span class="s">"/some/file"</span><span class="p">,</span><span class="w"> </span><span class="n">O_DIRECT</span><span class="o">|</span><span class="n">O_RDONLY</span><span class="p">);</span><span class="w">

</span><span class="c1">// No use of the page cache here:
</span><span class="kt">char</span><span class="w"> </span><span class="n">buf</span><span class="p">[</span><span class="mi">1024</span><span class="p">];</span><span class="w">
</span><span class="n">read</span><span class="p">(</span><span class="n">fd</span><span class="p">,</span><span class="w"> </span><span class="n">buf</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">buf</span><span class="p">));</span></pre><div class="notes"><p>This flag can be passed to the open() call.
It disables the page cache for this specific file handle.</p><p>Some people on the internet claim this would be faster,
but this is 90% wrong. There are 2 main use cases where O_DIRECT
has its use:</p><ul><li>Avoiding cache pollution: You know that you will not access the pages of
a specific file again and not want the page cache to remember those
files. This is a micro optimization and is probably not worth it. More or
less the same effect can be safely achieved by fadvise() with
FADV_DONTNEED.</li><li>Implementing your own "page cache" in userspace. Many databases use this,
since they have a better idea of what pages they need to cache and which
should be re-read.</li></ul></div></div><div class="step step-level-1" step="29" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="46400" data-y="0" data-z="0"><h1 id="i-o-scheduler">I/O scheduler &#x1F44E;</h1><img src="images/io_scheduler_perf.svg" width="100%"></img><p><a href="https://www.phoronix.com/review/linux-56-nvme">Full benchmark</a></p><div class="notes"><p>Re-orders read and write requests for performance.</p><ul><li><tt>none</tt>: Does no reordering.</li><li><tt>bfq</tt>: Complex, designed for desktops.</li><li><tt>mq-deadline</tt>, <tt>kyber</tt>: Simpler, good allround schedulers.</li></ul><p>In the age of SSDs we can use dumber schedulers.
In the age of HDDs schedulers were vital.</p></div></div><div class="step step-level-1" step="30" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="48000" data-y="0" data-z="0"><h1 id="ionice"><tt>ionice</tt> &#x1F44E;</h1><pre class="highlight code c"><span class="cp"># Default level is 4. Lower is higher.
</span><span class="n">$</span><span class="w"> </span><span class="n">ionice</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&lt;</span><span class="n">some</span><span class="o">-</span><span class="n">pid</span><span class="o">&gt;</span></pre><div class="notes"><p>Well, you can probably guess what it does.</p></div></div><div class="step step-level-1" step="31" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="49600" data-y="0" data-z="0"><h1 id="madvise-fadvise"><tt>madvise()</tt> &amp; <tt>fadvise()</tt></h1><img src="images/fadvise_bench.png" width="100%"></img><p class="example">Example: code/fadvise</p><p class="example">Example: code/madvise</p><div class="notes"><p>fadvise() and madvise() can be used to give the page cache hints on what
pages are going to be used next and in what order. This can make a big difference
for complex use cases like rsync or tar, where the program knows that it needs
to read a bunch of files in a certain order. In this case advises can be given
to the kernel quite a bit before the program starts reading the file.</p><p>The linked examples try to simulate this by clearing the cache, giving a advise,
waiting a bit and then reading the file in a specific order.</p><p>The examples also contain some noteable things:</p><ul><li>Reading random is much slower than reading forward.</li><li>Reading backwards is the end boss and really much, much slower.</li><li>hyperfine is a nice tool to automate little benchmarks like these.</li><li>Complex orders (like heaps or tree traversal) cannot be requested.</li><li>mmap does not suffer from the read order much and is much faster
for this kind of no-copy-needed workload.</li></ul></div></div><div class="step step-level-1" step="32" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="51200" data-y="0" data-z="0"><h1 id="why-is-cp-faster">Why is cp faster?</h1><pre class="highlight code go"><span class="kn">package</span><span class="w"> </span><span class="nx">main</span><span class="w">

</span><span class="kn">import</span><span class="p">(</span><span class="w">
    </span><span class="s">"os"</span><span class="w">
    </span><span class="s">"io"</span><span class="w">
</span><span class="p">)</span><span class="w">

</span><span class="kd">func</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nx">src</span><span class="p">,</span><span class="w"> </span><span class="nx">_</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">os</span><span class="p">.</span><span class="nx">Open</span><span class="p">(</span><span class="nx">os</span><span class="p">.</span><span class="nx">Args</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="w">
    </span><span class="nx">dst</span><span class="p">,</span><span class="w"> </span><span class="nx">_</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">os</span><span class="p">.</span><span class="nx">Create</span><span class="p">(</span><span class="nx">os</span><span class="p">.</span><span class="nx">Args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="w">
    </span><span class="nx">io</span><span class="p">.</span><span class="nx">Copy</span><span class="p">(</span><span class="nx">dst</span><span class="p">,</span><span class="w"> </span><span class="nx">src</span><span class="p">)</span><span class="w">
</span><span class="p">}</span></pre><div class="notes"><p>cp is not faster because it copies data faster, but
because it avoids copies to user space by using specialized calls like:</p><ul><li>ioctl(5, BTRFS_IOC_CLONE or FICLONE, 4) = 0 (on btrfs)</li><li>copy_file_range() - performs in-kernel copy, sometimes even using DMA</li></ul><p>Find out using strace cp src dst.
If no trick is possible it falls back to normal buffered read/write.</p></div></div><div class="step step-level-1" step="33" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="52800" data-y="0" data-z="0"><h1 id="reduce-number-of-copies">Reduce number of copies</h1><ul><li>Do not copy buffers too often (&#x1F921;)</li><li>Use <tt>readv()</tt> to splice existing buffers to one.</li><li>Use hardlinks if possible</li><li>Use CoW reflinks if possible.</li><li><tt>sendfile()</tt> to copy files to Network.</li><li><tt>copy_file_range()</tt> to copy between files.</li></ul></div><div class="step step-level-1" step="34" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="54400" data-y="0" data-z="0"><h1 id="good-abstractions">Good abstractions</h1><pre class="highlight code go"><span class="kd">type</span><span class="w"> </span><span class="nx">ReaderFrom</span><span class="w"> </span><span class="kd">interface</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nx">ReadFrom</span><span class="p">(</span><span class="nx">r</span><span class="w"> </span><span class="nx">Reader</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="nx">n</span><span class="w"> </span><span class="kt">int64</span><span class="p">,</span><span class="w"> </span><span class="nx">err</span><span class="w"> </span><span class="kt">error</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="kd">type</span><span class="w"> </span><span class="nx">WriterTo</span><span class="w"> </span><span class="kd">interface</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nx">WriteTo</span><span class="p">(</span><span class="nx">w</span><span class="w"> </span><span class="nx">Writer</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="nx">n</span><span class="w"> </span><span class="kt">int64</span><span class="p">,</span><span class="w"> </span><span class="nx">err</span><span class="w"> </span><span class="kt">error</span><span class="p">)</span><span class="w">
</span><span class="p">}</span></pre><div class="notes"><p>You might have heard that abstractions are costly from a performance point
of view and this partly true. Please do not take this an excuse for not adding
any abstractions to your code in fear of performance hits.</p><p>Most bad rap of abstractions come from interfaces that are not general
enough and cannot be extended when performance needs arise.</p><p>Example: io.Reader/io.Writer/io.Seeker are very general and hardly specific.
From performance point of view they tend to introduce some extra allocations
and also some extra copying that a more specialized implementation might get
rid of if it would know how it's used.</p><p>For example, a io.Reader that has to read a compressed stream needs to read
big chunks of compressed data since compression formats work block
oriented. Even if the caller only needs a single byte, it still needs to
decompress a whole block. If the API user needs another byte a few KB away,
the reader might have to throw away the curent block and allocate space for
a new one, while seeking in the underlying stream. This is costly.</p><p>Luckily, special cases can be optimized. What if the reader knows that the whole
stream is read in one go? Like FADV_SEQUENTIAL basically. This is what WriteTo()
is for. A io.Reader can implement this function to dump its complete content to
the writer specified by w. The knowledge that no seeking is required allows
the decompression reader to make some optimizations: i.e. use one big buffer,
no need to re-allocate, parallelize reading/decompression and avoid seek calls.</p><p>So remember: Keep your abstractions general, check if there are specific
patterns on how your API is called and offer optimizations for that.</p></div></div><div class="step step-level-1" step="35" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="56000" data-y="0" data-z="0"><h1 id="i-o-performance-checklist-the-sane-part">I/O performance checklist: <em>The sane part</em></h1><ol><li>Avoid I/O. (&#x1F921;)</li><li>Use a sane buffer size with <tt>read()</tt>/<tt>write()</tt>.</li><li>Use append only data for writing.</li><li>Read files sequential, avoid seeking.</li><li>Batch small writes, as they evict caches.</li><li>Avoid creating too many small files.</li><li>Make use of <tt>mmap()</tt> where applicable.</li><li>Reduce copying (<tt>mmap</tt>, <tt>sendfile</tt>, <tt>splice</tt>).</li><li>Compress data if you can spare the CPU cycles.</li></ol><div class="notes"><ol><li>In many cases I/O can be avoided by doing more things in memory
or avoiding duplicate work.</li><li>Anything between 1 and 32k is mostly fine. Exact size depends
on your system and might vary a little. Benchmark to find out.</li><li>Appending to a file is a heavily optimized flow in Linux. Benefit
from this by designing your software accordingly.</li><li>Reading a file backwards is much much slower than reading it
sequentially in forward direction. This is also a heavily optimized
case. Avoid excessive seeking, even for SSDs (syscall overhead +
page cache has a harder time what you will read next)</li><li>Small writes of even a single byte will mark a complete page
from the page cache as dirty, i.e. it needs to be written.
If done for many pages this will have an impact.</li><li>Every file is stored with metadata and some overhead. Prefer to
join small files to bigger ones by application logic.</li><li>mmap() can be very useful, especially in seek-heavy applications.
It can also be used to share the same file over several processes
and it has a zero-copy overhead.</li><li>Specialized calls can help to avoid copying data to userspace and
do a lot of syscalls by shifting the work to the kernel. In general,
try to avoid copying data in your application as much as possible.</li><li>If you have really slow storage (i.e. SD-cards) but a fast CPU,
then compressing data might be an option using a fast compression
algorithm like lz4 or snappy.</li></ol></div></div><div class="step step-level-1" step="36" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="57600" data-y="0" data-z="0"><h1 id="i-o-performance-checklist-the-deseperate-part">I/O performance checklist: <em>The deseperate part</em></h1><ol><li>Use <tt>io_uring</tt>, if applicable.</li><li>Buy faster/specialized hardware (<tt>RAID 0</tt>).</li><li>Use no I/O scheduler (<tt>none</tt>).</li><li>Tweak your filesystems settings.</li><li>Use a different filesystem (<tt>tmpfs</tt>)</li><li>Slightly crazy: <tt>fadvise()</tt> for cache warmup.</li><li>Maybe crazy: use <tt>O_DIRECT</tt></li><li>Likely crazy: skip <tt>fsync()/msync()</tt>)</li><li>Do not fill up your FS/SSD fully.</li></ol><div class="notes"><ol><li>io_uring can offer huge benefits, especially when dealing
with many files and parallel processing of them. It is definitely
the most complex of the 3 APIs of read+write / mmap / io_uring
and its usage most be warranted.</li><li>Always a good option and often the cheapest one. RAID 0 can,
in theory, speed up throughput almost indefinitely, although
you'll hit limits with processing speeds quite fast.</li><li>Mostly standard now. I/O schedulers were important in the age
of HDDs. Today, it's best to skip scheduling (to avoid overhead)
by using the none scheduler.</li><li>If raw performance is needed, then you might tweak some filesystem
settings, as seen before.</li><li>Some filesystems are optimized for scaling and write workloads (XFS),
while others are more optimized for desktop workloads (ext4). Choose
wisely. The pros and cons go beyond the scope of this workshop.
If you're happy with memory, you can of course <tt>tmpfs</tt> which is
the fastest available FS - because it just does not use the disk.</li><li>fadvise() can help in workloads that include a lot of files.
The correct usage is rather tricky though.</li><li>Some databases use direct access without page cache to implement
their own buffer pools. Since they know better when to keep a page
and when to read it from disk again.</li><li>If you do not care for lost data, then do not use fsync() to ensure that
data was written.</li><li>Full SSDs (and filesystem) suffer more from write amplification and
finding more free extents becomes increasingly challenging.</li></ol></div></div><div class="step step-level-1" step="37" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="59200" data-y="0" data-z="0"><h1 id="fynn">Fynn!</h1><p>&#x1F3C1;</p></div></div><div id="slide-number" class="slide-number">
         1
      </div><script type="text/javascript" src="js/impress.js"></script><script type="text/javascript" src="js/gotoSlide.js"></script><script type="text/javascript" src="js/hovercraft.js"></script><script type="text/javascript" src="hovercraft.js"></script><script type="text/javascript">
      document.getElementById("impress").addEventListener("impress:stepenter", update_slide_number, false);
    </script></body></html>