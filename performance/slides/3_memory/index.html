<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml"><head><title>Performance: Memory</title><meta charset="UTF-8"></meta><meta name="generator" content="Hovercraft! 1.0 http://regebro.github.com/hovercraft"></meta><link rel="stylesheet" href="css/hovercraft.css" media="all"></link><link rel="stylesheet" href="css/highlight.css" media="all"></link><link rel="stylesheet" href="hovercraft.css" media="screen,projection"></link><script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        showProcessingMessages: false,
        messageStyle: "none",
        TeX : { extensions : ['color.js'] }
      });
    </script></head><body class="impress-not-supported"><div id="impress-help"></div><div id="impress" data-transition-duration="1500"><div class="step step-level-1" step="0" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="0" data-y="0" data-z="0"><h1 id="agenda">Agenda</h1><p>TODO: Agenda</p></div><div class="step step-level-1" step="1" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="1600" data-y="0" data-z="0"><p>TODO: sync.Pool
TODO: pprof for memory.</p><h1 id="memory">Memory</h1></div><div class="step step-level-1" step="2" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="3200" data-y="0" data-z="0"><h1 id="ram">RAM</h1><ul><li><strong>RAM</strong> = Random Access Memory</li><li>Huge, sequential line of individual memory cells</li><li>Usually can only be addressed in pages</li><li>Memory controller that handles the actual interaction.</li><li>Two major types: Static RAM (SRAM) vs Dynamic RAM (DRAM)</li></ul><div class="notes"><p>SDRAM = Synchronous DRAM
DDR-SDRAM = Double Data Rate SDRAM</p></div></div><div class="step step-level-1" step="3" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="4800" data-y="0" data-z="0"><h1 id="dram-one-bit-please">DRAM - one bit, please</h1><img src="images/dram.png" width="100%" align="center"></img><div class="notes"><p>Dynamic sounds good, doesn't it?</p><ul><li>Very simple and cheap to produce.</li><li>High density (many cells per area)</li><li>Needs to be refreshed constantly (64ns or so)</li></ul><p>Fun fact: DRAM enables a hardware-based security attack: ROWHAMMER.
Changing a row of DRAM cells can, if done very often, switch a nearby row.
This can be used to change data like "userIsLoggedIn".</p></div></div><div class="step step-level-1" step="4" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="6400" data-y="0" data-z="0"><h1 id="sram-one-bit-please">SRAM - one bit, please</h1><img src="images/sram.png" width="100%" align="center"></img><div class="notes"><ul><li>Very fast. 10x speed of DRAM</li><li>No refresh required.</li><li>Low power consumption</li><li>Expensive, not so high density</li></ul></div></div><div class="step step-level-1" step="5" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="8000" data-y="0" data-z="0"><h1 id="why-use-dram-at-all">Why use DRAM at all?</h1><ul><li>Because it's cheap,  and we need tons of it.</li><li>Main memory is all DRAM.</li><li>Caches (L1-L3) are SRAM.</li><li>A lightbulb is maybe OSRAM (Sorry.)</li></ul><div class="notes"><p>So basically...</p><p>again, hardware is at fault
and instead of fixing it with some Pfiffikus
we software devs have to cope with slow main memory.</p></div></div><div class="step step-level-1" step="6" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="9600" data-y="0" data-z="0"><h1 id="numa">NUMA</h1><p>Is the access to all memory offsets equally fast?</p><ul><li>Not if you have more than one CPU!</li><li>Every CPU gets 1/nth of the memory.</li><li>Every CPU can access the completely memory.</li><li>Non-local access is costly.</li></ul><div class="notes"><p>NUMA - non uniform memory access</p><p>Linux is NUMA very well capable and that's why it's such a popular server operating system.
Or one of the reasons at least.</p></div></div><div class="step step-level-1" step="7" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="11200" data-y="0" data-z="0"><h1 id="how-the-heck-does-this-stuff-relate-to-me">How the heck does this stuff relate to me?</h1><p>Not so much on a daily basis, to be fair. But:</p><ul><li>Memory allocations are expensive.</li><li>Strategies to make less/smaller allocations help performance</li><li>Requires sadly an understanding how the OS handles memory.</li></ul></div><div class="step step-level-1" step="8" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="12800" data-y="0" data-z="0"><p>TODO: Maybe use graphics from here: <a href="https://medium.com/eureka-engineering/understanding-allocations-in-go-stack-heap-memory-9a2631b5035d">https://medium.com/eureka-engineering/understanding-allocations-in-go-stack-heap-memory-9a2631b5035d</a></p><h1 id="the-stack-heap-1">The stack &amp; heap #1</h1><pre class="highlight code go"><span class="c1">//go:noinline</span><span class="w">
</span><span class="kd">func</span><span class="w"> </span><span class="nx">f</span><span class="p">()</span><span class="w"> </span><span class="o">*</span><span class="kt">int</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nx">v</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="mi">3</span><span class="w">
    </span><span class="k">return</span><span class="w"> </span><span class="o">&amp;</span><span class="nx">v</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="kd">func</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="c1">// Two for the stack:</span><span class="w">
    </span><span class="c1">// a=0xc00009aef8 b=0xc00009aef0</span><span class="w">
    </span><span class="nx">a</span><span class="p">,</span><span class="w"> </span><span class="nx">b</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="mi">23</span><span class="p">,</span><span class="w"> </span><span class="mi">42</span><span class="w">

    </span><span class="c1">// Two for the heap:</span><span class="w">
    </span><span class="c1">// c=0xc0000b2000 d=0xc0000b2008</span><span class="w">
    </span><span class="nx">c</span><span class="p">,</span><span class="w"> </span><span class="nx">d</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">f</span><span class="p">(),</span><span class="w"> </span><span class="nx">f</span><span class="p">()</span><span class="w">
</span><span class="p">}</span></pre></div><div class="step step-level-1" step="9" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="14400" data-y="0" data-z="0"><h1 id="the-stack-heap-2">The stack &amp; heap #2</h1><p><strong>Stack</strong> is...</p><ul><li>...cleaned up automatically on return</li><li>...bound to a function call</li><li>...preferred if possible.</li><li>...can be reasoned about during compile time</li><li>...good for small amounts of data.</li></ul><p><strong>Heap</strong> is...</p><ul><li>...needs to be explicitly requested</li><li>...needs to be explititly cleaned up</li><li>...can be used until freed.</li><li>...should be used when required.</li><li>...usually required for a lot of data.</li></ul></div><div class="step step-level-1" step="10" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="16000" data-y="0" data-z="0"><h1 id="the-stack-heap-3">The stack &amp; heap #3</h1><p>Go is clever and hides this from you via
<strong>escape analysis</strong>:</p><pre class="highlight code go"><span class="kd">func</span><span class="w"> </span><span class="nx">f</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nx">v</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="mi">3</span><span class="p">;</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="o">&amp;</span><span class="nx">v</span><span class="w"> </span><span class="p">}</span><span class="w">
</span><span class="kd">func</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="nx">f</span><span class="p">())</span><span class="w">
</span><span class="p">}</span></pre><pre class="highlight code bash">$ go build -gcflags<span class="o">=</span><span class="s2">"-m"</span> .
./main.go:3:2: moved to heap: v</pre><p>The more you allocate on the heap, the more pressure you put on the
memory bookkeeping and the garbage collector.</p><p><strong>Performance tip:</strong> Avoid variables escaping to the heap:</p><ul><li></li><li>Avoid using pointers if unnecessary</li><li>Prefer return by value if value is small (&lt; 128 byte) (small copy is faster than GC)</li><li>Don't overreact here though. Don't make your APIs ugly just because you know this little fact. Use this in hot loops. AFTER measurement.</li></ul><div class="notes"><p>Never heard of this stuff, why should I care?</p><p>Difference is important in C
Well, you're lucky enough that your compiler does it for you
Or you're unlucky enough to use python where all hope is forlorn</p></div></div><div class="step step-level-1" step="11" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="17600" data-y="0" data-z="0"><h1 id="detour-what-is-a-stackoverflow">Detour: What is a StackOverflow?</h1><p>Why using the stack only for small data if you can also use it for somewhat dynamic allocations?</p><p>Because stack size is limited (on linux about 8MB, but don't rely on that)</p><p>How can you hit this limit?</p><ul><li>By recursion - lots of nested stacks.</li><li>By running over the extents of a buffer (in C)</li></ul><p>See example: stackoverflow.</p></div><div class="step step-level-1" step="12" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="19200" data-y="0" data-z="0"><h1 id="gc-pressure-locality-and-memory-management">GC pressure, locality and memory management</h1><p>Prefer this:</p><pre class="highlight code go"><span class="nx">m</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nb">make</span><span class="p">(</span><span class="kd">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="nx">someStruct</span><span class="p">)</span></pre><p>over:</p><pre class="highlight code go"><span class="nx">m</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nb">make</span><span class="p">(</span><span class="kd">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="o">*</span><span class="nx">someStruct</span><span class="p">)</span></pre><ul><li>Way less memory in total</li><li>Data is packed together (good for caching!)</li><li>Less work for the GC and the allocator to do</li><li>Pointers give you more potential to fuck up.</li></ul><pre class="highlight code bash">noptr  <span class="m">577</span>.7 ns/op   <span class="m">336</span> B/op             <span class="m">2</span> allocs/op
ptr    <span class="m">761</span>.4 ns/op   <span class="m">384</span> B/op            <span class="m">10</span> allocs/op

<span class="o">(</span>The <span class="m">10</span> will increase with input! Longer runs will cause more GC <span class="k">for</span> the ptr <span class="k">case</span><span class="o">)</span></pre></div><div class="step step-level-1" step="13" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="20800" data-y="0" data-z="0"><h1 id="virtual-memory">Virtual memory</h1><img src="images/virtual_memory.svg.png"></img><ul><li>The physical memory of a system is splitted up into 4k pages.</li><li>Each process maintains a virtual memory mapping table, mapping
from the virtual range of memory to physical memory.</li><li>Address translation is handled efficiently by the MMU</li></ul><div class="notes"><p>Wait, those addresses I saw earlier... are those the addrs in RAM?
Hopefully not, because otherwise you could somehow find out where the OpenSSH
server lives in memory and steal it's keys. For security reasons it must look
for each process like he's completely alone on the system. What you saw above
are virtual memory addresses and they stay very similar on each run.</p><p>The concept how this achieved is called "virtual memory" and it's probably one of
the more clever things we did in computer science.</p></div></div><div class="step step-level-1" step="14" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="22400" data-y="0" data-z="0"><h1 id="virtual-memory-implementation">Virtual memory implementation</h1><ul><li>Each process has a list of page tables mapping virtual to physical memory ("page table")</li><li>On process start this table is filled with a few default kilobytes of mapped pages
(the first few pages are not mapped, so dereferencing a NULL pointer will always crash)</li><li>When the program first accesses those addresses the CPU will generate a page fault, indicating
that there is no such mapping. The OS receives this and will find a free physical page, map
it and retry execution. If another page fault occurs the OS will kill the process with SIGSEGV.</li></ul></div><div class="step step-level-1" step="15" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="24000" data-y="0" data-z="0"><h1 id="virtual-memory-advantages">Virtual memory advantages</h1><ul><li>Pages can be mapped only once it is needed (CoW)</li><li>Processes can share the same page for shared memory.</li><li>Pages do not need to be mapped to physical memory: Disk, DMA or even network is possible!</li><li>Processes are isolated from each other.</li><li>Processes consume only as much physical ("residual") memory as really needed.</li><li>Programs get easier to write because they can just assume that the memory is not fragmented.</li><li>Pages can be swaped by the OS without the process even noticing (Swapping)</li><li>The kernel can give away more memory than there is on the system (overcommiting)</li><li>Pages with the same content can be deduplicated</li></ul></div><div class="step step-level-1" step="16" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="25600" data-y="0" data-z="0"><h1 id="residual-vs-virtual-memory-usage">Residual vs virtual memory usage</h1><p>TODO: look a  htop and free</p></div><div class="step step-level-1" step="17" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="27200" data-y="0" data-z="0"><h1 id="quick-peak-memory-measurement">Quick peak memory measurement</h1><pre class="highlight code">/usr/bin/time -v &lt;command&gt;</pre></div><div class="step step-level-1" step="18" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="28800" data-y="0" data-z="0"><h1 id="malloc">malloc()</h1><p><tt>`c
char *one_kb_buf = malloc(1024 * sizeof(char));
/* use one_kb_buf somehow */
free(onone_kb_buf);
`</tt></p><ul><li><tt>malloc</tt> itself is implemented in user space, not by the kernel.</li><li>Think of it as some sort of memory pool management library (implemente by glibc)</li><li>When <tt>malloc</tt> runs out of space it asks the kernel for more space by using either the <tt>sbrk</tt> call (for small allocations)
or <tt>mmap</tt> (for big allocations). Allocations have as multiple of PAGE_SIZE (4KB)</li><li><tt>sbrk</tt> is a system call that moves the <em>program break</em> of a program upwards (or downwards) by a certain amount.</li><li>The new space is then managed by <tt>malloc</tt>. Each allocation gets added a header by <tt>malloc</tt> at the start (~10 byte),
so many small allocations are wasteful.</li><li>Memory that is not directly used is kept in a freelist. Only once the freelist is empty, new memory is fetched
from the operating system.</li><li>On <tt>free</tt> a memory block is added back to the freelist.</li><li><tt>malloc</tt> is optimized for the usecase of allocating many (typically) small sized objects with minimal fragmentation.
Since every program tends to have different needs it makes sense to do this in userspace.</li><li>Go uses a similar implementation, but is more sophisticated. Main difference:
it keeps pre-allocated arenas for differently sized objects. i.e. 4, 8, 16,
32, 64 and so on.</li></ul><div class="notes"><p>What the fuck happens on allocation?</p><p>In C you have to explicitly what <tt>Go</tt> does in the background for you:</p></div></div><div class="step step-level-1" step="19" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="30400" data-y="0" data-z="0"><h1 id="swapping">Swapping</h1><pre class="highlight code bash">$ dd <span class="k">if</span><span class="o">=</span>/dev/zero <span class="nv">of</span><span class="o">=</span>swapfile <span class="nv">count</span><span class="o">=</span><span class="m">1024</span> <span class="nv">bs</span><span class="o">=</span>1M
$ swapon ./swapfile</pre><pre class="highlight code bash">$ cat /proc/sys/vm/swappiness
<span class="o">(</span>value between <span class="m">0</span>-100<span class="o">)</span>
<span class="nv">0</span> <span class="o">=</span> only swap <span class="k">if</span> OOM would hit otherwise.
<span class="nv">100</span> <span class="o">=</span> swap everything not actively used.</pre><div class="notes"><p>Linux can use swap space as second-prio memory if main memory runs low.
Swap is already used before memory goes low. Inactive processes and stale IO pages
get put to swap so that memory management can make use of that space to provide less
fragmented memory regions.</p><p>How aggressive this happens can be set using vm.swappiness. A value between</p><p>Rules:</p><ul><li>If you want to hibernate (i.e. powerless suspend) then you need as much swap as RAM.</li><li>Otherwise about half of RAM is a good rule of thumb.</li><li>Systems that rely on low latency (i.e. anything that goes in the direction of realtime) should not swap.</li></ul></div></div><div class="step step-level-1" step="20" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="32000" data-y="0" data-z="0"><h1 id="the-oom-killer">The OOM Killer</h1><ul><li>Kicks in if sytem almost completely ran out of RAM.</li><li>Selects a process based on a scoring system and kills it.</li><li>Processes can be given a priority in advance.</li></ul><div class="notes"><ul><li>Last resort mechanism.</li><li>Reports in dmesg.</li><li>Sometimes comes too late and is not able to operate anymore.</li></ul><p>Alternatives:</p><ul><li>earlyoom</li><li>systemd-oomd</li></ul><p>Userspace-Daemons that monitor memory usage and kill processes
in a very configurable way. Well suited for server systems.</p></div></div><div class="step step-level-1" step="21" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="33600" data-y="0" data-z="0"><h1 id="mmap"><tt>mmap()</tt></h1><ul><li>Can map files (among other things) to a processes' memory.</li><li>File contents are loaded</li></ul><div class="notes"><p>Maybe one of the most mysterious system features we have on Linux.</p><p>Typical open/read/write/close APIs see files as streams.
With mmap() we can handle files as arrays and the memory needed for
this can be shared by several processes!</p><p>Great for implementing databases
or implementing random access to a big file (ex: reading every tenth byte of a file)</p></div><h1 id="mmap-for-databases"><tt>mmap</tt> for databases</h1><p>Short answer: Don't. Not enough control. Random order + writes hurt mmap.</p><p>Long answer: <a href="https://db.cs.cmu.edu/mmap-cidr2022">https://db.cs.cmu.edu/mmap-cidr2022</a></p><p>Good mmap use cases:</p><ul><li>Reading large files (+ telling the OS how to read)</li><li>Sharing the file data with several processes in a very efficient way.</li><li>Zero copy during reading.</li><li>Ease-of-use. No buffers, no file handles.</li></ul></div><div class="step step-level-1" step="22" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="35200" data-y="0" data-z="0"><h1 id="madvise-and-fadvise"><tt>madvise()</tt> and <tt>fadvise()</tt></h1><ul><li>You can give tips to the kernel.</li><li>When you know that you need a certain memory page soon,
then you can do <tt>madvise(addr, 4096, MADV_WILLNEED)</tt>.</li><li>With <tt>fadvise()</tt> you can do the same for files.</li></ul><div class="notes"><p>This is greatly notice-able with file I/O!</p><p>Caveat: Complex orders (like tree traversal) cannot be requested
by userspace.</p></div></div></div><script type="text/javascript" src="js/impress.js"></script><script type="text/javascript" src="js/gotoSlide.js"></script><script type="text/javascript" src="js/hovercraft.js"></script></body></html>