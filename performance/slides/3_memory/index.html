<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml"><head><title>Performance: Memory</title><meta charset="UTF-8"></meta><meta name="generator" content="Hovercraft! 1.0 http://regebro.github.com/hovercraft"></meta><link rel="stylesheet" href="css/hovercraft.css" media="all"></link><link rel="stylesheet" href="css/highlight.css" media="all"></link><link rel="stylesheet" href="hovercraft.css" media="screen,projection"></link><script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        showProcessingMessages: false,
        messageStyle: "none",
        TeX : { extensions : ['color.js'] }
      });
    </script></head><body class="impress-not-supported"><div id="impress-help"></div><div id="impress" data-transition-duration="1500"><div class="step step-level-1" step="0" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="0" data-y="0" data-z="0"><h1 id="agenda">Agenda</h1><ul><li>How does memory work as hardware?</li><li>How does Linux manage memory?</li><li>How can we measure &amp; profile memory usage?</li><li>How can we allocate less and faser?</li></ul><img src="images/ram.png" width="50%"></img></div><div class="step step-level-1" step="1" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="1600" data-y="0" data-z="0"><h1 id="rama-lama-ding-dong">RAMa Lama Ding Dong &#x1F3BA;</h1><ul><li><strong>RAM</strong> = Random Access Memory</li><li>Huge, sequential line of individual memory cells.</li><li>Usually can only be addressed in 4K pages.</li><li>Memory controller that handles the actual interaction between Bus and CPU.</li></ul><p>Two major types in use today:</p><ul><li><em>Static RAM</em> (SRAM)</li><li><em>Dynamic RAM</em> (DRAM)</li></ul><div class="notes"><p>SDRAM = Synchronous DRAM
DDR-SDRAM = Double Data Rate SDRAM</p></div></div><div class="step step-level-1" step="2" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="3200" data-y="0" data-z="0"><h1 id="dram-one-bit-please">DRAM - one bit, please</h1><img src="images/dram.png" width="100%" align="center"></img><div class="notes"><p>Dynamic sounds good, doesn't it? Well, it isn't...</p><p>Pros:</p><ul><li>Very simple and cheap to produce.</li><li>High density (many cells per area)</li></ul><p>Cons:</p><ul><li>Needs to be refreshed constantly (64ns or so)</li><li>Makes logic in controller way more complicated.</li><li>Relatively slow.</li><li>Enables security issues like ROWHAMMER.</li></ul></div></div><div class="step step-level-1" step="3" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="4800" data-y="0" data-z="0"><h1 id="sram-one-bit-please">SRAM - one bit, please</h1><img src="images/sram.png" width="100%" align="center"></img><div class="notes"><ul><li>Very fast. 10x speed of DRAM</li><li>No refresh required.</li><li>Low power consumption</li><li>Expensive, not so high density</li></ul></div></div><div class="step step-level-1" step="4" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="6400" data-y="0" data-z="0"><h1 id="why-use-dram-at-all">Why use DRAM at all?</h1><ul><li>Because it's cheap, and we need tons of it.</li><li>Main memory is all DRAM.</li><li>Caches (L1-L3) are SRAM.</li><li>A lightbulb is maybe OSRAM (Sorry.) &#x1F4A1;</li></ul><div class="notes"><p>So basically...</p><p>again, hardware is at fault
and instead of fixing it with some Pfiffikus
we software devs have to cope with slow main memory.</p></div></div><div class="step step-level-1" step="5" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="8000" data-y="0" data-z="0"><h1 id="rowhammer">ROWHAMMER &#x1F528;</h1><img src="images/rowhamer.webp" width="100%"></img><div class="notes"><p>Fun fact: DRAM enables a hardware-based security attack: ROWHAMMER.
Changing a row of DRAM cells can, if done very often, switch a
nearby row. This can be used to change data like "userIsLoggedIn".</p></div></div><div class="step step-level-1" step="6" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="9600" data-y="0" data-z="0"><h1 id="ecc-memory">ECC Memory</h1><ul><li>Radiation or damage can flip bits</li><li>ECC RAM protects against such errors.</li><li>Use of parity bits or Hamming code.</li><li>Slightly slower than normal RAM.</li></ul><img src="images/ecc.png" width="100%"></img></div><div class="step step-level-1" step="7" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="11200" data-y="0" data-z="0"><h1 id="numa-multiple-cpus">NUMA - multiple CPUs</h1><p>NUMA = Non Uniform Memory Architecture</p><p>Is the access to all memory offsets equally fast?</p><ul><li>Not if you have more than one CPU!</li><li>Every CPU gets 1/nth of the memory.</li><li>Every CPU can access the complete memory.</li><li>Non-local access is costly.</li></ul><div class="notes"><p>TODO: is that slide really important? If yes, make it prettier using a diagram.</p><p>Linux is NUMA capable and that's why it's such a popular server and
superomputer operating system. Or one of the reasons at least.</p></div></div><div class="step step-level-1" step="8" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="12800" data-y="0" data-z="0"><h1 id="how-is-memory-managed">How is memory managed?</h1><img src="diagrams/3_os_allocations.svg" width="100%"></img><div class="notes"><p>The large sequential slab of memory needs to be
distributed to all programs that require it.</p><ul><li>Usage is not known in advance.</li><li>programs need to allocate based on their need.</li><li>OS needs to make memory allocations inexpensive</li></ul><p>Understandin how the kernel and processes manage their memory
makes it possible to use less of it and make more efficient use of it.</p><p>For this we need to start at the basics...</p></div></div><div class="step step-level-1" step="9" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="14400" data-y="0" data-z="0"><h1 id="inside-a-process">Inside a process</h1><ul><li>Each process may allocate certain amounts of memory on-demand.</li><li>Memory inside the process can be managed in two ways: <em>Stack</em> and <em>Heap.</em></li><li><em>Stack:</em> For short-lived memory.</li><li><em>Heap:</em> For long-lived memory.</li></ul></div><div class="step step-level-1" step="10" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="16000" data-y="0" data-z="0"><h1 id="the-stack-lifo-layout">The stack: LIFO Layout</h1><img src="images/stack_layout.svg" width="80%"></img><div class="notes"><p><a href="https://en.wikipedia.org/wiki/Stack-based_memory_allocation">https://en.wikipedia.org/wiki/Stack-based_memory_allocation</a></p></div></div><div class="step step-level-1" step="11" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="17600" data-y="0" data-z="0"><h1 id="the-stack-growth">The stack: Growth</h1><pre class="highlight code go"><span class="kd">func</span><span class="w"> </span><span class="nx">recursive</span><span class="p">(</span><span class="nx">depth</span><span class="w"> </span><span class="kt">int</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="k">if</span><span class="w"> </span><span class="nx">depth</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="p">}</span><span class="w">

    </span><span class="kd">var</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="kt">int</span><span class="w">
    </span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Printf</span><span class="p">(</span><span class="s">"%p\n"</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="nx">a</span><span class="p">)</span><span class="w">
    </span><span class="nx">recursive</span><span class="p">(</span><span class="nx">depth</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="c1">// ...</span><span class="w">
</span><span class="nx">recursive</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="w">

</span><span class="c1">// Output:</span><span class="w">
</span><span class="mh">0xc000070e70</span><span class="w"> </span><span class="o">-</span><span class="p">&gt;</span><span class="w"> </span><span class="nx">diff</span><span class="p">:</span><span class="w"> </span><span class="mi">80</span><span class="w"> </span><span class="nx">bytes</span><span class="w"> </span><span class="nx">due</span><span class="w"> </span><span class="nx">to</span><span class="p">:</span><span class="w">
</span><span class="mh">0xc000070e20</span><span class="w"> </span><span class="o">-</span><span class="p">&gt;</span><span class="w"> </span><span class="nx">stack</span><span class="w"> </span><span class="nx">pointer</span><span class="p">,</span><span class="w"> </span><span class="nx">frame</span><span class="w"> </span><span class="nx">pointer</span><span class="w">
</span><span class="mh">0xc000070dd0</span><span class="w"> </span><span class="o">-</span><span class="p">&gt;</span><span class="w"> </span><span class="nx">registers</span><span class="p">,</span><span class="w"> </span><span class="nx">params</span><span class="p">,</span><span class="w"> </span><span class="o">...</span><span class="w">
</span><span class="o">...</span></pre><div class="notes"><p>Stack grows downwards.</p><p>More details on calling a function:</p><p><a href="https://eli.thegreenplace.net/2011/09/06/stack-frame-layout-on-x86-64">https://eli.thegreenplace.net/2011/09/06/stack-frame-layout-on-x86-64</a></p></div></div><div class="step step-level-1" step="12" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="19200" data-y="0" data-z="0"><h1 id="the-stack-overflow">The stack: Overflow</h1><p>Why not use the Stack for everything?</p><ol><li>Stack size is limited to 8MB (default on Linux).</li><li>Memory is bound to your call hierarchy.</li><li>Stack is per-thread, sharing requires heap.</li></ol><div class="notes"><dl><dt>1: Reason for this are security mostly. Recursion happens on the stack, so</dt><dd><p>endless recursive programs cannot break everything. Also running over the
extents of a buffer in C (Security issue!) will overwrite parts of the
stack, so limiting it makes sense.</p></dd></dl><ol><li>Stack is a LIFO. You cannot free objects down in the stack without
freeing everything in between.</li><li>Every thread (and in Go every goroutine) has their own stack.</li></ol></div><p class="example">Example: code/stackoverflow</p></div><div class="step step-level-1" step="13" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="20800" data-y="0" data-z="0"><h1 id="the-stack-summary">The stack: Summary</h1><ul><li>...cleaned up automatically on return.</li><li>...bound to a function call.</li><li>...low overhead and should be preferred.</li><li>...can be reasoned about during compile time.</li><li>...good for small amounts of data.</li></ul></div><div class="step step-level-1" step="14" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="22400" data-y="0" data-z="0"><h1 id="the-heap-allocations">The Heap: Allocations</h1><pre class="highlight code go"><span class="c1">//go:noinline</span><span class="w">
</span><span class="kd">func</span><span class="w"> </span><span class="nx">f</span><span class="p">()</span><span class="w"> </span><span class="o">*</span><span class="kt">int</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nx">v</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="mi">3</span><span class="w">
    </span><span class="k">return</span><span class="w"> </span><span class="o">&amp;</span><span class="nx">v</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="kd">func</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="c1">// Two for the stack:</span><span class="w">
    </span><span class="c1">// a=0xc00009aef8 b=0xc00009aef0</span><span class="w">
    </span><span class="nx">a</span><span class="p">,</span><span class="w"> </span><span class="nx">b</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="mi">23</span><span class="p">,</span><span class="w"> </span><span class="mi">42</span><span class="w">

    </span><span class="c1">// Two for the heap:</span><span class="w">
    </span><span class="c1">// c=0xc0000b2000 d=0xc0000b2008</span><span class="w">
    </span><span class="nx">c</span><span class="p">,</span><span class="w"> </span><span class="nx">d</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">f</span><span class="p">(),</span><span class="w"> </span><span class="nx">f</span><span class="p">()</span><span class="w">
</span><span class="p">}</span></pre><div class="notes"><p>Contrary to the stack, the memory is not bound to the function
and therefore will survive the return of a function. The downside
is that the memory needs to be freed</p><p>Languages like Go allocate automatically on the heap if they
have to - they do this either when the compiler cannot prove that
the value does not escape the function stack or when the allocation
is too big for the stack. More on this later. Thanks to the GC
memory is freed automatically after it's used. Having a GC is often
understood as "I don't need to think about memory" though, which is not
the case. You can help the GC to run faster and avoid memory leaks
that can arise through edge cases.</p><p>Languages like Python allocate everything on the heap. They almost
never use stack based memory for anything. Most interpreted languages
use a combination of reference counting and garbage collection.
Very convenient but also the slowest way to go.</p><p>Languages like C (and partly Rust) pass the duty of memory management
to the programmer. While this make it possible to be clever, it also
opens up ways to fuck up tremendously by creating memory leaks, double
frees, forgotten allocations or use-after-free scenarios.</p><p>Heap memory must be cleaned up after use. Go does this with a GC.</p><p>Heap grows upwards.</p><p>TODO: Maybe use graphics from here: <a href="https://medium.com/eureka-engineering/understanding-allocations-in-go-stack-heap-memory-9a2631b5035d">https://medium.com/eureka-engineering/understanding-allocations-in-go-stack-heap-memory-9a2631b5035d</a></p></div></div><div class="step step-level-1" step="15" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="24000" data-y="0" data-z="0"><h1 id="the-heap-malloc">The Heap: <tt>malloc()</tt></h1><pre class="highlight code c"><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">ptrs</span><span class="p">[</span><span class="mi">100</span><span class="p">];</span><span class="w">
</span><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">100</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="n">ptrs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">malloc</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="c1">// ... use memory ...
</span><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">100</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="n">free</span><span class="p">(</span><span class="n">ptrs</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span><span class="w">
</span><span class="p">}</span></pre><div class="notes"><p>malloc() is a function that returns N bytes of memory, if available.
It is a syscall of the kernel, but implemented as library in userspace.</p><p>malloc() manages internally a pool of memory internally, from which it
slices of the requested portions. Whenever the pool runs out of fresh
memory, the malloc implementation will ask the kernel for a new chunk
of memory. The exact mechanism is either over sbrk(2) or mmap()
(we will see mmap later)</p><p>As malloc() needs to cater objects of many different sizes (as seen in the
example above) it is prone to fragmentation.</p></div></div><div class="step step-level-1" step="16" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="25600" data-y="0" data-z="0"><h1 id="the-heap-freelist">The Heap: Freelist</h1><img src="images/heap_freelist.png" width="70%"></img><div class="notes"><p>As mentioned above, the memory allocated from the pool
needs to be freed, so it can be re-used. This is done by the free() call.</p><p>malloc() needs to track which parts of its pool are in-use and which can
be issued on the next call. It does by the use of free-lists. Each block
returned by malloc() has a small header (violet) that points to the next block.
The memory returned by malloc() is just behind this small header.</p><p>Once allocated, a free block is taken out of the list and added to the "allocated"
list. This means that every allocation has a small space and time overhead.</p><p>On free(), the opposite happens: The block is put back into the freelist
and out of the "allocated" list.</p><p>(i.e. an allocation is O(log n), instead of O(1) as with the stack)</p><p>Useful Links:</p><ul><li><a href="https://azeria-labs.com/heap-exploitation-part-1-understanding-the-glibc-heap-implementation">https://azeria-labs.com/heap-exploitation-part-1-understanding-the-glibc-heap-implementation</a> (More details)</li><li><a href="https://sourceware.org/git/?p=glibc.git;a=blob;f=malloc/malloc.c;h=05e65a2d54f9b3850fa0c4d2c7dfaae3dfd94dac;hb=HEAD#l54">https://sourceware.org/git/?p=glibc.git;a=blob;f=malloc/malloc.c;h=05e65a2d54f9b3850fa0c4d2c7dfaae3dfd94dac;hb=HEAD#l54</a></li><li><a href="https://sourceware.org/git/?p=glibc.git;a=blob;f=malloc/malloc.c;h=05e65a2d54f9b3850fa0c4d2c7dfaae3dfd94dac;hb=HEAD#l102">https://sourceware.org/git/?p=glibc.git;a=blob;f=malloc/malloc.c;h=05e65a2d54f9b3850fa0c4d2c7dfaae3dfd94dac;hb=HEAD#l102</a>:</li></ul></div></div><div class="step step-level-1" step="17" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="27200" data-y="0" data-z="0"><h1 id="the-heap-leaks">The Heap: Leaks</h1><pre class="highlight code c"><span class="c1">// In C:
</span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">s</span><span class="p">;</span><span class="w">
</span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">malloc</span><span class="p">(</span><span class="mi">20</span><span class="p">);</span><span class="w">
</span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">malloc</span><span class="p">(</span><span class="mi">30</span><span class="p">);</span><span class="w"> </span><span class="c1">// leak: 20 bytes.</span></pre><pre class="highlight code go"><span class="c1">// In Go:</span><span class="w">
</span><span class="kd">var</span><span class="w"> </span><span class="nx">m</span><span class="w"> </span><span class="kd">map</span><span class="p">[</span><span class="kt">string</span><span class="p">][]</span><span class="kt">byte</span><span class="p">{}</span><span class="w">
</span><span class="kd">func</span><span class="w"> </span><span class="nx">f</span><span class="p">(</span><span class="nx">v</span><span class="w"> </span><span class="kt">int</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="c1">// the slice will be still referenced after</span><span class="w">
    </span><span class="c1">// the function returned, if not delete()'d</span><span class="w">
    </span><span class="nx">m</span><span class="p">[</span><span class="s">"blub"</span><span class="p">]</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="nb">make</span><span class="p">([]</span><span class="kt">byte</span><span class="p">,</span><span class="w"> </span><span class="mi">100</span><span class="p">)</span><span class="w">
    </span><span class="k">return</span><span class="w"> </span><span class="nx">v</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">v</span><span class="w">
</span><span class="p">}</span></pre><div class="notes"><p>Other sources of memory leaks:</p><ul><li>Go routines blocking forever.</li><li>Assigning a small slice of a big array to a variable
(causing the whole array to be still referenced)</li></ul><p>Use pprof to find memory leaks in Go.</p><p>In C it's very easy to forget a free(), therefore quite
some impressive tooling developed over the years. The most prominent
example is valgrind: <a href="https://valgrind.org">https://valgrind.org</a></p><p>Python: Also has memory leaks, finding them is much harder
since the tooling is not great (at least when I looked last time).
Also: Memory leaks can happen on the C-side or in the python code
itself. If they happen in a C-module you're pretty much fuc.. lost.</p></div></div><div class="step step-level-1" step="18" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="28800" data-y="0" data-z="0"><h1 id="the-heap-summary">The Heap: Summary</h1><p><strong>Heap</strong></p><ul><li>...needs to be explicitly requested.</li><li>...needs to be explititly cleaned up.</li><li>...can be used until freed. Will crash otherwise.</li><li>...required for big data chunks or long-lived data.</li><li>...has a small, but noticeable, overhead.</li></ul><div class="notes"><p>Heap requires some implementation of malloc(). There are many different implementations
of it in C, using different strategies to perform well under certain load.
Choosing the right kind of allocator is a science in itself. More info can be obtained here:</p><p><a href="https://en.wikipedia.org/wiki/Memory_management#Implementations">https://en.wikipedia.org/wiki/Memory_management#Implementations</a></p><p>In languages like Go you don't have a choice which memory allocator you get. The Go runtime
provides one for you. This makes sense as it is coupled very tightly with the garbage collector.
Go uses a similar implementation, but is more sophisticated. Main difference:
it keeps pre-allocated arenas for differently sized objects. i.e. 4, 8, 16,
32, 64 and so on.</p><p>The grow direction of the heap and stack is not really important and you
should keep in mind that every thread/goroutine has their own stack and
there might be even more than one heap area, possibly backed by different
malloc() implementations.</p></div></div><div class="step step-level-1" step="19" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="30400" data-y="0" data-z="0"><h1 id="garbage-collector-gc">Garbage collector (GC)</h1><img src="images/gc.png" width="100%"></img><div class="notes"><p>GC is a utility that remembers allocation and scans the memory used by the program
for referenes to the allocations. If no references are found it automatically cleans
up the associated memory.</p><p>This is very ergonomic for the programmer, but comes with a peformance impact. The
GC needs to run regularly and has, at least for a very small amount of time, stop
the execution of the program.</p><p>Good reference for the Go GC: <a href="https://tip.golang.org/doc/gc-guide">https://tip.golang.org/doc/gc-guide</a></p></div></div><div class="step step-level-1" step="20" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="32000" data-y="0" data-z="0"><h1 id="gc-pressure">GC: Pressure</h1><pre class="highlight code go"><span class="c1">// Prefer this...</span><span class="w">
</span><span class="nx">m</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nb">make</span><span class="p">(</span><span class="kd">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="nx">someStruct</span><span class="p">)</span><span class="w">

</span><span class="c1">// ...over this:</span><span class="w">
</span><span class="nx">m</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nb">make</span><span class="p">(</span><span class="kd">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="o">*</span><span class="nx">someStruct</span><span class="p">)</span></pre><p class="example">Example: code/allocs</p><pre class="highlight code bash"><span class="c1"># counting words with a map:
</span>$<span class="w"> </span>go<span class="w"> </span><span class="nb">test</span><span class="w"> </span>-v<span class="w"> </span>-bench<span class="o">=</span>.<span class="w"> </span>-benchmem<span class="w">
</span>noptr<span class="w">  </span><span class="m">577</span>.7<span class="w"> </span>ns/op<span class="w">   </span><span class="m">336</span><span class="w"> </span>B/op<span class="w">   </span><span class="m">2</span><span class="w"> </span>allocs/op<span class="w">
</span>ptr<span class="w">    </span><span class="m">761</span>.4<span class="w"> </span>ns/op<span class="w">   </span><span class="m">384</span><span class="w"> </span>B/op<span class="w">  </span><span class="m">10</span><span class="w"> </span>allocs/op</pre><div class="notes"><p>"GC Pressure" describes the amount of load a garbage collector currently has.
The more small objects it has to track, the higher the load. You can help it
by reducing the amount of different objects and making use of sync.Pools (see later)</p><p>One way to less use memory is to use less pointers:</p><ul><li>Way less memory in total (one cell less for the pointer)</li><li>Data is packed together (good for the CPU cache!)</li><li>Less work for the GC and the allocator to do</li><li>Pointers give you more potential to fuck up (they can be nil...)</li></ul><p>The "10" will increase with input size!
Longer runs will cause more GC for the ptr case.</p></div></div><div class="step step-level-1" step="21" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="33600" data-y="0" data-z="0"><h1 id="gc-escape-analysis">GC: Escape Analysis</h1><img src="images/escape_analysis.jpg" width="100%"></img><pre class="highlight code bash">$<span class="w"> </span>go<span class="w"> </span>build<span class="w"> </span>-gcflags<span class="o">=</span><span class="s2">"-m"</span><span class="w"> </span>.<span class="w">
</span>./main.go:5:2:<span class="w"> </span>moved<span class="w"> </span>to<span class="w"> </span>heap:<span class="w"> </span>x</pre><div class="notes"><p>Only heap allocated data is managed by the garbage collector.
The more you allocate on the heap, the more pressure you put on the
memory bookkeeping and the garbage collector.</p><ul><li>Avoid using pointers and refactor to make it allocate-able on the stack.</li><li>Prefer pass &amp; return by value if value is small (&lt; 64 byte ~= cache line)</li><li>Use sync.Pool to save allocations.</li></ul><p>Good guide for the details: <a href="https://tip.golang.org/doc/gc-guide#Eliminating_heap_allocations">https://tip.golang.org/doc/gc-guide#Eliminating_heap_allocations</a></p><p>Picture source: <a href="https://dev.to/karankumarshreds/memory-allocations-in-go-1bpa">https://dev.to/karankumarshreds/memory-allocations-in-go-1bpa</a></p></div></div><div class="step step-level-1" step="22" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="35200" data-y="0" data-z="0"><h1 id="gc-pre-allocate">GC: Pre-Allocate</h1><pre class="highlight code go"><span class="nx">s</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nb">make</span><span class="p">([]</span><span class="kt">int</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="nx">input</span><span class="p">))</span><span class="w">
</span><span class="nx">m</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nb">make</span><span class="p">(</span><span class="kd">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="kt">int</span><span class="p">,</span><span class="w"> </span><span class="mi">20</span><span class="p">)</span><span class="w">
</span><span class="c1">// ...</span><span class="w">

</span><span class="c1">// If you need to concatenate many strings:</span><span class="w">
</span><span class="kd">var</span><span class="w"> </span><span class="nx">b</span><span class="w"> </span><span class="nx">strings</span><span class="p">.</span><span class="nx">Builder</span><span class="w">
</span><span class="nx">b</span><span class="p">.</span><span class="nx">Grow</span><span class="p">(</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">13</span><span class="p">)</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="nx">idx</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="nx">idx</span><span class="w"> </span><span class="p">&lt;</span><span class="w"> </span><span class="mi">100</span><span class="p">;</span><span class="w"> </span><span class="nx">idx</span><span class="o">++</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nx">b</span><span class="p">.</span><span class="nx">WriteString</span><span class="p">(</span><span class="s">"Hello World!\n"</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="nx">b</span><span class="p">.</span><span class="nx">String</span><span class="p">())</span></pre><p class="example">Example: code/prealloc</p></div><div class="step step-level-1" step="23" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="36800" data-y="0" data-z="0"><h1 id="gc-pooling">GC: Pooling</h1><pre class="highlight code go"><span class="c1">// avoid expensive allocations by pooling:</span><span class="w">
</span><span class="kd">var</span><span class="w"> </span><span class="nx">writerGzipPool</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="nx">sync</span><span class="p">.</span><span class="nx">Pool</span><span class="p">{</span><span class="w">
    </span><span class="c1">// other good candidates: bytes.Buffer{},</span><span class="w">
    </span><span class="c1">// big slices, empty objects used for unmarshal</span><span class="w">
    </span><span class="nx">New</span><span class="p">:</span><span class="w"> </span><span class="kd">func</span><span class="p">()</span><span class="w"> </span><span class="kt">any</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="k">return</span><span class="w"> </span><span class="nx">gzip</span><span class="p">.</span><span class="nx">NewWriter</span><span class="p">(</span><span class="nx">ioutil</span><span class="p">.</span><span class="nx">Discard</span><span class="p">)</span><span class="w">
    </span><span class="p">},</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="nx">w</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">writerGzipPool</span><span class="p">.</span><span class="nx">Get</span><span class="p">().(</span><span class="o">*</span><span class="nx">gzip</span><span class="p">.</span><span class="nx">Writer</span><span class="p">)</span><span class="w">
</span><span class="c1">// ... use w ...</span><span class="w">
</span><span class="nx">writerGzipPool</span><span class="p">.</span><span class="nx">Put</span><span class="p">(</span><span class="nx">w</span><span class="p">)</span></pre><p class="example">Example: code/mempool</p><div class="notes"><p>Pooling is the general technique of keeping a set of objects that are expensive object,
if they can be re-used. Typical examples would be thread pools that keep running threads
around, instead of firing up a new one for every task. Same can be done for memory objects
that are expensive to allocate (or have long-running init code like gzip.Writer).</p><p>Pools can be easily implemented using an array (or similar) and a mutex.
sync.Pool is a Go-specific solution that has some knowledge of the garbage collector
which would be not available to normal programs otherwise. It keeps a set of objects
around until they would be garbage collected anyways. I.e. the objects in the pool
get automatically freed after one or two GC runs.</p></div></div><div class="step step-level-1" step="24" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="38400" data-y="0" data-z="0"><h1 id="gc-internment-1">GC: Internment #1</h1><pre class="highlight code go"><span class="c1">// type StringHeader struct {</span><span class="w">
</span><span class="c1">//         Data uintptr</span><span class="w">
</span><span class="c1">//         Len  int</span><span class="w">
</span><span class="c1">// }</span><span class="w">
</span><span class="kd">func</span><span class="w"> </span><span class="nx">stringptr</span><span class="p">(</span><span class="nx">s</span><span class="w"> </span><span class="kt">string</span><span class="p">)</span><span class="w"> </span><span class="kt">uintptr</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="o">*</span><span class="nx">reflect</span><span class="p">.</span><span class="nx">StringHeader</span><span class="p">)(</span><span class="nx">unsafe</span><span class="p">.</span><span class="nx">Pointer</span><span class="p">(</span><span class="o">&amp;</span><span class="nx">s</span><span class="p">)).</span><span class="nx">Data</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="kd">func</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nx">s1</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="s">"123"</span><span class="w">
    </span><span class="nx">s2</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">s1</span><span class="w">
    </span><span class="nx">s3</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="s">"1"</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s">"2"</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s">"3"</span><span class="w">
    </span><span class="nx">s4</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="s">"12"</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">strconv</span><span class="p">.</span><span class="nx">FormatInt</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">)</span><span class="w">
    </span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Printf</span><span class="p">(</span><span class="s">"0x%x 0x%x 0x%x 0x%x\n"</span><span class="p">,</span><span class="w">
        </span><span class="nx">stringptr</span><span class="p">(</span><span class="nx">s1</span><span class="p">),</span><span class="w"> </span><span class="c1">// 0x000049a4c2</span><span class="w">
        </span><span class="nx">stringptr</span><span class="p">(</span><span class="nx">s2</span><span class="p">),</span><span class="w"> </span><span class="c1">// 0x000049a4c2</span><span class="w">
        </span><span class="nx">stringptr</span><span class="p">(</span><span class="nx">s3</span><span class="p">),</span><span class="w"> </span><span class="c1">// 0x000049a4c2</span><span class="w">
        </span><span class="nx">stringptr</span><span class="p">(</span><span class="nx">s4</span><span class="p">),</span><span class="w"> </span><span class="c1">// 0xc000074ed0</span><span class="w">
    </span><span class="p">)</span><span class="w">
</span><span class="p">}</span></pre></div><div class="step step-level-1" step="25" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="40000" data-y="0" data-z="0"><h1 id="gc-internment-2">GC: Internment #2</h1><pre class="highlight code go"><span class="kd">type</span><span class="w"> </span><span class="nx">stringInterner</span><span class="w"> </span><span class="kd">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="kt">string</span><span class="w">

</span><span class="kd">func</span><span class="w"> </span><span class="p">(</span><span class="nx">si</span><span class="w"> </span><span class="nx">stringInterner</span><span class="p">)</span><span class="w"> </span><span class="nx">Intern</span><span class="p">(</span><span class="nx">s</span><span class="w"> </span><span class="kt">string</span><span class="p">)</span><span class="w"> </span><span class="kt">string</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="k">if</span><span class="w"> </span><span class="nx">interned</span><span class="p">,</span><span class="w"> </span><span class="nx">ok</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">si</span><span class="p">[</span><span class="nx">s</span><span class="p">];</span><span class="w"> </span><span class="nx">ok</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="k">return</span><span class="w"> </span><span class="nx">interned</span><span class="w">
    </span><span class="p">}</span><span class="w">
    </span><span class="nx">si</span><span class="p">[</span><span class="nx">s</span><span class="p">]</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="nx">s</span><span class="w">
    </span><span class="k">return</span><span class="w"> </span><span class="nx">s</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="kd">func</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nx">si</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">stringInterner</span><span class="p">{}</span><span class="w">
    </span><span class="nx">s1</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">si</span><span class="p">.</span><span class="nx">Intern</span><span class="p">(</span><span class="s">"123"</span><span class="p">)</span><span class="w">
    </span><span class="nx">s2</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">si</span><span class="p">.</span><span class="nx">Intern</span><span class="p">(</span><span class="nx">strconv</span><span class="p">.</span><span class="nx">Itoa</span><span class="p">(</span><span class="mi">123</span><span class="p">))</span><span class="w">
    </span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="nx">stringptr</span><span class="p">(</span><span class="nx">s1</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nx">stringptr</span><span class="p">(</span><span class="nx">s2</span><span class="p">))</span><span class="w"> </span><span class="c1">// true</span><span class="w">
</span><span class="p">}</span></pre><div class="notes"><p>Advantage:</p><ul><li>Strings can be compared by the compiler by ptr equality.</li><li>Less memory is used.</li></ul><p>Further examples and the full impressive benchmark can be found here:</p><p><a href="https://artem.krylysov.com/blog/2018/12/12/string-interning-in-go">https://artem.krylysov.com/blog/2018/12/12/string-interning-in-go</a></p></div></div><div class="step step-level-1" step="26" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="41600" data-y="0" data-z="0"><h1 id="gc-internment-3">GC: Internment #3</h1><pre class="highlight code go"><span class="c1">// Measuring speed of string comparisons:</span><span class="w">
</span><span class="nx">BenchmarkStringCompare1</span><span class="o">-</span><span class="mi">4</span><span class="w">         </span><span class="mf">1.873</span><span class="w"> </span><span class="nx">ns</span><span class="o">/</span><span class="nx">op</span><span class="w">
</span><span class="nx">BenchmarkStringCompare10</span><span class="o">-</span><span class="mi">4</span><span class="w">        </span><span class="mf">4.816</span><span class="w"> </span><span class="nx">ns</span><span class="o">/</span><span class="nx">op</span><span class="w">
</span><span class="nx">BenchmarkStringCompare100</span><span class="o">-</span><span class="mi">4</span><span class="w">       </span><span class="mf">9.481</span><span class="w"> </span><span class="nx">ns</span><span class="o">/</span><span class="nx">op</span><span class="w">
</span><span class="nx">BenchmarkStringCompareIntern1</span><span class="o">-</span><span class="mi">4</span><span class="w">   </span><span class="mf">1.830</span><span class="w"> </span><span class="nx">ns</span><span class="o">/</span><span class="nx">op</span><span class="w">
</span><span class="nx">BenchmarkStringCompareIntern10</span><span class="o">-</span><span class="mi">4</span><span class="w">  </span><span class="mf">1.868</span><span class="w"> </span><span class="nx">ns</span><span class="o">/</span><span class="nx">op</span><span class="w">
</span><span class="nx">BenchmarkStringCompareIntern100</span><span class="o">-</span><span class="mi">4</span><span class="w"> </span><span class="mf">1.965</span><span class="w"> </span><span class="nx">ns</span><span class="o">/</span><span class="nx">op</span></pre><p class="example">Example: code/internment</p><div class="notes"><p>Internment scales incredibly well.</p><p>Good usecases:</p><ul><li>Reading words of natural language.</li><li>Enum-like strings like country names.</li><li>Interning keys of json objects.</li></ul><p>Bad usecases:</p><ul><li>Internment for input that is very long
and cannot be predicted (tweets e.g.)</li></ul></div></div><div class="step step-level-1" step="27" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="43200" data-y="0" data-z="0"><h1 id="gc-memory-limit">GC: Memory Limit</h1><pre class="highlight code bash">$<span class="w"> </span><span class="nv">GOMEMLIMIT</span><span class="o">=</span>2000M<span class="w"> </span>go<span class="w"> </span>run<span class="w"> </span>app.go</pre><img src="images/deephealth_mem.png" width="100%"></img><div class="notes"><p>Linux only supports setting a max amount of memory that a process (or cgroup)
may consume. If the limit is exceeded, then the process (or cgroup) is killed.
This makes the limit a hard limit, which is seldomly useful.</p><p>What is more useful is to have a soft limit, that makes the application attempt
to free memory before it reaches the limit. As the garbage collector normally
has a backlog of short-lived (i.e. memory on the heap that gets regularly freed)
it could peak over a hard limit (6G in the diagram) for a short moment of time.
By setting a GOMEMLIMIT we can tell the GC to run the</p><p>More Info:
<a href="https://weaviate.io/blog/gomemlimit-a-game-changer-for-high-memory-applications">https://weaviate.io/blog/gomemlimit-a-game-changer-for-high-memory-applications</a></p></div></div><div class="step step-level-1" step="28" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="44800" data-y="0" data-z="0"><h1 id="virtual-memory-vm">Virtual memory (VM)</h1><img src="images/elephant_in_the_room.jpg" width="100%"></img><div class="notes"><p>Let's talk about the elephant in the room: The adress of a value
is not the adress in physical memory. How can we proof it?</p></div></div><div class="step step-level-1" step="29" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="46400" data-y="0" data-z="0"><h1 id="vm-the-mapping">VM: The mapping</h1><img src="images/virtual_memory.png" width="80%"></img><div class="notes"><ul><li>The physical memory of a system is splitted up into 4k pages.</li><li>Each process maintains a virtual memory mapping table, mapping
from the virtual range of memory to physical memory.</li><li>Address translation is handled efficiently by the MMU</li></ul><p>Wait, those addresses I saw earlier... are those the addrs in RAM?
Hopefully not, because otherwise you could somehow find out where the OpenSSH
server lives in memory and steal it's keys. For security reasons it must look
for each process like he's completely alone on the system. What you saw above
are virtual memory addresses and they stay very similar on each run.</p><p>The concept how this achieved is called "virtual memory" and it's probably one of
the more clever things we did in computer science.</p></div></div><div class="step step-level-1" step="30" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="48000" data-y="0" data-z="0"><h1 id="vm-implementation">VM: implementation</h1><pre class="highlight code bash">$<span class="w"> </span>cat<span class="w"> </span>/proc/&lt;pid&gt;/maps<span class="w">
</span>55eab7237000-55eab7258000<span class="w"> </span>rw-p<span class="w">  </span><span class="o">[</span>heap<span class="o">]</span><span class="w">
</span>...<span class="w">
</span>7f54a1c18000-7f54a1c3a000<span class="w"> </span>r--p<span class="w">  </span>/usr/lib/libc.so.6<span class="w">
</span>...<span class="w">
</span>7ffe78a26000-7ffe78a47000<span class="w"> </span>rw-p<span class="w">  </span><span class="o">[</span>stack<span class="o">]</span></pre><p>Each process has a &#xBB;<em>Page Table</em>&#xAB; mapping virtual to physical memory.</p><div class="notes"><p>On process start this table is filled with a few default kilobytes of mapped pages
(the first few pages are not mapped, so dereferencing a NULL pointer will always crash)</p><p>When the program first accesses those addresses the CPU will generate a page fault, indicating
that there is no such mapping. The OS receives this and will find a free physical page, map
it and retry execution. If another page fault occurs the OS will kill the process with SIGSEGV.</p></div></div><div class="step step-level-1" step="31" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="49600" data-y="0" data-z="0"><h1 id="vm-advantages">VM: Advantages</h1><ul><li>Pages can be mapped only once used (CoW)</li><li>Several processes can share the same pages</li><li>Pages do not need to be mapped to physical memory: Disk, DMA or even network is possible!</li><li>Processes are isolated from each other.</li><li>Processes consume only as much physical (<em>&#xBB;residual&#xAB;</em>) memory as really needed.</li><li>Programs get easier to write because they can just assume that the memory is not fragmented.</li><li>Pages can be swapped to disk by the OS without the process even noticing</li><li>The kernel can give away more memory than there is on the system (overcommiting)</li><li>Pages with the same content can be deduplicated</li><li>Kernel may steal pages of inactive processes</li></ul></div><div class="step step-level-1" step="32" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="51200" data-y="0" data-z="0"><h1 id="vm-swapping">VM: Swapping</h1><pre class="highlight code bash"><span class="c1"># Create some space for swapping:
</span>$<span class="w"> </span>dd<span class="w"> </span><span class="k">if</span><span class="o">=</span>/dev/zero<span class="w"> </span><span class="nv">of</span><span class="o">=</span>swapfile<span class="w"> </span><span class="nv">count</span><span class="o">=</span><span class="m">1024</span><span class="w"> </span><span class="nv">bs</span><span class="o">=</span>1M<span class="w">
</span>$<span class="w"> </span>swapon<span class="w"> </span>./swapfile<span class="w">

</span><span class="c1"># Check how eager the system is to use the swap
# with a value between 0-100. This is the percentage
# of RAM that is left before swapping starts.
</span>$<span class="w"> </span>cat<span class="w"> </span>/proc/sys/vm/swappiness<span class="w">
</span><span class="o">(</span>a<span class="w"> </span>value<span class="w"> </span>between<span class="w"> </span><span class="m">0</span>-100<span class="o">)</span><span class="w">

</span><span class="c1"># 0   = only swap if OOM would hit otherwise.
# 100 = swap everything not actively used.
#  60 = default for most desktops.
# &lt;10 = good setting for database servers</span></pre><div class="notes"><p>Linux can use swap space as second-prio memory if main memory runs low.
Swap is already used before memory goes low. Inactive processes and stale IO pages
get put to swap so that memory management can make use of that space to provide less
fragmented memory regions.</p><p>How aggressive this happens can be set using vm.swappiness. A value between</p><p>Rules:</p><ul><li>If you want to hibernate (i.e. powerless suspend) then you need as much swap as RAM.</li><li>Otherwise about half of RAM is a good rule of thumb.</li><li>Systems that rely on low latency (i.e. anything that goes in the direction of realtime) should not swap.</li></ul></div></div><div class="step step-level-1" step="33" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="52800" data-y="0" data-z="0"><h1 id="profiling-residual-memory-vs-virtual-memory">Profiling: Residual memory vs virtual memory</h1><img src="images/res_vs_virtual.png" width="100%"></img><div class="notes"><p>Picture above showing htop on my rather old laptop
with a normal workload. The amount of virtual memory for some programs
like signal-desktop is HUGE and only a tiny portion is actually used.</p><p>Fun fact: The program I was actively using was gimp, but the actual
performance hogs were all browser-based applications. Brave new world.</p></div></div><div class="step step-level-1" step="34" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="54400" data-y="0" data-z="0"><h1 id="profiling-quick-dirty">Profiling: Quick &amp; dirty</h1><pre class="highlight code bash"><span class="c1"># Show the peak residual memory usage:
</span>$<span class="w"> </span>/usr/bin/time<span class="w"> </span>-v<span class="w"> </span>&lt;command&gt;<span class="w">
</span>...<span class="w">
</span>Maximum<span class="w"> </span>resident<span class="w"> </span><span class="nb">set</span><span class="w"> </span>size<span class="w"> </span><span class="o">(</span>kbytes<span class="o">)</span>:<span class="w"> </span><span class="m">16192</span><span class="w">
</span>...</pre><div class="line-block"><br></br><br></br></div><p class="example">Example: code/virtualmem</p><div class="notes"><p>Start ./virt and observe in htop how the virtual memory is immediately there
and the residual memory slowly increases second by second. The program will
crash if you wait long enough.</p><p>Start with '/usr/bin/time -v ./virt' and interrupt at any time.</p></div></div><div class="step step-level-1" step="35" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="56000" data-y="0" data-z="0"><h1 id="profiling-pprof">Profiling: <tt>pprof</tt></h1><img src="images/pprof_heap.svg" width="100%"></img><div class="notes"><p>Works similar to the CPU profile and gives us a good overview.
The little cubes mean "x memory was allocated in y size batches".</p><p>The pprof output is also available as flamegraph if you prefer
this kind of presentation.</p></div></div><div class="step step-level-1" step="36" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="57600" data-y="0" data-z="0"><h1 id="profiling-monitoring">Profiling: Monitoring</h1><img src="images/memleak_grafana.png" width="100%"></img><div class="notes"><p>No way around it. Profiling and benchmarking leave a gap:
long running applications where you do not expect performance issues.
In that case you should always monitor resource usage so you can check
when and how fast memory usage increased (and maybe correlate with load)</p><p>When you notice issues you can do profiling via pprof.</p></div></div><div class="step step-level-1" step="37" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="59200" data-y="0" data-z="0"><h1 id="profiling-pyroscope">Profiling: Pyroscope</h1><img src="images/pyroscope.png" width="100%"></img><p><a href="https://pyroscope.io/docs/golang">Pyroscope</a></p><div class="notes"><p>Especially long-running memorly leaks are hard to debug
(i.e. when memory accumulates over the course of several days e.g.)</p><p>In this it can help to combine monitoring and profiling. This is sometimes
called "continuous profiling" therefore. Pyroscope is one of those tools.</p><p>A short article on how to integrate this with Go services:
<a href="https://grafana.com/blog/2023/04/19/how-to-troubleshoot-memory-leaks-in-go-with-grafana-pyroscope/">https://grafana.com/blog/2023/04/19/how-to-troubleshoot-memory-leaks-in-go-with-grafana-pyroscope/</a></p><p>Demo for Go:
<a href="https://demo.pyroscope.io/?query=rideshare-app-golang.cpu%7B%7D&amp;from=1682450314&amp;until=1682450316">https://demo.pyroscope.io/?query=rideshare-app-golang.cpu%7B%7D&amp;from=1682450314&amp;until=1682450316</a></p></div></div><div class="step step-level-1" step="38" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="60800" data-y="0" data-z="0"><h1 id="the-oom-killer">The OOM Killer</h1><img src="images/oom.jpg" width="50%"></img><div class="notes"><ul><li>Kicks in if system almost completely ran out of RAM.</li><li>Selects a process based on a scoring system and kills it.</li><li>Processes can be given a priority in advance.</li><li>Last resort mechanism.</li><li>Reports in dmesg.</li><li>Sometimes comes too late and is not able to operate anymore.</li></ul><p>Alternatives:</p><ul><li>earlyoom</li><li>systemd-oomd</li></ul><p>Userspace-Daemons that monitor memory usage and kill processes
in a very configurable way. Well suited for server systems.</p></div></div><div class="step step-level-1" step="39" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="62400" data-y="0" data-z="0"><h1 id="fynn">Fynn!</h1></div></div><div id="slide-number" class="slide-number">
         1
      </div><script type="text/javascript" src="js/impress.js"></script><script type="text/javascript" src="js/gotoSlide.js"></script><script type="text/javascript" src="js/hovercraft.js"></script><script type="text/javascript">
      document.getElementById("impress").addEventListener("impress:stepenter", update_slide_number, false);
    </script></body></html>