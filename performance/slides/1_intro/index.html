<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml"><head><title>Performance: Intro</title><meta charset="UTF-8"></meta><meta name="generator" content="Hovercraft! 1.0 http://regebro.github.com/hovercraft"></meta><link rel="stylesheet" href="css/hovercraft.css" media="all"></link><link rel="stylesheet" href="css/highlight.css" media="all"></link><link rel="stylesheet" href="hovercraft.css" media="screen,projection"></link><script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        showProcessingMessages: false,
        messageStyle: "none",
        TeX : { extensions : ['color.js'] }
      });
    </script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script></head><body class="impress-not-supported"><div id="impress-help"></div><div id="impress" data-transition-duration="1500"><div class="step step-level-1" step="0" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="0" data-y="0" data-z="0"><h1 id="what-s-that">What's that?</h1><img src="images/moores_law.png" width="100%"></img></div><div class="step step-level-1" step="1" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="1600" data-y="0" data-z="0"><h1 id="who-s-that">Who's that?</h1><img src="images/bill_taketh.jpg" width="100%"></img><div class="notes"><p>General idea:</p><ul><li>Maybe you heard of Moore's law? Computing power doubles every two years</li><li>Andy and Bill's law: What Andy Grove (Intel ex-CEO) produces in Hardware speed, Bill Gates takes away.</li><li>Lemur's law: Software engineers get twice as incompentent every decade (only half ironic) - seriously, as an engineering discipline we should be
ashamed of how bad we performed over the last decades. We introduced so many layers of bad software and hacks that we depend on that we can't
change anymore. It's like building a complete city on sand. Part of this because we don't really do engineerings and focus so much on providing
company value that many of us did not even learn how good, performance optimized is supposed to look like. The costs of software engineers
is more expensive than hardware these days, but this is short sighted. Investing in quality long term benefits us all.
I hope to change your perspective a bit in this talk. We all lost the connection to the machine our programs run on and while the things in this
talk were somewhat common knowledge 20 years ago (at least parts of it) it became somehow obscure knowledge over time and universities just focused
on disciplines like web development and data science where you're not supposed to have this knowledge. Because you know, numpy and pandas does it for you.
Or the browser will just do the right thing.</li><li>In the 90s we still squeezed every byte of memory out of game consoles and did both amazing and scary optimizations to get basic functionality.</li><li>And last decade we invented things like Electron, a lazy-ass way to make
applications "portable" by just starting a browser for every application
- I don't want you guys to invent something like Electron</li><li>If you think Electron is a good idea, then please stop doing anything related to software engineering.</li><li>Maybe try gardening, or do waterboarding in Guantanamo. Just do something less hurtful to mankind than Electron</li><li>Seriously take some pride as software engineerings and try to leave a solid legacy to the next generation of engineers.</li><li>Teaching you about the internals of program execution.</li><li>Very neglected field - not much teached in studies, during day-to-day work "it worked (once)" is more important.</li></ul><p>Disclaimer:</p><ul><li>We're working from low level to slightly higher level here. Don't expect tips like "use this data structure to make
stuff incredibly fast". I'll won't go over all possible performance tips for your language (there are better
lists on the internet). I also won't go over a lot of data structures - what I do show is to show you how to choose
a data structure.</li><li>The talk is loosely tied to the hardware: General intro, cpu, mem, io, parallel programming</li><li>Most code examples will be in Go and C, as most ideads require a compiled language.</li><li>Interpreted languages like Python/Typescript might take away a few concepts, but to be honest,
your language is fucked up and will never achieve solid performance.</li><li>For Python you can at least put performance criticals into C libraries, for the blistering cestpool
that web technology is... well, I guess your only hope is Webassembly.</li><li>If you are unsure how a specific concept translates to your language: just ask. I might have no idea,
but often there is only a limited choice of design decisions language designers can make.</li><li>In this talk you will learn why people invent things Webassembly - even though it's kinda sad.</li></ul></div></div><div class="step step-level-1" step="2" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="3200" data-y="0" data-z="0"><h1 id="simple-can-be-complex">Simple can be complex</h1><pre class="highlight code python"><span class="kn">import</span> <span class="nn">sys</span><span class="w">
</span><span class="nb">print</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span></pre><div class="notes"><p>The prior rules assume that we're able to understand what's going on
in our program. After all we have to judge what gets executed ultimately.
Turns out, in interpreted language this is very hard.</p><p>Interpreted -&gt; compiled to byte code.
sys.stdin.readline are two dict lookups.
memory allocations
file I/O from stdin to stdout
calling a c function (strip)
unicode conversion!</p></div></div><div class="step step-level-1" step="3" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="4800" data-y="0" data-z="0"><h1 id="inside-python">Inside Python &#x1F40D;</h1><pre class="highlight code c"><span class="k">static</span><span class="w"> </span><span class="n">PyObject</span><span class="w"> </span><span class="o">*</span><span class="w">
</span><span class="nf">strip</span><span class="p">(</span><span class="n">PyObject</span><span class="w"> </span><span class="o">*</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">PyObject</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span><span class="w">
    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">PyArg_ParseTuple</span><span class="p">(</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="s">"s"</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">s</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="k">return</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span><span class="w">
    </span><span class="p">}</span><span class="w">

    </span><span class="cm">/* ... actual "strip" logic here ... */</span><span class="w">
    </span><span class="k">return</span><span class="w"> </span><span class="n">PyUnicode_FromString</span><span class="p">(</span><span class="n">s</span><span class="p">);</span><span class="w">
</span><span class="p">}</span></pre><div class="notes"><p>All functions eventuall call functions implemented in C:</p><p>And that happens for every function call in Python. Very often.
All those objects are allocated on the heap. Python is easy, but the price you pay for it
is high. This might give you a first feeling on how much stuff happens in a simple program.</p><p>Printing to stdout and drawing something on the screen is insanely complex too and beyond
this workshop.</p><p>This slides could be also a talk about "Why interpreted languages suck"</p><p>Most optimizations will not work with python.
As a language it's really disconnected from the HW - every single statement
will cause 100s or 1000s of assembly instructions. Also there are no almost
no guarantees how big e.g. arrays or other data structures will be and how
they are layout in memory. You have to rely on your interpreter (and I count
Java's JIT as one!) to be fast on modern hardware - most are not and that's
why there's so much C libraries in python, making the whole packaging system
a bloody mess.</p></div></div><div class="step step-level-1" step="4" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="6400" data-y="0" data-z="0"><h1 id="workshop-contents">Workshop contents</h1><ul><li>Why is performance important?</li><li>How does the machine we program on work?</li><li>Are there ways to exploit this machine?</li></ul><p><em>Remember:</em> <strong>Work</strong> shop.</p><div class="notes"><p>If you can answer these questions to your own
liking, then you succeeded. I can't yet.</p></div></div><div class="step step-level-1" step="5" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="8000" data-y="0" data-z="0"><h1 id="what-s-missing">What's missing?</h1><ul><li>An exhausting list of tips. You'd forget them.</li><li>A full lecture on algorithm and data structures.</li><li>A lecture you just have to listen to make it click.</li><li>Language specific optimization techniques.</li><li>Performance in distributed systems.</li><li>Application specific performance tips (<em>Networking, SQL, Data</em> ...)</li></ul><div class="notes"><p>Google: I mean that. After the workshop you know what to google for. Hopefully.</p><p>There are plenty free online courses and many books. I can't really recommend one,
as my lecture in university is also already 10 years ago now.</p><p>Languages: includes C, Go, Python and a bit of Bash though.
Most code examples are written with compiled languages in mind.
Users of interpreted languages may find some things unintuitive.</p><p>Check that "interpreted" and "compiled" is a known distinction.</p></div></div><div class="step step-level-1" step="6" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="9600" data-y="0" data-z="0"><h1 id="experiments-mandatory">Experiments mandatory &#x1F97C;</h1><p>You'll write your own <em>cute</em> database:</p><ul><li>You can group up or do it on our own.</li><li>You can use your favourite language.</li><li>You can always ask me outside or in the workshop about your progress and problems.</li></ul><div class="notes"><p>But do the database for yourself, not for me.</p></div></div><div class="step step-level-1" step="7" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="11200" data-y="0" data-z="0"><h1 id="what-is-optimization">What is optimization?</h1><p>Please define it in your words.</p><div class="notes"><p>In computer science, optimization is the process of modifying
a software system to make some aspect of it work more efficiently
or use fewer resources. -- Wikipedia</p><p>The "fewer resources" is the more important bit. See yourself as tenant
of resources like CPU, Mem, disk, network, dbs, ... that you share with
other tenants of the same system. Be nice to other tenants, don't just
make your own life pleasant.</p></div></div><div class="step step-level-1" step="8" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="12800" data-y="0" data-z="0"><h1 id="when-to-optimize">When to optimize?</h1><p>If <strong>performance requirements</strong> are not met <strong>and</strong> when doing so does not hurt other requirements.</p><div class="notes"><p>Wait, there are such requirements?</p><p>Most of us do implicit requirements: Does it feel fast enough?
So probably more often than you do now.</p><p>Other requirements: Maintenability and readability e.g.
or correctness.</p></div></div><div class="step step-level-1" step="9" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="14400" data-y="0" data-z="0"><h1 id="questions-to-ask">Questions to ask:</h1><ul><li>On what kind of system the software will run on?</li><li>How many requests will there be in parallel?</li><li>What kind of latency is the user willing to accept? (<em>Games, Websites, ATMs</em>, ...)</li><li>How much scaling is expected in the next time?</li><li>How long can we do without? Do we need it now?</li><li>Will my technology choice be a bottleneck? (<em>Python, React, Electron, ...</em>)</li><li>Does <em>EdgeCaseX</em> need to perform well?</li><li>Are the optimizations worth the risk/effort?</li><li>...</li></ul><div class="notes"><p>It's your job to figure out the performance requirements. Your PM will likely not be
technical enough to set realisitc goals, so you need to discuss with him what kind
of use cases you have and what kind of performance is acceptable for them (the latter is your part)
Figure out possible edge cases together (i.e. pathological use cases bringing down your requirement)
The engineer is the driver of the conversation, as he know's where the problems are.</p><p>Do some basic calculations based on these questions and add X to your goals. Those are your
requirements.</p></div></div><div class="step step-level-1" step="10" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="16000" data-y="0" data-z="0"><h1 id="when-not-to-optimize">When not to optimize?</h1><div class="line-block">"Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered. We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil. Yet we should not pass up our opportunities in that critical 3%."<br></br>- Donald Knuth<br></br></div><div class="notes"><p>I used the full quote here, since it's often abbreviated as "premature optimization is the root of all evil" which
has a totally different meaning.</p><p>Many programmers just asked "how fast can it be?" and not "how fast should it be?"
That's a fine question for personal learning but not for an actual product where time is a resource.</p><p>If you don't have a problem you really should not do anything.
It is difficult to define what a "problem" is.</p><p>Electron apparently defined that it's not a problem if low-memory devices
can't use their framework.</p></div></div><div class="step step-level-1" step="11" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="17600" data-y="0" data-z="0"><h1 id="huh-premature">Huh, premature?</h1><img src="images/premature_optimization_flowchart.png" width="35%"></img><p><strong>Reminder:</strong> <em>It does not matter how fast you compute a wrong result.</em></p><div class="notes"><p>Proof: There's a xkcd for everything.</p><p>The main point is: Take your time to do things the right away. Don't drop the pen
when it worked for the first time and didn't feel slow, really take some to measure.</p><p>However, don't just blindly optimize things before you measured or optimize the small
things after measuring.</p><p>Optimizations come at a price. It's usually more and harder code to maintain (and if not,
why didn't you do it in the first place?) or they have some other disadavntages (an index
in a database for example slows drown writes and needs space!). Is it worth the risk?</p></div></div><div class="step step-level-1" step="12" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="19200" data-y="0" data-z="0"><h1 id="how-do-i-measure">How do I measure?</h1><p>In a reproducible environment.</p><p>(<a href="https://gernot-heiser.org/benchmarking-crimes.html">Best practices</a>)</p><img src="diagrams/1_how_do_i_measure.svg" width="100%"></img><div class="notes"><p>Only ever compare apples with apples. Don't compare numbers
between:</p><ul><li>Different machines.</li><li>Different runs with different load on the same machine.</li><li>Different inputs.</li><li>Different implementations if they do not produce the same results.</li></ul><p>Use benchmarks primarily to compare numbers of older benchmarks.
And if you have to compare different implementations: Stay fair.</p></div></div><div class="step step-level-1" step="13" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="20800" data-y="0" data-z="0"><h1 id="how-to-optimize">How to optimize?</h1><p>Requires a strong understanding of your program and experience.</p><ul><li>No way around measurements.</li><li>A certain level of experience helps.</li><li>The model of your program in your head
is different to what gets actually executed.</li></ul><div class="notes"><p>No short answer and no shortcuts to this.
It will be a long journey and this is workshop will be only a step on the journey.
Very many different languages, OS (Python, Go) and many different applications
(SQL - 90%: just add an index) that cannot all be covered.</p></div></div><div class="step step-level-1" step="14" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="22400" data-y="0" data-z="0"><h1 id="a-rule-of-thumb">A rule of thumb</h1><p><strong>Go from big to small</strong>:</p><ol><li>Do the obvious things right away.</li><li>Check if your requirements are met.</li><li>Find the biggest bottleneck.</li><li>Optimize it and repeat from step 1.</li></ol><div class="notes"><ol><li>"obvious" depends a lot on experience. Example: Open a CSV file 10k times
to extract a single row because you have a convenience function.
Do not use this as excuse for bad software.</li><li>If you don't have concrete performance requirements, make some.</li><li>We are incredible bad at guessing! Never ever skip this step!</li><li>Never mix up this order.</li></ol></div></div><div class="step step-level-1" step="15" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="24000" data-y="0" data-z="0"><h1 id="theory-complexity">Theory: Complexity</h1><ul><li>Algorithms/Structures can be divided in classes.</li><li>General types are <strong>time</strong> and <strong>space</strong> complexity.</li><li>Each divided in <strong>worst, best &amp; average case</strong>.</li><li>For datastructures specific operations are scored.</li><li>Complexity classes are given in Big-O notation.</li></ul><div class="notes"><p>It's a bit like Pokemon for algorithms.
"Merge sort, use worst case on quick sort!"
"It's very effective!"</p><p>Good example (thanks Alex): <a href="https://sortvisualizer.com">https://sortvisualizer.com</a>
(compare quick sort and merge sort)</p></div></div><div class="step step-level-1" step="16" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="25600" data-y="0" data-z="0"><h1 id="theory-big-o-notation">Theory: Big-O Notation</h1><img src="images/bigo.svg" width="100%"></img><p><a href="https://www.bigocheatsheet.com">https://www.bigocheatsheet.com</a></p><div class="notes"><p>O(1) -&gt; constant
O(n) -&gt; linear
O(log n) -&gt; logarithmic
O(n * log n) -&gt; sorting
O(n ** x) -&gt; polynomial
O(x ** n) -&gt; exponential
O(n!) -&gt; fucktorial (oops, typo)</p><p>Data structures and algorithms:</p><p>-&gt; Some have better space / time complexity.
-&gt; Most have tradeoffs, only few are universally useful like arrays / hash tables
-&gt; Some are probalibisitic: i.e. they save you work or space at the expense of accuracy (bloom filters)
-&gt; Difference between O(log n) and O(1) is not important most of the time. (database developers might disagree here though)</p></div></div><div class="step step-level-1" step="17" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="27200" data-y="0" data-z="0"><h1 id="complexity-exercises">Complexity exercises:</h1><ol><li><em>Time</em> complexity of <em>Bubble Sort</em>?</li><li><em>Time</em> complexity of <em>Binary Search</em> (<em>worst</em> &amp; <em>best</em>)?</li><li><em>Space</em> complexity of <em>Merge Sort</em> versus <em>Quick Sort</em>?</li><li><em>Removing</em> an element from an <em>Array</em> vs from a <em>Linked List</em>?</li><li><em>Best/Worst</em> case time complexity of <em>Get/Set</em> of a <em>Hash Map</em>?</li><li><em>Space complexity</em> of a <em>Hash Map</em>?</li></ol><div class="notes"><ol><li>O(n**2)</li><li>O(log2 n) (both)</li><li>O(n) vs O(1)</li><li>O(n) vs O(1)</li><li>O(1) and O(n) (but much more expensive than an array index)</li><li>O(n)</li></ol><p>Makes you wonder why you don't use hash maps all the time?
Indeed they are a wonderful invention, but:</p><ul><li>get is still much more expensive than an array index.</li><li>collisions can happen, making things inefficient.</li><li>range queries and sorting are impossible.</li><li>self balancing trees have O(log n) for get/set but are stable.</li></ul></div></div><div class="step step-level-1" step="18" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="28800" data-y="0" data-z="0"><h1 id="data-structures-lecture">&lt;/Data structures lecture&gt;</h1><img src="images/book_algorithm.png" width="50%"></img><p>That's all. Go and remember a list of:</p><ul><li>Sorting algorithms (+ external sorting)</li><li>Common &amp; some specialized data structures.</li><li>Typical algorithms like binary search.</li><li>Levenshtein, Graphs, Backtracking, ...</li><li>...whatever is of interest to you.</li></ul><div class="notes"><p>Data structures and algorithms is something you gonna have to learn yourself.
Would totally go over the scope of this workshop and does not work as frontal lecture.</p><p>Do not ignore primitive algorithms like bubble sort.
Remember: Fancy algorithms are slow when n is small, and n is usually small.</p></div></div><div class="step step-level-1" step="19" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="30400" data-y="0" data-z="0"><h1 id="performance-metrics">Performance metrics</h1><p>Automated tests that assert the <em>performance requirements</em> of a piece of code
by computing <strong>performance metrics</strong> and...</p><ul><li>...either plot them for human consumption.</li><li>...compare against old versions.</li><li>...compare against constant thresholds.</li></ul><div class="notes"><p>Collect possible performance metrics (unit in parans):</p><ul><li>Execution time (time, cpu cycles)</li><li>Latency (time)</li><li>Throughput (IO, bytes/sec)</li><li>Memory (allocations, peak, total bytes)</li></ul><p>NOTE: Execution is heavily tied to hardware.</p><p>For CI/CD tools you can use something like this:</p><p><a href="https://github.com/dandavison/chronologer">https://github.com/dandavison/chronologer</a></p><p>In an ideal world, performance requirements are tested just like
normal functional requirements.</p><p>Challenges:</p><ul><li>Different machines that benchmarks run on.</li><li>Only comparison between releases makes sense.</li></ul><p>Makes sense only for big projects. Many projects have
their own set of scripts to do this. I'm not aware of a standard solution.</p></div></div><div class="step step-level-1" step="20" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="32000" data-y="0" data-z="0"><h1 id="humans-vs-magnitudes">Humans vs Magnitudes</h1><p><a href="https://colin-scott.github.io/personal_website/research/interactive_latency.html">Interactive Latency Visualization</a></p><p><strong>Optimize in this order:</strong></p><div class="math-block ">$$\begin{align}Network &gt; Files &gt; Memory &gt; CPU\end{align}$$</div></div><div class="step step-level-1" step="21" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="33600" data-y="0" data-z="0"><h1 id="profiling">Profiling</h1><pre class="highlight code bash"><span class="c1"># Profiling is throwaway-benchmarking:
</span>$<span class="w"> </span>hyperfine<span class="w"> </span>&lt;some-command&gt;</pre><div class="notes"><p>Profiling is usually used for finding a bottleneck.
Basically a throw away benchmark, like a non-automated, manual test.</p><p>So most of the time the terms can be used interchangeably.</p><ul><li>Run several times.</li><li>If the variance is not big, take the maximum.</li><li>If the variance is rather large, use min...max.</li></ul></div></div><div class="step step-level-1" step="22" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="35200" data-y="0" data-z="0"><h1 id="workshop-project">Workshop Project</h1><div class="line-block">&#x201C;What I cannot create, I do not understand&#x201D;.<br></br>- Richard Feynman<br></br></div><div class="notes"><p>Words don't cut it. To understand something you have to lay your hands on something
and start exploring. Workshop is about tacit knowledge, you have to connect the little dots
on my slides by working on this small slide project. I can only show you things, not understand and
learn it for you.</p><p>tacit = unausgeprochen</p></div></div><div class="step step-level-1" step="23" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="36800" data-y="0" data-z="0"><h1 id="thestore-memory-only">TheStore: Memory only</h1><pre class="highlight code go"><span class="kd">type</span><span class="w"> </span><span class="nx">KV</span><span class="w"> </span><span class="kd">map</span><span class="p">[</span><span class="kt">string</span><span class="p">][]</span><span class="kt">byte</span><span class="w">

</span><span class="kd">func</span><span class="w"> </span><span class="p">(</span><span class="nx">kv</span><span class="w"> </span><span class="o">*</span><span class="nx">KV</span><span class="p">)</span><span class="w"> </span><span class="nx">sync</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="kd">var</span><span class="w"> </span><span class="nx">b</span><span class="w"> </span><span class="nx">bytes</span><span class="p">.</span><span class="nx">Buffer</span><span class="w">
    </span><span class="k">for</span><span class="w"> </span><span class="nx">k</span><span class="p">,</span><span class="w"> </span><span class="nx">v</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="k">range</span><span class="w"> </span><span class="nx">kv</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nx">b</span><span class="p">.</span><span class="nx">WriteString</span><span class="p">(</span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Sprintf</span><span class="p">(</span><span class="s">"%s=%s\n"</span><span class="p">,</span><span class="w"> </span><span class="nx">k</span><span class="p">,</span><span class="w"> </span><span class="nx">v</span><span class="p">))</span><span class="w">
    </span><span class="p">}</span><span class="w">

    </span><span class="nx">ioutil</span><span class="p">.</span><span class="nx">WriteFile</span><span class="p">(</span><span class="s">"/blah"</span><span class="p">,</span><span class="w"> </span><span class="nx">b</span><span class="p">.</span><span class="nx">Bytes</span><span class="p">(),</span><span class="w"> </span><span class="mo">0644</span><span class="p">)</span><span class="w">
</span><span class="p">}</span></pre><div class="notes"><p>You could use a bigh in-memory hash table and sync that to disk sometimes.</p><p>When do you call sync()? After every write? Inefficient.
Less often? Then you will suffer data loss on power loss or crash.</p><p>Sounds impractical, but surprise: Redis actually works this way.
They do not use a hash map internally though, but a tree structure as index.
Oh, and they perform most work in a single thread. Still fast.</p></div></div><div class="step step-level-1" step="24" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="38400" data-y="0" data-z="0"><h1 id="thestore-append-only">TheStore: Append only</h1><pre class="highlight code bash">set<span class="o">()</span><span class="w"> </span><span class="o">{</span><span class="w">
    </span><span class="nb">printf</span><span class="w"> </span><span class="s2">"%s=%s\n"</span><span class="w"> </span><span class="s2">"</span><span class="nv">$1</span><span class="s2">"</span><span class="w"> </span><span class="s2">"</span><span class="nv">$2</span><span class="s2">"</span><span class="w"> </span>&gt;&gt;<span class="w"> </span>./db<span class="w">
</span><span class="o">}</span><span class="w">

</span>get<span class="o">()</span><span class="w"> </span><span class="o">{</span><span class="w">
    </span>grep<span class="w"> </span><span class="s2">"^</span><span class="nv">$1</span><span class="s2">="</span><span class="w"> </span>./db<span class="w"> </span><span class="p">|</span><span class="w"> </span>tail<span class="w"> </span>-1<span class="w"> </span><span class="p">|</span><span class="w"> </span>cut<span class="w"> </span>-d<span class="o">=</span><span class="w"> </span>-f2-<span class="w">
</span><span class="o">}</span></pre><div class="notes"><p>Simple append only write, get reads only the last value.
Every update of an existing key writes it again.</p><p>Terribly slow because get needs to scan the whole db, but
very easy to implement and set is pretty fast. If you hardly
ever call get then this might be a viable solution.</p></div></div><div class="step step-level-1" step="25" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="40000" data-y="0" data-z="0"><h1 id="thestore-indexed">TheStore: Indexed</h1><pre class="highlight code go"><span class="kd">type</span><span class="w"> </span><span class="nx">KV</span><span class="w"> </span><span class="kd">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="kt">int64</span><span class="w">

</span><span class="kd">func</span><span class="w"> </span><span class="p">(</span><span class="nx">kv</span><span class="w"> </span><span class="o">*</span><span class="nx">KV</span><span class="p">)</span><span class="w"> </span><span class="nx">Set</span><span class="p">(</span><span class="nx">key</span><span class="w"> </span><span class="kt">string</span><span class="p">,</span><span class="w"> </span><span class="nx">val</span><span class="w"> </span><span class="p">[]</span><span class="kt">byte</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="c1">// 1. Build entry with key and value</span><span class="w">
    </span><span class="c1">// 2. Append entry to end of db file</span><span class="w">
    </span><span class="c1">// 3. Update kv index with new offset.</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="kd">func</span><span class="w"> </span><span class="p">(</span><span class="nx">kv</span><span class="w"> </span><span class="o">*</span><span class="nx">KV</span><span class="p">)</span><span class="w"> </span><span class="nx">Get</span><span class="p">(</span><span class="nx">key</span><span class="w"> </span><span class="kt">string</span><span class="p">)</span><span class="w"> </span><span class="p">[]</span><span class="kt">byte</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="c1">// 1. Get offset &amp; seek to it.</span><span class="w">
    </span><span class="c1">// 2. Read value from db file at offset.</span><span class="w">
</span><span class="p">}</span></pre><div class="notes"><p>This is actually already quite nice!</p><p>This approach is called "log structured", because values are handled
like a stream of logs, just timestamped (or offset stamped) data.</p><p>We can handle any number of values as long as we do not run out of memory.
If we throw in a little caching, we could probably get decent performance.
This would also be a decent usage for something called mmap which we will
look into later in this series.</p><p>When loading the db file, we can reconstruct the index map easily.</p><p>Problems:</p><ul><li>There will be many duplicates if we update the same keys over and over.</li><li>The database file will grow without bound. Might turn out problematic.</li><li>There may only be one writer at a point (race condition between size of db
and actual write).</li></ul></div></div><div class="step step-level-1" step="26" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="41600" data-y="0" data-z="0"><h1 id="thestore-segments">TheStore: Segments</h1><img src="diagrams/1_segments.svg" width="100%"></img><div class="notes"><p>Solution:</p><ol><li>If the db file gets too big (&gt; 32M), start a new one.</li><li>Old one gets compacted in background (i.e. duplicates get removed)</li><li>Index structure remembers what file we need to read.</li></ol><p>The compaction step can be easily done in the background.</p><p>Open issues:</p><ul><li>We still need to have all keys in memory.</li><li>Range queries are kinda impossible.</li><li>We can't delete stuff.</li></ul></div></div><div class="step step-level-1" step="27" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="43200" data-y="0" data-z="0"><h1 id="thestore-deletion">TheStore: Deletion</h1><img src="images/tombstones.png" width="50%"></img><div class="notes"><p>When we want to delete something, we just write a special value
that denotes that this key was deleted. If a tombstone is the last
value then the key is gone. Compaction can use it to clean up old
traces of that value.</p><p>At this point we already build a key value store that is used out there: Bitcask.</p></div></div><div class="step step-level-1" step="28" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="44800" data-y="0" data-z="0"><h1 id="thestore-range-queries">TheStore: Range queries</h1><img src="diagrams/1_lsm.svg" width="100%"></img><div class="notes"><blockquote><p>Change approach quite a bit:</p><ol><li>Keep a batch of key-value pairs in memory, but sorted by key.</li><li>If batch gets too big, then swap to disk.</li><li>Keep every 100th key in the offset index.</li><li>If key not in index, go to file and scan the range.</li></ol></blockquote><p>This technique is called a Log-Structured-Merge tree (LSM).</p><p>"tree" because usually a tree is used instead of a hash table for easy handling,
but this is not strictly necessary and the main point of the concept.</p><p>Since the index can be "sparse" (not all keys need to be stored), we have very
fine grained control over memory usage. Worst thing is a bit of extra scanning
in the file.</p><p>Open problems:</p><ul><li>Get on non-existing keys.</li><li>Crash safety</li></ul></div></div><div class="step step-level-1" step="29" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="46400" data-y="0" data-z="0"><h1 id="thestore-wal">TheStore: WAL &#x1F40B;</h1><img src="diagrams/1_wal.svg" width="100%"></img><div class="notes"><p>What if a crash occurs before things get written to disk?</p><p>We have to use a WAL like above! On a crash we can reconstruct the memory index from it.
Postgres and many other databases make use of this technique too.</p></div></div><div class="step step-level-1" step="30" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="48000" data-y="0" data-z="0"><h1 id="fynn">Fynn!</h1><div class="notes"><p>I left quite some details out, but that's something you should be able to figure out.</p></div></div></div><div id="slide-number" class="slide-number">
         1
      </div><script type="text/javascript" src="js/impress.js"></script><script type="text/javascript" src="js/gotoSlide.js"></script><script type="text/javascript" src="js/hovercraft.js"></script><script type="text/javascript">
      document.getElementById("impress").addEventListener("impress:stepenter", update_slide_number, false);
    </script></body></html>