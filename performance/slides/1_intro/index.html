<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml"><head><title>Performance: I/O</title><meta charset="UTF-8"></meta><meta name="generator" content="Hovercraft! 1.0 http://regebro.github.com/hovercraft"></meta><link rel="stylesheet" href="css/hovercraft.css" media="all"></link><link rel="stylesheet" href="css/highlight.css" media="all"></link><link rel="stylesheet" href="hovercraft.css" media="screen,projection"></link><script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        showProcessingMessages: false,
        messageStyle: "none",
        TeX : { extensions : ['color.js'] }
      });
    </script></head><body class="impress-not-supported"><div id="impress-help"></div><div id="impress" data-transition-duration="1500"><div class="step step-level-1" step="0" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="0" data-y="0" data-z="0"><h1 id="what-this-workshop-is">What this workshop is</h1><ul><li>An intro into Performance thinking</li><li>An attempt at understanding the machine we program on</li><li>Some lesser know tricks</li><li>A workshop. You gonna have to work for it.</li></ul></div><div class="step step-level-1" step="1" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="1600" data-y="0" data-z="0"><h1 id="what-this-workshop-is-not">What this workshop is not</h1><ul><li>An exhausting list of tricks</li><li>A lecture on algorithm and data structures - pick a book.</li><li>Something you just listen and it clicks</li><li>Application specific performance tips (Networking, SQL, ...)</li></ul></div><div class="step step-level-1" step="2" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="3200" data-y="0" data-z="0"><h1 id="you-need-to-experiment-yourself">You need to experiment yourself</h1><p>We will write our own little databases in this workshop.</p><ul><li>You can group up or do it on our own if you must.</li><li>You can also use your favourite programming language.</li><li>You can always ask me outside the workshop when writing it.</li></ul><p>TODO: Move the explanation of LSM dbs to intro and re-order io and cpu?</p></div><div class="step step-level-1" step="3" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="4800" data-y="0" data-z="0"><h1 id="what-is-performance-optimization">What is performance optimization?</h1><p>TODO: Wikipedia.</p><p>Optimizing different metrics that</p></div><div class="step step-level-1" step="4" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="6400" data-y="0" data-z="0"><h1 id="when-to-apply-it">When to apply it?</h1><ul><li>Probably more often than you do now.</li><li>Whenever your performance requirements are not fulfilled.</li></ul><p>Wait, there are requirements?</p></div><div class="step step-level-1" step="5" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="8000" data-y="0" data-z="0"><h1 id="how-to-figure-out-performance-criteria">How to figure out performance criteria?</h1><p>Well, that's your job mostly. Your PM won't tell you most of the time.
But they will help you to get the requirements.</p><p>Ask those questions:</p><ul><li>On what kind of system the software will run on?</li><li>How many users will there be in parallel?</li><li>What kind of latency is the user willing to accept? (games, websites, ATMs)</li><li>How much scaling is expected in the next time?</li><li>Will my technology choice be a bottleneck? (Electron)</li><li>Do edge cases need to perform well?</li><li>Are the optimizations worth the risk/effort?</li><li>...</li></ul><p>Do some basic calculations based on these and add X to your goals.</p><div class="notes"><p>Do not ask: How fast could this be?
(that's a fine question for personal learning though,
but not when you get paid for delivering value to a company ;-))</p><p>After this workshop you should be able to onvert the answers to those questions
to measurable numbers.</p><p>Edgecases are a good point: Sometimes performance is only bad in certain cases.
Ask your PM if those are important for your business.
If it's a open source library, probably fix those edge cases too.</p></div></div><div class="step step-level-1" step="6" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="9600" data-y="0" data-z="0"><h1 id="when-not-to-apply-it">When not to apply it?</h1><div class="line-block">"Programmers waste enormous amounts of time thinking about, or worrying<br></br>about, the speed of noncritical parts of their programs, and these attempts at<br></br>efficiency actually have a strong negative impact when debugging and<br></br>maintenance are considered. We should forget about small efficiencies, say<br></br>about 97% of the time: premature optimization is the root of all evil. Yet we<br></br>should not pass up our opportunities in that critical 3%."<br></br></div><p>-- Donald Knuth</p><div class="notes"><p>If you don't have a problem you really should not do anything.
It is difficult to define what a "problem" is.
Electron apparently defined that it's not a problem if low-memory devices
can't use their framework.</p></div></div><div class="step step-level-1" step="7" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="11200" data-y="0" data-z="0"><h1 id="how-do-i-know-if-it-s-premature">How do I know if it's premature?</h1><img src="images/premature_optimization_flowchart.png"></img><p>Remember: It does not matter you fast you compute a wrong result.</p><div class="notes"><p>The main point is: Take your time to do things the right away. Don't drop the pen
when it worked for the first time and didn't feel slow, really take some to measure.</p><p>However, don't just blindly optimize things before you measured or optimize the small
things after measuring.</p><p>Optimizations come at a price. It's usually more and harder code to maintain (and if not,
why didn't you do it in the first place?) or they have some other disadavntages (an index
in a database for example slows drown writes and needs space!). Is it worth the risk?</p></div></div><div class="step step-level-1" step="8" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="12800" data-y="0" data-z="0"><h1 id="how-do-i-measure">How do I measure?</h1><p>Via automated benchmarks.</p><div class="notes"><p>The how will be shown</p></div></div><div class="step step-level-1" step="9" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="14400" data-y="0" data-z="0"><h1 id="how-do-i-know-how-to-optimize">How do I know how to optimize?</h1><p>No short answer and no shortcuts to this.
It will be a long journey and this is workshop will be only a step on the journey.</p><p>Very many different languages, OS (Python, Go) and many different applications
(SQL - 90%: just add an index) that cannot all be covered.</p><p>But there are some common basics and more importantly a commone thinking behind all of it.
And that is: <strong>You have to understand what your program is doing to optimize it.</strong></p></div><div class="step step-level-1" step="10" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="16000" data-y="0" data-z="0"><h1 id="in-a-nutshell-go-from-big-to-small">In a nutshell: Go from big to small</h1><p>Algorithm for optimizing a <strong>correct</strong> program:</p><ol><li>Do the obvious things right away. ("obvious" depends a lot on experience)</li><li>Check if your requirements are met. If you don't have concrete performance requirements, make some.</li><li>Benchmark to find the biggest bottlenecks regarding performance (we are incredible bad at guessing! Never skip this step)</li><li>Optimize biggest offender found and repeat from step 1.</li></ol><p>Never mix up this order.</p></div><div class="step step-level-1" step="11" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="17600" data-y="0" data-z="0"><h1 id="what-is-this-program-doing">What is this program doing?</h1><pre class="highlight code python"><span class="kn">import</span> <span class="nn">sys</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span></pre><div class="notes"><p>Interpreted -&gt; compiled to byte code.
sys.stdin.readline are two dict lookups.
memory allocations
file I/O from stdin to stdout
calling a c function (strip)
unicode conversion!</p></div></div><div class="step step-level-1" step="12" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="19200" data-y="0" data-z="0"><h1 id="inside-python">Inside Python</h1><p>All functions eventuall call functions implemented in C:</p><pre class="highlight code python"><span class="n">static</span> <span class="n">PyObject</span> <span class="o">*</span>
<span class="n">strip</span><span class="p">(</span><span class="n">PyObject</span> <span class="o">*</span><span class="bp">self</span><span class="p">,</span> <span class="n">PyObject</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">char</span> <span class="o">*</span><span class="n">s</span> <span class="o">=</span> <span class="n">NULL</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="err">!</span><span class="n">PyArg_ParseTuple</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="s2">"s"</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">s</span><span class="p">))</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">NULL</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">PyUnicode_FromString</span><span class="p">(</span><span class="n">s</span><span class="p">);</span>
<span class="p">}</span></pre><div class="notes"><p>And that happens for every function call in Python. Very often.
All those objects are allocated on the heap. Python is easy, but the price you pay for it
is high. This might give you a first feeling on how much stuff happens in a simple program.</p><p>Printing to stdout and drawing something on the screen is insanely complex too and beyond
this workshop.</p></div></div><div class="step step-level-1" step="13" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="20800" data-y="0" data-z="0"><h1 id="a-word-on-interpreted-languages">A word on interpreted languages</h1><p>TODO: needed?</p><ul><li>Many things in this workshop do not apply to you 1:1.</li><li>If you follow this workshop, a compiled language helps.</li><li>TODO</li></ul><p>Maybe some day you have to extend your language with a C module?</p></div><div class="step step-level-1" step="14" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="22400" data-y="0" data-z="0"><h1 id="theory-complexity">Theory: Complexity</h1><ul><li>Data structures and algorithms can be divided in performance classes.</li><li>General types are space and time complexity.</li><li>Often also divided in worst case, best case, average case and specific operations.</li><li>Complexity classes are given in Big-O notation.</li></ul></div><div class="step step-level-1" step="15" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="24000" data-y="0" data-z="0"><h1 id="theory-big-o-notation">Theory: Big-O Notation</h1><img src="images/bigo.svg"></img><p>www.bigocheatsheet.com</p><div class="notes"><p>O(1) -&gt; constant
O(n) -&gt; linear
O(log n) -&gt; logarithmic
O(n * log n) -&gt; sorting
O(n ** x) -&gt; polynomial
O(x ** n) -&gt; exponential
O(n!) -&gt; fucktorial (oops, typo)</p><p>Data structures and algorithms:</p><p>-&gt; Some have better space / time complexity.
-&gt; Most have tradeoffs, only few are universally useful like arrays / hash tables
-&gt; Some are probalibisitic: i.e. they save you work or space at the expense of accuracy (bloom filters)
-&gt; Difference between O(log n) and O(1) is not important most of the time. (database developers might disagree here though)</p></div></div><div class="step step-level-1" step="16" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="25600" data-y="0" data-z="0"><h1 id="complexity-examples">Complexity examples</h1><ul><li>Time complexity of bubble sort?</li><li>Time complexity of binary search (worst + best)?</li><li>Space complexity of merge sort vs quick sort?</li><li>Removing an element from an array vs from a linked list?</li><li>Best case / Worst case time complexity of get and set of a hash table?</li><li>Space complexity of a hash map?</li></ul><div class="notes"><p>n**2
log2 n
n vs 1
n vs 1
1 and 1 (but much more expensive than an array index)
n</p><p>Makes you wonder why you don't use hash maps all the time?
Indeed they are a wonderful invention, but:</p><ul><li>get is still much more expensive than an array index.</li><li>collisions can happen, making things inefficient.</li><li>range queries and sorting are impossible.</li><li>self balancing trees have O(log n) for get/set but are stable.</li></ul></div></div><div class="step step-level-1" step="17" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="27200" data-y="0" data-z="0"><h1 id="data-structures-in-this-workshop">Data structures in this workshop</h1><p>This was it all. Go pick a book or course.</p><div class="notes"><p>Data structures and algorithms is something you gonna have to learn yourself.
Would totally go over the scope of this workshop and does not work as frontal lecture.</p><p>Do not ignore primitive algorithms like bubble sort.
Remember: Fancy algorithms are slow when n is small, and n is usually small.</p></div></div><div class="step step-level-1" step="18" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="28800" data-y="0" data-z="0"><h1 id="benchmarking">Benchmarking</h1><p>Tests that measure performance requirements.</p><ul><li>Heavily tied to hardware.</li><li>Requires</li></ul><p>What are possible performance metrics?</p><div class="notes"><p>Collect possible performance metrics (unit in parans):</p><ul><li>Execution time (time, cpu cycles)</li><li>Latency (time)</li><li>Throughput (IO, bytes/sec)</li><li>Memory (allocations, peak, total bytes)</li></ul></div></div><div class="step step-level-1" step="19" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="30400" data-y="0" data-z="0"><h1 id="humans-are-bad-at-magnitudes">Humans are bad at magnitudes</h1><p><a href="https://colin-scott.github.io/personal_website/research/interactive_latency.html">https://colin-scott.github.io/personal_website/research/interactive_latency.html</a></p><p>In general:</p><ul><li>CPU &lt; Memory &lt; Files &lt; Network.</li></ul><p>Optimize in that order.</p></div><div class="step step-level-1" step="20" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="32000" data-y="0" data-z="0"><h1 id="profiling">Profiling</h1><p>Profiling is like benchmarking, but just once.</p><div class="notes"><p>Profiling is usually used for finding a bottleneck,
but you benchmark a program as part of it.</p><p>So most of the time the terms can be used interchangeably.</p></div></div><div class="step step-level-1" step="21" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="33600" data-y="0" data-z="0"><h1 id="benchmarking-and-statistics">Benchmarking and Statistics</h1><pre class="highlight code bash">$ hyperfine</pre><div class="notes"><ul><li>Run several times.</li><li>If the variance is not big, take the maximum.</li><li>If the variance is rather large, use min...max.</li></ul></div></div><div class="step step-level-1" step="22" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="35200" data-y="0" data-z="0"><h1 id="benchmarking-and-ci-cd">Benchmarking and CI/CD</h1><p><a href="https://github.com/dandavison/chronologer">https://github.com/dandavison/chronologer</a></p><div class="notes"><p>In an ideal world, performance requirements are tested just like
normal functional requirements.</p><p>Challenges:</p><ul><li>Different machines that benchmarks run on.</li><li>Only comparison between releases makes sense.</li></ul><p>Makes sense only for big projects. Many projects have
their own set of scripts to do this. I'm not aware of a standard solution.</p></div></div><div class="step step-level-1" step="23" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="36800" data-y="0" data-z="0"><h1 id="workshop-project">Workshop Project</h1><p>&#x201C;What I cannot create, I do not understand&#x201D;.</p><p>-- Richard Feynman</p><div class="notes"><p>Words don't cut it. To understand something you have to lay your hands on something
and start exploring. Workshop is about tacit knowledge, you have to connect the little dots
on my slides by working on this small slide project. I can only show you things, not understand and
learn it for you.</p><p>tacit = unausgeprochen</p></div></div><div class="step step-level-1" step="24" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="38400" data-y="0" data-z="0"><h1 id="kv-store-memory-only">KV Store: Memory only</h1><pre class="highlight code go"><span class="kd">type</span><span class="w"> </span><span class="nx">KV</span><span class="w"> </span><span class="kd">map</span><span class="p">[</span><span class="kt">string</span><span class="p">][]</span><span class="kt">byte</span><span class="w">

</span><span class="kd">func</span><span class="w"> </span><span class="p">(</span><span class="nx">kv</span><span class="w"> </span><span class="o">*</span><span class="nx">KV</span><span class="p">)</span><span class="w"> </span><span class="nx">sync</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="kd">var</span><span class="w"> </span><span class="nx">b</span><span class="w"> </span><span class="nx">bytes</span><span class="p">.</span><span class="nx">Buffer</span><span class="p">{}</span><span class="w">
    </span><span class="k">for</span><span class="w"> </span><span class="nx">k</span><span class="p">,</span><span class="w"> </span><span class="nx">v</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="k">range</span><span class="w"> </span><span class="nx">kv</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nx">b</span><span class="p">.</span><span class="nx">WriteString</span><span class="p">(</span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Sprintf</span><span class="p">(</span><span class="s">"%s=%s\n"</span><span class="p">,</span><span class="w"> </span><span class="nx">k</span><span class="p">,</span><span class="w"> </span><span class="nx">v</span><span class="p">))</span><span class="w">
    </span><span class="p">}</span><span class="w">

    </span><span class="k">return</span><span class="w"> </span><span class="nx">ioutil</span><span class="p">.</span><span class="nx">WriteFile</span><span class="p">(</span><span class="s">"/blah"</span><span class="p">,</span><span class="w"> </span><span class="mo">0644</span><span class="p">,</span><span class="w"> </span><span class="nx">b</span><span class="p">.</span><span class="nx">Bytes</span><span class="p">())</span><span class="w">
</span><span class="p">}</span></pre><div class="notes"><p>You could use a bigh in-memory hash table and sync that to disk sometimes.</p><p>When do you call sync()? After every write? Inefficient.
Less often? Then you will suffer data loss on power loss or crash.</p><p>Sounds impractical, but surprise: Redis actually works this way.
They do not use a hash map internally though, but a tree structure as index.
Oh, and they perform most work in a single thread. Still fast.</p></div></div><div class="step step-level-1" step="25" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="40000" data-y="0" data-z="0"><h1 id="kv-store-append-only">KV Store: Append only</h1><pre class="highlight code bash">set<span class="o">()</span> <span class="o">{</span>
    <span class="nb">printf</span> <span class="s2">"%s=%s\n"</span> <span class="s2">"</span><span class="nv">$1</span><span class="s2">"</span> <span class="s2">"</span><span class="nv">$2</span><span class="s2">"</span> &gt;&gt; ./db
<span class="o">}</span>

get<span class="o">()</span> <span class="o">{</span>
    grep <span class="s2">"^</span><span class="nv">$1</span><span class="s2">="</span> ./db <span class="p">|</span> tail -1 <span class="p">|</span> cut -d<span class="o">=</span> -f2-
<span class="o">}</span></pre><div class="notes"><p>Simple append only write, get reads only the last value.
Every update of an existing key writes it again.</p><p>Terribly slow because get needs to scan the whole db, but
very easy to implement and set is pretty fast. If you hardly
ever call get then this might be a viable solution.</p></div></div><div class="step step-level-1" step="26" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="41600" data-y="0" data-z="0"><h1 id="kv-store-indexed">KV Store: Indexed</h1><pre class="highlight code go"><span class="kd">type</span><span class="w"> </span><span class="nx">KV</span><span class="w"> </span><span class="kd">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="kt">int64</span><span class="w">

</span><span class="kd">func</span><span class="w"> </span><span class="p">(</span><span class="nx">kv</span><span class="w"> </span><span class="o">*</span><span class="nx">KV</span><span class="p">)</span><span class="w"> </span><span class="nx">Get</span><span class="p">(</span><span class="nx">key</span><span class="w"> </span><span class="kt">string</span><span class="p">)</span><span class="w"> </span><span class="p">[]</span><span class="kt">byte</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="c1">// 1. Get &amp; seek to offset</span><span class="w">
    </span><span class="c1">// 2. Read value from db file.</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="kd">func</span><span class="w"> </span><span class="p">(</span><span class="nx">kv</span><span class="w"> </span><span class="o">*</span><span class="nx">KV</span><span class="p">)</span><span class="w"> </span><span class="nx">Set</span><span class="p">(</span><span class="nx">key</span><span class="w"> </span><span class="kt">string</span><span class="p">,</span><span class="w"> </span><span class="nx">val</span><span class="w"> </span><span class="p">[]</span><span class="kt">byte</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="c1">// 1. Check size of db file.</span><span class="w">
    </span><span class="c1">// 2. Append value to file with offset equal to db size</span><span class="w">
    </span><span class="c1">// 3. Update kv index with new offset.</span><span class="w">
</span><span class="p">}</span></pre><div class="notes"><p>This is actually already quite nice!</p><p>This approach is called "log structured", because values are handled
like a stream of logs, just timestamped (or offset stamped) data.</p><p>We can handle any number of values as long as we do not run out of memory.
If we throw in a little caching, we could probably get decent performance.
This would also be a decent usage for something called mmap which we will
look into later in this series.</p><p>When loading the db file, we can reconstruct the index map easily.</p><p>Problems:</p><ul><li>There will be many duplicates if we update the same keys over and over.</li><li>The database file will grow without bound. Might turn out problematic.</li><li>There may only be one writer at a point (race condition between size of db
and actual write).</li></ul></div></div><div class="step step-level-1" step="27" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="43200" data-y="0" data-z="0"><h1 id="kv-store-segments">KV Store: Segments</h1><p>Solution:</p><ol><li>If the db file gets too big (&gt; 32M), start a new one.</li><li>Old one gets compacted in background (i.e. duplicates get removed)</li><li>Index structure remembers what file we need to read.</li></ol><p>TODO: Find good diagram.</p><div class="notes"><p>The compaction step can be easily done in the background.</p><p>Open issues:</p><ul><li>We still need to have all keys in memory.</li><li>Range queries are kinda impossible.</li><li>We can't delete stuff.</li></ul></div></div><div class="step step-level-1" step="28" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="44800" data-y="0" data-z="0"><h1 id="kv-store-deletion">KV Store: Deletion</h1><img src="images/tombstones.png"></img><div class="notes"><p>When we want to delete something, we just write a special value
that denotes that this key was deleted. If a tombstone is the last
value then the key is gone. Compaction can use it to clean up old
traces of that value.</p><p>At this point we already build a key value store that is used out there: Bitcask.</p></div></div><div class="step step-level-1" step="29" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="46400" data-y="0" data-z="0"><h1 id="kv-store-range-queries">KV Store: Range queries</h1><p>TODO: good diagram</p><p>Change approach quite a bit:</p><ol><li>Keep a batch of key-value pairs in memory, but sorted by key.</li><li>If batch gets too big, then swap to disk.</li><li>Keep every 100th key in the offset index.</li><li>If key not in index, go to file and scan the range.</li></ol><div class="notes"><p>This technique is called a Log-Structured-Merge tree (LSM).</p><p>"tree" because usually a tree is used instead of a hash table for easy handling,
but this is not strictly necessary and the main point of the concept.</p><p>Since the index can be "sparse" (not all keys need to be stored), we have very
fine grained control over memory usage. Worst thing is a bit of extra scanning
in the file.</p><p>Open problems:</p><ul><li>Get on non-existing keys.</li><li>Crash safety</li></ul></div></div><div class="step step-level-1" step="30" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="48000" data-y="0" data-z="0"><h1 id="kv-store-wal">KV Store: WAL</h1><p>What if a crash occurs before things get written to disk?</p><p>We have to use a WAL like above! On a crash we can reconstruct everything from it.
Postgres and many other databases make use of this technique too.</p></div><div class="step step-level-1" step="31" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="49600" data-y="0" data-z="0"><h1 id="kv-store-fin">KV Store: Fin</h1><div class="notes"><p>I left quite some details out, but that's something you should be able to figure out.</p></div></div></div><script type="text/javascript" src="js/impress.js"></script><script type="text/javascript" src="js/gotoSlide.js"></script><script type="text/javascript" src="js/hovercraft.js"></script></body></html>